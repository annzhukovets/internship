{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport copy\nimport time\n%matplotlib inline\nimport os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n!pip install --quiet googletrans==3.1.0a0\nfrom googletrans import Translator\nfrom transformers import RobertaModel, AdamW, RobertaTokenizer, RobertaConfig\nfrom torch.optim import SGD\nimport random\nfrom transformers import get_cosine_schedule_with_warmup\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet as wn\nimport gc\nimport math\ngc.enable()\n\nSEED = 42\nBATCH_SIZE = 16\nMAX_LENGTH = 256\nROBERTA_FP = '../input/roberta-base'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nos.environ['PYTHONASSEED'] = str(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"_cell_guid":"34f3b73b-4e2d-4976-8553-3785bc80ceaf","_uuid":"9a537004-fdaf-4d59-b417-e2f6a9de74d5","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":19.501535,"end_time":"2021-07-20T19:32:02.002199","exception":false,"start_time":"2021-07-20T19:31:42.500664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:27:51.67686Z","iopub.execute_input":"2021-07-21T14:27:51.677359Z","iopub.status.idle":"2021-07-21T14:28:11.842016Z","shell.execute_reply.started":"2021-07-21T14:27:51.677244Z","shell.execute_reply":"2021-07-21T14:28:11.841162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"_cell_guid":"179096b0-64d9-4f7b-b0c9-5ecaac4af727","_uuid":"30c5a220-cb57-4717-9acf-3650a981ce1d","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.039854,"end_time":"2021-07-20T19:32:02.074861","exception":false,"start_time":"2021-07-20T19:32:02.035007","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.843372Z","iopub.execute_input":"2021-07-21T14:28:11.843709Z","iopub.status.idle":"2021-07-21T14:28:11.850123Z","shell.execute_reply.started":"2021-07-21T14:28:11.843675Z","shell.execute_reply":"2021-07-21T14:28:11.848055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaForSequenceRegression(nn.Module):\n    def __init__(self):\n        super(RobertaForSequenceRegression, self).__init__()\n        self.config = RobertaConfig.from_pretrained(ROBERTA_FP)\n        self.config.update({\"output_hidden_states\":True, \n                       \"layer_norm_eps\": 1e-7})  \n        self.roberta = RobertaModel.from_pretrained(ROBERTA_FP, config = self.config)\n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.layer_norm = nn.LayerNorm(self.config.hidden_size)\n#         self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n        self.linear = nn.Linear(768, 1)\n        \n        self._init_weights(self.layer_norm)\n        self._init_weights(self.linear)\n \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)     \n\n    def forward(self, input_ids, attention_mask):\n        pooled_output = self.roberta(input_ids, attention_mask)\n        last_layer_hidden_states = pooled_output.hidden_states[-1]\n        weights = self.attention(last_layer_hidden_states)\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)\n        pooled_output = self.layer_norm(context_vector)\n#         pooled_output = self.dropout(pooled_output)\n        outputs = self.linear(pooled_output)\n        return outputs.view(-1)","metadata":{"_cell_guid":"e1c853e2-5ae8-47dd-ba16-39c01402b109","_uuid":"6f678c5b-030d-49bb-b611-0c744376f571","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.045109,"end_time":"2021-07-20T19:32:02.295009","exception":false,"start_time":"2021-07-20T19:32:02.2499","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.853Z","iopub.execute_input":"2021-07-21T14:28:11.853542Z","iopub.status.idle":"2021-07-21T14:28:11.866078Z","shell.execute_reply.started":"2021-07-21T14:28:11.853489Z","shell.execute_reply":"2021-07-21T14:28:11.864841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def RMSELoss(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs, targets))","metadata":{"_cell_guid":"036568c5-6886-4da2-a9a8-bde13e052873","_uuid":"605ec29c-031c-4a91-a9dc-4c6964265c99","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.040251,"end_time":"2021-07-20T19:32:02.364466","exception":false,"start_time":"2021-07-20T19:32:02.324215","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.868145Z","iopub.execute_input":"2021-07-21T14:28:11.868588Z","iopub.status.idle":"2021-07-21T14:28:11.877952Z","shell.execute_reply.started":"2021-07-21T14:28:11.868549Z","shell.execute_reply":"2021-07-21T14:28:11.877213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nclass regressor_stratified_cv:\n    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n                 random_state = 0, strategy = 'quantile'):\n        self.group_count = group_count\n        self.strategy = strategy\n        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n                             random_state = random_state)\n        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n                                            strategy = self.strategy)  \n            \n    def split(self, X, y, groups = None):\n        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n        return self.cv.split(X, kgroups, groups)\n    \n    def get_n_splits(self, X, y, groups = None):\n        return self.cv.get_n_splits(X, y, groups)","metadata":{"_cell_guid":"b43ea6f3-4a91-4482-a028-94a15c31a174","_uuid":"c0fbda5c-40f2-4dd9-8886-fb202bf84479","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.042288,"end_time":"2021-07-20T19:32:02.438482","exception":false,"start_time":"2021-07-20T19:32:02.396194","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.879224Z","iopub.execute_input":"2021-07-21T14:28:11.879664Z","iopub.status.idle":"2021-07-21T14:28:11.88985Z","shell.execute_reply.started":"2021-07-21T14:28:11.879621Z","shell.execute_reply":"2021-07-21T14:28:11.888749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    roberta_parameters = named_parameters[:197]    \n    attention_parameters = named_parameters[199:203]\n    regressor_parameters = named_parameters[203:]\n        \n    attention_group = [params for (name, params) in attention_parameters]\n    regressor_group = [params for (name, params) in regressor_parameters]\n\n    parameters = []\n    parameters.append({\"params\": attention_group})\n    parameters.append({\"params\": regressor_group})\n\n    for layer_num, (name, params) in enumerate(roberta_parameters):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n\n        lr = 1e-5\n\n        if layer_num >= 69:        \n            lr = 2e-5\n\n        if layer_num >= 133:\n            lr = 7e-5\n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n\n    return AdamW(parameters)","metadata":{"papermill":{"duration":0.040621,"end_time":"2021-07-20T19:32:02.512237","exception":false,"start_time":"2021-07-20T19:32:02.471616","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.891538Z","iopub.execute_input":"2021-07-21T14:28:11.891942Z","iopub.status.idle":"2021-07-21T14:28:11.90345Z","shell.execute_reply.started":"2021-07-21T14:28:11.891905Z","shell.execute_reply":"2021-07-21T14:28:11.902595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndf","metadata":{"_cell_guid":"07039672-d6a3-4e44-8a7b-e5799972f7cd","_uuid":"ac55590c-3f6f-4ba5-b053-5242aaa41b5e","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.152245,"end_time":"2021-07-20T19:32:02.696134","exception":false,"start_time":"2021-07-20T19:32:02.543889","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:11.905006Z","iopub.execute_input":"2021-07-21T14:28:11.905425Z","iopub.status.idle":"2021-07-21T14:28:12.032724Z","shell.execute_reply.started":"2021-07-21T14:28:11.905384Z","shell.execute_reply":"2021-07-21T14:28:12.031896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"text\"] = df['excerpt'].apply(lambda x: x.replace('\\n',''))","metadata":{"_cell_guid":"c2b28ea0-c1e9-45cf-8d69-1ce466dac14e","_uuid":"2b7a539e-2add-4537-98c8-ee9a0286d392","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.048971,"end_time":"2021-07-20T19:32:02.779009","exception":false,"start_time":"2021-07-20T19:32:02.730038","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.035419Z","iopub.execute_input":"2021-07-21T14:28:12.035879Z","iopub.status.idle":"2021-07-21T14:28:12.047276Z","shell.execute_reply.started":"2021-07-21T14:28:12.035815Z","shell.execute_reply":"2021-07-21T14:28:12.046159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TokenDataset(Dataset):\n    def __init__(self, tokenizer, text, target = None, is_test=False):\n        self.text = text.tolist()\n        self.target = target\n        self.is_test = is_test\n        self.max_len = MAX_LENGTH\n        self.tokenizer = tokenizer\n         \n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        inputs = self.tokenizer.encode_plus(\n            self.text[idx],\n            padding = 'max_length',            \n            max_length = self.max_len,\n            truncation = True,\n            return_attention_mask=True\n        ) \n        input_ids = torch.tensor(inputs['input_ids'])\n        attention_mask = torch.tensor(inputs['attention_mask'])\n        targets = torch.tensor(self.target[idx], dtype=torch.float)\n        if self.is_test:\n            return (input_ids, attention_mask)  \n        else:    \n            return (input_ids, attention_mask, targets)  ","metadata":{"_cell_guid":"f1941f49-e270-463c-b5a1-cd56578c8840","_uuid":"f16bc25d-9dde-46e2-94ed-ed9af62f3f81","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.042734,"end_time":"2021-07-20T19:32:02.925604","exception":false,"start_time":"2021-07-20T19:32:02.88287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.049258Z","iopub.execute_input":"2021-07-21T14:28:12.049694Z","iopub.status.idle":"2021-07-21T14:28:12.061637Z","shell.execute_reply.started":"2021-07-21T14:28:12.049648Z","shell.execute_reply":"2021-07-21T14:28:12.060736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def change_trans_target(target, se):\n    return target + random.uniform(0, se)","metadata":{"papermill":{"duration":0.039007,"end_time":"2021-07-20T19:32:02.997927","exception":false,"start_time":"2021-07-20T19:32:02.95892","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.062861Z","iopub.execute_input":"2021-07-21T14:28:12.063211Z","iopub.status.idle":"2021-07-21T14:28:12.070733Z","shell.execute_reply.started":"2021-07-21T14:28:12.063178Z","shell.execute_reply":"2021-07-21T14:28:12.069889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def change_syn_target(target, se):\n    return target - random.uniform(0, se)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T14:28:12.073835Z","iopub.execute_input":"2021-07-21T14:28:12.074152Z","iopub.status.idle":"2021-07-21T14:28:12.080603Z","shell.execute_reply.started":"2021-07-21T14:28:12.074104Z","shell.execute_reply":"2021-07-21T14:28:12.07975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_synonyms(word):\n    synonyms = set()\n    for syn in wn.synsets(word): \n        for l in syn.lemmas(): \n            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n            synonyms.add(synonym) \n    if word in synonyms:\n        synonyms.remove(word)\n    return list(synonyms)","metadata":{"papermill":{"duration":0.043803,"end_time":"2021-07-20T19:32:03.072539","exception":false,"start_time":"2021-07-20T19:32:03.028736","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.082057Z","iopub.execute_input":"2021-07-21T14:28:12.083611Z","iopub.status.idle":"2021-07-21T14:28:12.092207Z","shell.execute_reply.started":"2021-07-21T14:28:12.083569Z","shell.execute_reply":"2021-07-21T14:28:12.091338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def synonym_replacement(words, n):\n    \n    words = words.split()\n    \n    stop_words = []\n    for w in stopwords.words('english'):\n        stop_words.append(w)\n    new_words = words.copy()\n    random_word_list = list(set([word for word in words if word not in stop_words]))\n    random.shuffle(random_word_list)\n    num_replaced = 0\n    \n    for random_word in random_word_list:\n        synonyms = get_synonyms(random_word)\n        \n        if len(synonyms) >= 1:\n            synonym = random.choice(list(synonyms))\n            new_words = [synonym if word == random_word else word for word in new_words]\n#             print(\"replaced\", random_word, \"with\", synonym)\n            num_replaced += 1\n        \n        if num_replaced >= n: #only replace up to n words\n            break\n\n    sentence = ' '.join(new_words)\n    new_words = sentence.split(' ')\n\n    return sentence","metadata":{"papermill":{"duration":0.041739,"end_time":"2021-07-20T19:32:03.14616","exception":false,"start_time":"2021-07-20T19:32:03.104421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.093727Z","iopub.execute_input":"2021-07-21T14:28:12.094195Z","iopub.status.idle":"2021-07-21T14:28:12.103773Z","shell.execute_reply.started":"2021-07-21T14:28:12.094159Z","shell.execute_reply":"2021-07-21T14:28:12.102724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translation(df):\n    df_trans = df.copy(deep=True)\n    translator = Translator()\n    df_trans['text_es'] = df_trans['text'].apply(translator.translate, src='en', dest='es').apply(getattr, args=('text',))\n    df_trans['text'] = df_trans['text_es'].apply(translator.translate, src='es', dest='en').apply(getattr, args=('text',))\n    df_trans['target']  = df_trans.apply(lambda f: change_trans_target(f['target'],f['standard_error']), axis=1)\n    df_trans.drop(columns=['text_es'], inplace = True)\n    return df_trans","metadata":{"papermill":{"duration":0.039639,"end_time":"2021-07-20T19:32:03.219943","exception":false,"start_time":"2021-07-20T19:32:03.180304","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.105068Z","iopub.execute_input":"2021-07-21T14:28:12.105632Z","iopub.status.idle":"2021-07-21T14:28:12.116718Z","shell.execute_reply.started":"2021-07-21T14:28:12.105593Z","shell.execute_reply":"2021-07-21T14:28:12.115741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_syn(df):\n    df_syn = df.copy(deep=True)\n    df_syn[\"text\"] = df_syn[\"text\"].apply(lambda x: synonym_replacement(x, 4))\n    df_syn['target']  = df_syn.apply(lambda f: change_syn_target(f['target'],f['standard_error']), axis=1)\n    return df_syn","metadata":{"papermill":{"duration":0.041737,"end_time":"2021-07-20T19:32:03.293745","exception":false,"start_time":"2021-07-20T19:32:03.252008","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.120336Z","iopub.execute_input":"2021-07-21T14:28:12.120717Z","iopub.status.idle":"2021-07-21T14:28:12.127184Z","shell.execute_reply.started":"2021-07-21T14:28:12.120687Z","shell.execute_reply":"2021-07-21T14:28:12.126091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\nn_repeats = 1\ngroup_count = 12\n\ncv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n                           group_count = group_count, random_state = 42, strategy = 'quantile')\n\nepochs = 15\nn_epochs_stop = 5\nepochs_no_improve = 0\ntraining_stats = []\ni = 1\neval_losses = []\n\nfor train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n    gc.collect()\n    print('======== Fold {:}  ========'.format(i))\n    train_data = df.loc[train_idx]\n    test_data = df.loc[test_idx]\n    df_trans = translation(train_data)\n    df_syn = get_syn(train_data)\n    train_data = pd.concat([train_data, df_trans, df_syn], ignore_index=True, sort=False)\n    del df_trans, df_syn\n    \n    tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_FP)\n    \n    train_set = TokenDataset(tokenizer,\n                            text = train_data['text'].values,\n                            target = train_data['target'].values\n                           )\n    \n    test_set = TokenDataset(tokenizer,\n                           text = test_data['text'].values,\n                           target = test_data['target'].values\n                          )\n    \n    del train_data\n\n    train_dataloader = DataLoader(train_set, \n                                  batch_size = BATCH_SIZE, \n                                  shuffle = True, \n                                  num_workers=4,\n                                  pin_memory=True, \n                                  drop_last=False)\n\n    test_dataloader = DataLoader(test_set, \n                                 batch_size = BATCH_SIZE, \n                                 shuffle = False, \n                                 num_workers=4,\n                                 pin_memory=True,\n                                 drop_last=False)\n    \n    del train_set, test_set\n    gc.collect()\n    \n    model = RobertaForSequenceRegression().to(device) \n    optimizer = create_optimizer(model)\n    total_steps = (len(train_dataloader) * epochs) \n    scheduler = get_cosine_schedule_with_warmup(optimizer,\n                                                num_warmup_steps = 0, \n                                                num_training_steps= total_steps)  \n    \n    iter_eval_loss = []\n    min_eval_loss = np.Inf\n    best_loss = np.Inf\n    writer = SummaryWriter(log_dir=f'fold_{i}')\n    \n    for epoch_i in range(0, epochs):\n        print(\"\")\n        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n        t0_train = time.time()\n        \n        # training\n        model.train()\n        tr_loss = []\n        for step, (input_ids, attention_mask, target) in enumerate(train_dataloader):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)            \n            target = target.to(device)  \n            optimizer.zero_grad()\n            output = model(input_ids, attention_mask)\n            loss = RMSELoss(output, target)\n            loss.backward()\n            optimizer.step()\n            tr_loss.append(loss.detach().cpu().numpy().tolist())\n            scheduler.step()\n        \n            if (step % 20 == 0) or (step == (len(train_dataloader)-1)):\n                # evaluation\n                t1_train = time.time()\n                t0_eval = time.time()\n                all_targets, all_preds = [], []\n                model.eval()   \n                eval_loss = []\n                valid_loss = 0\n                # disable gradients \n                with torch.no_grad():\n                    for step, (input_ids, attention_mask, target) in enumerate(test_dataloader):\n                        input_ids = input_ids.to(device)\n                        attention_mask = attention_mask.to(device)   \n                        target = target.to(device)\n                        output = model(input_ids, attention_mask)\n                        loss = RMSELoss(output, target)\n                        eval_loss.append(loss.cpu().detach().numpy().tolist())\n                        \n                    valid_loss = np.array(eval_loss).mean()\n                    if valid_loss <= best_loss:\n                        print(f\"epoch:{epoch_i} | Train Loss:{np.array(tr_loss).mean()} | Validation loss:{valid_loss}\")\n                        print(f\"Validation loss Decreased from {best_loss} to {valid_loss}\")\n\n                        best_loss = valid_loss\n                        torch.save(model.state_dict(), f'model_fold_{i}.bin')\n        \n        torch.cuda.empty_cache()\n        train_losses = np.mean(tr_loss)  \n        training_time = format_time(t1_train - t0_train)\n        writer.add_scalar(\"train_loss\", train_losses, epoch_i)\n        print(\"Train loss: \", train_losses)\n        print(\"Training epcoh took: {:}\".format(training_time))\n        \n        del loss\n        del output\n        del input_ids\n        del target\n        del attention_mask\n            \n        gc.collect()\n        \n        epoch_eval_loss = np.mean(eval_loss)\n        eval_time = format_time(time.time() - t0_eval)\n        writer.add_scalar(\"eval_loss\", epoch_eval_loss, epoch_i)\n        print(\"Eval loss: \", epoch_eval_loss)\n        print(\"Evaluation took: {:}\".format(eval_time))\n        \n        # recording all statistics from this epoch\n        training_stats.append({\n            'fold' : i,\n            'epoch': epoch_i + 1,\n            'Training Loss': train_losses,\n            'Eval Loss': epoch_eval_loss,\n            'Training Time': training_time,\n            'Eval Time': eval_time\n        })\n        \n        # early stopping and saving best model\n        if epoch_eval_loss < min_eval_loss:\n            epochs_no_improve = 0\n            min_eval_loss = epoch_eval_loss\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= n_epochs_stop and epoch_i + 1 >= 10:\n            print('Early stopping! Epoch {:}'.format(epoch_i + 1) )\n            break\n        else:\n            continue\n     \n    i += 1    \n    torch.cuda.empty_cache()\n    del model\n    gc.collect()\nwriter.flush()\nwriter.close()","metadata":{"_cell_guid":"3569fa32-c022-49f6-b6fe-f9ddc75c3dfe","_uuid":"163bad85-f736-456f-b0ed-8c75cce84146","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":8093.878384,"end_time":"2021-07-20T21:46:57.203428","exception":false,"start_time":"2021-07-20T19:32:03.325044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-21T14:28:12.128767Z","iopub.execute_input":"2021-07-21T14:28:12.129157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame from our training statistics.\ndf_stats = pd.DataFrame(data=training_stats)\ndf_stats","metadata":{"_cell_guid":"d851b70c-8a9e-4b62-9720-9af838753bc9","_uuid":"242393f2-f3f2-42b0-a7bc-6a547876da9a","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.120758,"end_time":"2021-07-20T21:46:57.409298","exception":false,"start_time":"2021-07-20T21:46:57.28854","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 15))\nfor fold in df_stats.fold.unique():\n    ax = fig.add_subplot(5,1,fold)\n    max_epoch = df_stats[df_stats['fold']==fold]['epoch'].max()\n    x = np.arange(max_epoch)\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Training Loss']])\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Eval Loss']])\n    plt.xticks(range(0, max_epoch, 5))","metadata":{"_cell_guid":"9ad36d53-cc01-451e-bdf1-c6ad6f45b4ed","_uuid":"902da3b7-7d86-4716-b68d-07ca03ce50d4","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.828934,"end_time":"2021-07-20T21:46:58.332041","exception":false,"start_time":"2021-07-20T21:46:57.503107","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_cell_guid":"977ed5ac-a426-4e13-8dfe-e2915a93f3c3","_uuid":"bfef8cfd-afe4-427b-999e-8eaa167a3972","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.089927,"end_time":"2021-07-20T21:47:01.513061","exception":false,"start_time":"2021-07-20T21:47:01.423134","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}