{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "urban-bankruptcy",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:35.716314Z",
     "iopub.status.busy": "2021-06-29T16:04:35.714773Z",
     "iopub.status.idle": "2021-06-29T16:04:48.117222Z",
     "shell.execute_reply": "2021-06-29T16:04:48.116605Z",
     "shell.execute_reply.started": "2021-06-29T11:19:32.852938Z"
    },
    "papermill": {
     "duration": 12.427676,
     "end_time": "2021-06-29T16:04:48.117379",
     "exception": false,
     "start_time": "2021-06-29T16:04:35.689703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "import os\n",
    "# os.listdir(\"../input/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.system('pip install pytorch_pretrained_bert --no-index --find-links=\"../input/pytorch-pretrained-bert/pytorch_pretrained_bert\" ')\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "import random\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 356\n",
    "BERT_FP = '../input/bert-base-uncased'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-inside",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:48.164726Z",
     "iopub.status.busy": "2021-06-29T16:04:48.163939Z",
     "iopub.status.idle": "2021-06-29T16:04:48.166628Z",
     "shell.execute_reply": "2021-06-29T16:04:48.166225Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.558514Z"
    },
    "papermill": {
     "duration": 0.027136,
     "end_time": "2021-06-29T16:04:48.166737",
     "exception": false,
     "start_time": "2021-06-29T16:04:48.139601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personal-remove",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:48.212658Z",
     "iopub.status.busy": "2021-06-29T16:04:48.211974Z",
     "iopub.status.idle": "2021-06-29T16:04:48.214641Z",
     "shell.execute_reply": "2021-06-29T16:04:48.214250Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.566924Z"
    },
    "papermill": {
     "duration": 0.028201,
     "end_time": "2021-06-29T16:04:48.214745",
     "exception": false,
     "start_time": "2021-06-29T16:04:48.186544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "\n",
    "\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "whole-hello",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:48.261217Z",
     "iopub.status.busy": "2021-06-29T16:04:48.260343Z",
     "iopub.status.idle": "2021-06-29T16:04:48.262767Z",
     "shell.execute_reply": "2021-06-29T16:04:48.262357Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.577548Z"
    },
    "papermill": {
     "duration": 0.028329,
     "end_time": "2021-06-29T16:04:48.262876",
     "exception": false,
     "start_time": "2021-06-29T16:04:48.234547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForSequenceRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForSequenceRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_FP)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, ids,  token_type_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear1(pooled_output)\n",
    "        pooled_output = self.relu(pooled_output)\n",
    "        outputs = self.linear2(pooled_output)\n",
    "        return outputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-wellington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:48.306225Z",
     "iopub.status.busy": "2021-06-29T16:04:48.305568Z",
     "iopub.status.idle": "2021-06-29T16:04:48.307798Z",
     "shell.execute_reply": "2021-06-29T16:04:48.308247Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.588976Z"
    },
    "papermill": {
     "duration": 0.025776,
     "end_time": "2021-06-29T16:04:48.308369",
     "exception": false,
     "start_time": "2021-06-29T16:04:48.282593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSELoss(outputs, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "administrative-notice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:48.355749Z",
     "iopub.status.busy": "2021-06-29T16:04:48.355100Z",
     "iopub.status.idle": "2021-06-29T16:04:49.036485Z",
     "shell.execute_reply": "2021-06-29T16:04:49.035454Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.598337Z"
    },
    "papermill": {
     "duration": 0.708154,
     "end_time": "2021-06-29T16:04:49.036615",
     "exception": false,
     "start_time": "2021-06-29T16:04:48.328461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "class regressor_stratified_cv:\n",
    "    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n",
    "                 random_state = 0, strategy = 'quantile'):\n",
    "        self.group_count = group_count\n",
    "        self.strategy = strategy\n",
    "        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n",
    "                             random_state = random_state)\n",
    "        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n",
    "        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n",
    "                                            strategy = self.strategy)  \n",
    "            \n",
    "    def split(self, X, y, groups = None):\n",
    "        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n",
    "        return self.cv.split(X, kgroups, groups)\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups = None):\n",
    "        return self.cv.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "european-surgeon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.082272Z",
     "iopub.status.busy": "2021-06-29T16:04:49.081430Z",
     "iopub.status.idle": "2021-06-29T16:04:49.083910Z",
     "shell.execute_reply": "2021-06-29T16:04:49.083504Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.611382Z"
    },
    "papermill": {
     "duration": 0.026763,
     "end_time": "2021-06-29T16:04:49.084021",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.057258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(excerpt):\n",
    "    \n",
    "    # lower casing\n",
    "    excerpt = excerpt.lower()\n",
    "\n",
    "    # removal of punctuation\n",
    "    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        \n",
    "    # removal of stopwords\n",
    "#     from nltk.corpus import stopwords\n",
    "#     \", \".join(stopwords.words('english'))\n",
    "#     STOPWORDS = set(stopwords.words('english'))\n",
    "#     excerpt = \" \".join([word for word in str(excerpt).split() if word not in STOPWORDS])\n",
    "        \n",
    "    # lemmatization \n",
    "#     from nltk.stem import WordNetLemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     excerpt = \" \".join([lemmatizer.lemmatize(word) for word in excerpt.split()])\n",
    "        \n",
    "                \n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "featured-telling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.129329Z",
     "iopub.status.busy": "2021-06-29T16:04:49.128781Z",
     "iopub.status.idle": "2021-06-29T16:04:49.230819Z",
     "shell.execute_reply": "2021-06-29T16:04:49.229849Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.621207Z"
    },
    "papermill": {
     "duration": 0.126859,
     "end_time": "2021-06-29T16:04:49.230984",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.104125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2829  1.711390        0.646900  \n",
       "2830  0.189476        0.535648  \n",
       "2831  0.255209        0.483866  \n",
       "2832 -0.215279        0.514128  \n",
       "2833  0.300779        0.512379  \n",
       "\n",
       "[2834 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprised-russell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.330543Z",
     "iopub.status.busy": "2021-06-29T16:04:49.309816Z",
     "iopub.status.idle": "2021-06-29T16:04:49.361224Z",
     "shell.execute_reply": "2021-06-29T16:04:49.360789Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.675289Z"
    },
    "papermill": {
     "duration": 0.108224,
     "end_time": "2021-06-29T16:04:49.361345",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.253121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "resistant-antarctica",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.406751Z",
     "iopub.status.busy": "2021-06-29T16:04:49.406250Z",
     "iopub.status.idle": "2021-06-29T16:04:49.409982Z",
     "shell.execute_reply": "2021-06-29T16:04:49.409576Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.758059Z"
    },
    "papermill": {
     "duration": 0.027498,
     "end_time": "2021-06-29T16:04:49.410107",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.382609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "excerpts = df.text.values\n",
    "targets = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "geological-example",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.455222Z",
     "iopub.status.busy": "2021-06-29T16:04:49.454667Z",
     "iopub.status.idle": "2021-06-29T16:04:49.504844Z",
     "shell.execute_reply": "2021-06-29T16:04:49.504342Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.76434Z"
    },
    "papermill": {
     "duration": 0.074127,
     "end_time": "2021-06-29T16:04:49.504960",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.430833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_FP, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "internal-rogers",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.556908Z",
     "iopub.status.busy": "2021-06-29T16:04:49.555693Z",
     "iopub.status.idle": "2021-06-29T16:04:49.558421Z",
     "shell.execute_reply": "2021-06-29T16:04:49.558008Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.808321Z"
    },
    "papermill": {
     "duration": 0.032201,
     "end_time": "2021-06-29T16:04:49.558530",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.526329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, target = None, is_test=False):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.max_len = MAX_LENGTH\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.text[idx])\n",
    "        text = ' '.join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "            }\n",
    "        else:    \n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'targets': targets\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preliminary-judges",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.608026Z",
     "iopub.status.busy": "2021-06-29T16:04:49.605883Z",
     "iopub.status.idle": "2021-06-29T16:04:49.614214Z",
     "shell.execute_reply": "2021-06-29T16:04:49.613509Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.820009Z"
    },
    "papermill": {
     "duration": 0.035316,
     "end_time": "2021-06-29T16:04:49.614407",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.579091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "shared-theology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.699685Z",
     "iopub.status.busy": "2021-06-29T16:04:49.698863Z",
     "iopub.status.idle": "2021-06-29T16:04:49.723746Z",
     "shell.execute_reply": "2021-06-29T16:04:49.724812Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.832327Z"
    },
    "papermill": {
     "duration": 0.077516,
     "end_time": "2021-06-29T16:04:49.725016",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.647500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "group_count = 10\n",
    "\n",
    "cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "                           group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "df = df[['text', 'target']]\n",
    "\n",
    "epochs = 10\n",
    "n_epochs_stop = 5\n",
    "epochs_no_improve = 0\n",
    "training_stats = []\n",
    "i = 1\n",
    "eval_losses = []\n",
    "scaler = GradScaler()\n",
    "# input_ids, attention_masks, token_type_ids = encode(excerpts, tokenizer)\n",
    "for train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n",
    "    train_data = df.loc[train_idx]\n",
    "    test_data = df.loc[test_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inclusive-ethics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:04:49.811839Z",
     "iopub.status.busy": "2021-06-29T16:04:49.810845Z",
     "iopub.status.idle": "2021-06-29T16:21:02.518555Z",
     "shell.execute_reply": "2021-06-29T16:21:02.517643Z",
     "shell.execute_reply.started": "2021-06-29T11:20:35.386874Z"
    },
    "papermill": {
     "duration": 972.756375,
     "end_time": "2021-06-29T16:21:02.518696",
     "exception": false,
     "start_time": "2021-06-29T16:04:49.762321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Train loss:  0.6338404903949146\n",
      "Training epcoh took: 0:01:29\n",
      "Eval loss:  0.6698778735266792\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Train loss:  0.5923063033063647\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6878928906387753\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Train loss:  0.5592541090199645\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6750177774164412\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Train loss:  0.5443341744617677\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6446802881028917\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Train loss:  0.5237029127671685\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6397620638211569\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Train loss:  0.507088581441154\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6428205470244089\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Train loss:  0.5036102936301433\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6752697924772898\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Train loss:  0.4887424480747169\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6495056880844964\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Train loss:  0.49091966639102347\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6718112428983053\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Train loss:  0.48417075251189756\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6657220820585886\n",
      "Evaluation took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "train_set = TokenDataset(tokenizer,\n",
    "                        text = train_data['text'].values,\n",
    "                        target = train_data['target'].values\n",
    "                        )\n",
    "    \n",
    "test_set = TokenDataset(tokenizer,\n",
    "                        text = test_data['text'].values,\n",
    "                        target = test_data['target'].values\n",
    "                        )\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "    \n",
    "model = BertForSequenceRegression().to(device)\n",
    "model.load_state_dict(torch.load('../input/model-5-9-066/model_fold_5_epoch_9_loss_0.66.pt'))\n",
    "set_trainable(model, True)\n",
    "set_trainable(model.bert.embeddings, True)\n",
    "set_trainable(model.bert.encoder, True)\n",
    "# Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.0}\n",
    "]  \n",
    "optimizer = AdamW(optimizer_parameters,\n",
    "                      lr = 2e-6\n",
    "                     )\n",
    "total_steps = (len(train_dataloader) * epochs)               \n",
    "#     num_steps = int(total_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "iter_eval_loss = []\n",
    "min_eval_loss = np.Inf\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    # training\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        target = batch['targets'].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "\n",
    "        scheduler.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "    train_losses = np.mean(tr_loss)  \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/train_fold_{i}_epoch_{epoch_i+1}\", train_losses, epoch_i)\n",
    "    print(\"Train loss: \", train_losses)\n",
    "    print(\"Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # evaluation\n",
    "    t0 = time.time()\n",
    "    all_targets, all_preds = [], []\n",
    "    model.eval()   \n",
    "    eval_loss = []\n",
    "        \n",
    "    # disable gradients \n",
    "    with torch.no_grad(): \n",
    "        for batch in test_dataloader:\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            target = batch['targets'].to(device, dtype=torch.float)\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "    epoch_eval_loss = np.mean(eval_loss)\n",
    "    eval_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/eval_fold_{i}_epoch_{epoch_i+1}\", epoch_eval_loss, epoch_i)\n",
    "    print(\"Eval loss: \", epoch_eval_loss)\n",
    "    print(\"Evaluation took: {:}\".format(eval_time))\n",
    "        \n",
    "    # recording all statistics from this epoch\n",
    "    training_stats.append({\n",
    "            'fold' : i,\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': train_losses,\n",
    "            'Eval Loss': epoch_eval_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Eval Time': eval_time\n",
    "    })\n",
    "        \n",
    "    # early stopping and saving best model\n",
    "    if epoch_eval_loss < min_eval_loss:\n",
    "        min_eval_loss = epoch_eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        PATH = f'model_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.pt'\n",
    "    \n",
    "torch.save(best_model.state_dict(), PATH)   \n",
    "torch.cuda.empty_cache()\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-bibliography",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.575674Z",
     "iopub.status.busy": "2021-06-29T16:21:02.574404Z",
     "iopub.status.idle": "2021-06-29T16:21:02.576662Z",
     "shell.execute_reply": "2021-06-29T16:21:02.577110Z"
    },
    "papermill": {
     "duration": 0.032262,
     "end_time": "2021-06-29T16:21:02.577232",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.544970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# n_repeats = 2\n",
    "# group_count = 10\n",
    "# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "# for train_index, test_index in cv.split(input_ids, targets):\n",
    "#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n",
    "#     train_targets, test_targets = targets[train_index], targets[test_index]\n",
    "#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n",
    "#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "objective-namibia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.632297Z",
     "iopub.status.busy": "2021-06-29T16:21:02.631758Z",
     "iopub.status.idle": "2021-06-29T16:21:02.635566Z",
     "shell.execute_reply": "2021-06-29T16:21:02.635167Z"
    },
    "papermill": {
     "duration": 0.032599,
     "end_time": "2021-06-29T16:21:02.635671",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.603072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_trainable(model, True)\n",
    "# set_trainable(model.bert.embeddings, True)    \n",
    "# set_trainable(model.bert.encoder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "italian-third",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.692457Z",
     "iopub.status.busy": "2021-06-29T16:21:02.691663Z",
     "iopub.status.idle": "2021-06-29T16:21:02.694356Z",
     "shell.execute_reply": "2021-06-29T16:21:02.693892Z"
    },
    "papermill": {
     "duration": 0.032499,
     "end_time": "2021-06-29T16:21:02.694476",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.661977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs = 5\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = 5e-6,\n",
    "#                   eps = 1e-6 \n",
    "#                 )\n",
    "# total_steps = len(train_dataloader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps = 0,\n",
    "#                                             num_training_steps = total_steps)\n",
    "# eval_losses = []\n",
    "# for epoch_i in range(0, epochs):\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "#     # training\n",
    "#     model.train()\n",
    "#     tr_loss = []\n",
    "    \n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "#         ids, input_mask, type_ids, target = batch\n",
    "#         output = model(ids, input_mask, type_ids, target)\n",
    "#         loss = RMSELoss(output, target)\n",
    "#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "#         loss.backward()  \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()  \n",
    "#         scheduler.step()\n",
    "            \n",
    "#     train_losses = np.mean(tr_loss)  \n",
    "#     print(\"Train loss: \", train_losses)\n",
    "#     all_targets, all_preds = [], []\n",
    "#     model.eval()   \n",
    "#     eval_loss = []\n",
    "#     # evaluation\n",
    "#     # disable gradients \n",
    "#     with torch.no_grad(): \n",
    "#         for batch in test_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             ids, input_mask, type_ids, target = batch\n",
    "#             output = model(ids, input_mask, type_ids, target)\n",
    "#             loss = RMSELoss(output, target)\n",
    "#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "#     epoch_eval_loss = np.mean(eval_loss)\n",
    "#     print(\"Eval loss: \", epoch_eval_loss)\n",
    "\n",
    "#     eval_losses.append(epoch_eval_loss)   \n",
    "# torch.cuda.empty_cache()\n",
    "# mean_eval_loss = np.mean(eval_losses)\n",
    "# print(mean_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "democratic-broad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.749380Z",
     "iopub.status.busy": "2021-06-29T16:21:02.748859Z",
     "iopub.status.idle": "2021-06-29T16:21:02.752465Z",
     "shell.execute_reply": "2021-06-29T16:21:02.752822Z"
    },
    "papermill": {
     "duration": 0.032656,
     "end_time": "2021-06-29T16:21:02.752942",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.720286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eligible-sussex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.810406Z",
     "iopub.status.busy": "2021-06-29T16:21:02.808856Z",
     "iopub.status.idle": "2021-06-29T16:21:02.811392Z",
     "shell.execute_reply": "2021-06-29T16:21:02.811833Z"
    },
    "papermill": {
     "duration": 0.033064,
     "end_time": "2021-06-29T16:21:02.811957",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.778893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bright-pension",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.867235Z",
     "iopub.status.busy": "2021-06-29T16:21:02.866587Z",
     "iopub.status.idle": "2021-06-29T16:21:02.869363Z",
     "shell.execute_reply": "2021-06-29T16:21:02.868925Z"
    },
    "papermill": {
     "duration": 0.031375,
     "end_time": "2021-06-29T16:21:02.869469",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.838094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excerpts = test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "funky-banking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.925219Z",
     "iopub.status.busy": "2021-06-29T16:21:02.924489Z",
     "iopub.status.idle": "2021-06-29T16:21:02.927274Z",
     "shell.execute_reply": "2021-06-29T16:21:02.926842Z"
    },
    "papermill": {
     "duration": 0.031317,
     "end_time": "2021-06-29T16:21:02.927378",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.896061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sustained-basic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:02.983614Z",
     "iopub.status.busy": "2021-06-29T16:21:02.982836Z",
     "iopub.status.idle": "2021-06-29T16:21:02.985681Z",
     "shell.execute_reply": "2021-06-29T16:21:02.985253Z"
    },
    "papermill": {
     "duration": 0.032073,
     "end_time": "2021-06-29T16:21:02.985787",
     "exception": false,
     "start_time": "2021-06-29T16:21:02.953714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_set = TokenDataset(tokenizer,\n",
    "#                         text = test_data['text'].values, is_test = True\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "typical-people",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.041405Z",
     "iopub.status.busy": "2021-06-29T16:21:03.040718Z",
     "iopub.status.idle": "2021-06-29T16:21:03.043460Z",
     "shell.execute_reply": "2021-06-29T16:21:03.042997Z"
    },
    "papermill": {
     "duration": 0.031434,
     "end_time": "2021-06-29T16:21:03.043572",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.012138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "desperate-earth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.100707Z",
     "iopub.status.busy": "2021-06-29T16:21:03.099983Z",
     "iopub.status.idle": "2021-06-29T16:21:03.102290Z",
     "shell.execute_reply": "2021-06-29T16:21:03.102652Z"
    },
    "papermill": {
     "duration": 0.032495,
     "end_time": "2021-06-29T16:21:03.102788",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.070293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BertForSequenceRegression().to(device)\n",
    "# model.load_state_dict(torch.load('../input/model-1-13-0662/model_fold_1_epoch_13_loss_0.662.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "skilled-precipitation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.158863Z",
     "iopub.status.busy": "2021-06-29T16:21:03.158131Z",
     "iopub.status.idle": "2021-06-29T16:21:03.160957Z",
     "shell.execute_reply": "2021-06-29T16:21:03.160465Z"
    },
    "papermill": {
     "duration": 0.031999,
     "end_time": "2021-06-29T16:21:03.161089",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.129090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# # disable gradients \n",
    "# with torch.no_grad(): \n",
    "#     for batch in test_dataloader:\n",
    "#         ids = batch['ids'].to(device, dtype=torch.long)\n",
    "#         input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "#         type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "#         output = model(ids, input_mask, type_ids)\n",
    "#         output = output.cpu().detach().numpy().tolist()\n",
    "#         predictions += output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "automated-shade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.217571Z",
     "iopub.status.busy": "2021-06-29T16:21:03.216858Z",
     "iopub.status.idle": "2021-06-29T16:21:03.219524Z",
     "shell.execute_reply": "2021-06-29T16:21:03.219044Z"
    },
    "papermill": {
     "duration": 0.032269,
     "end_time": "2021-06-29T16:21:03.219623",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.187354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id':test['id'],'target':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "arabic-eugene",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.276342Z",
     "iopub.status.busy": "2021-06-29T16:21:03.275650Z",
     "iopub.status.idle": "2021-06-29T16:21:03.278431Z",
     "shell.execute_reply": "2021-06-29T16:21:03.277918Z"
    },
    "papermill": {
     "duration": 0.032733,
     "end_time": "2021-06-29T16:21:03.278538",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.245805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "domestic-stranger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:21:03.334555Z",
     "iopub.status.busy": "2021-06-29T16:21:03.333873Z",
     "iopub.status.idle": "2021-06-29T16:21:03.336626Z",
     "shell.execute_reply": "2021-06-29T16:21:03.336140Z"
    },
    "papermill": {
     "duration": 0.032117,
     "end_time": "2021-06-29T16:21:03.336729",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.304612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-sister",
   "metadata": {
    "papermill": {
     "duration": 0.026243,
     "end_time": "2021-06-29T16:21:03.389081",
     "exception": false,
     "start_time": "2021-06-29T16:21:03.362838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 996.908125,
   "end_time": "2021-06-29T16:21:06.057938",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-29T16:04:29.149813",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
