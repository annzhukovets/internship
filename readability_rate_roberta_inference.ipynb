{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5d7cde",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:05.242798Z",
     "iopub.status.busy": "2021-07-22T05:55:05.233159Z",
     "iopub.status.idle": "2021-07-22T05:55:11.418663Z",
     "shell.execute_reply": "2021-07-22T05:55:11.418059Z",
     "shell.execute_reply.started": "2021-07-19T06:23:14.196873Z"
    },
    "papermill": {
     "duration": 6.208479,
     "end_time": "2021-07-22T05:55:11.418817",
     "exception": false,
     "start_time": "2021-07-22T05:55:05.210338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, RobertaConfig\n",
    "import random\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 256\n",
    "ROBERTA_FP = '../input/roberta-base'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ce9152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:11.452208Z",
     "iopub.status.busy": "2021-07-22T05:55:11.451471Z",
     "iopub.status.idle": "2021-07-22T05:55:11.454154Z",
     "shell.execute_reply": "2021-07-22T05:55:11.453755Z",
     "shell.execute_reply.started": "2021-07-19T06:23:20.398841Z"
    },
    "papermill": {
     "duration": 0.020886,
     "end_time": "2021-07-22T05:55:11.454259",
     "exception": false,
     "start_time": "2021-07-22T05:55:11.433373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d905c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:11.492597Z",
     "iopub.status.busy": "2021-07-22T05:55:11.491907Z",
     "iopub.status.idle": "2021-07-22T05:55:11.494252Z",
     "shell.execute_reply": "2021-07-22T05:55:11.494687Z",
     "shell.execute_reply.started": "2021-07-19T06:23:20.427842Z"
    },
    "papermill": {
     "duration": 0.026404,
     "end_time": "2021-07-22T05:55:11.494803",
     "exception": false,
     "start_time": "2021-07-22T05:55:11.468399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RobertaForSequenceRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaForSequenceRegression, self).__init__()\n",
    "        self.config = RobertaConfig.from_pretrained(ROBERTA_FP)\n",
    "        self.config.update({\"output_hidden_states\":True, \n",
    "                       \"layer_norm_eps\": 1e-7})  \n",
    "        self.roberta = RobertaModel.from_pretrained(ROBERTA_FP, config = self.config)\n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(self.config.hidden_size)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        \n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.linear)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)     \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.roberta(input_ids, attention_mask)\n",
    "        last_layer_hidden_states = pooled_output.hidden_states[-1]\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)\n",
    "        pooled_output = self.layer_norm(context_vector)\n",
    "        outputs = self.linear(pooled_output)\n",
    "        return outputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf9d90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:11.526504Z",
     "iopub.status.busy": "2021-07-22T05:55:11.525829Z",
     "iopub.status.idle": "2021-07-22T05:55:11.528097Z",
     "shell.execute_reply": "2021-07-22T05:55:11.528531Z",
     "shell.execute_reply.started": "2021-07-19T06:23:20.443358Z"
    },
    "papermill": {
     "duration": 0.019676,
     "end_time": "2021-07-22T05:55:11.528649",
     "exception": false,
     "start_time": "2021-07-22T05:55:11.508973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSELoss(outputs, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c447e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:11.563271Z",
     "iopub.status.busy": "2021-07-22T05:55:11.562697Z",
     "iopub.status.idle": "2021-07-22T05:55:12.252877Z",
     "shell.execute_reply": "2021-07-22T05:55:12.252022Z",
     "shell.execute_reply.started": "2021-07-19T06:23:20.45556Z"
    },
    "papermill": {
     "duration": 0.710574,
     "end_time": "2021-07-22T05:55:12.253019",
     "exception": false,
     "start_time": "2021-07-22T05:55:11.542445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "class regressor_stratified_cv:\n",
    "    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n",
    "                 random_state = 0, strategy = 'quantile'):\n",
    "        self.group_count = group_count\n",
    "        self.strategy = strategy\n",
    "        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n",
    "                             random_state = random_state)\n",
    "        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n",
    "        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n",
    "                                            strategy = self.strategy)  \n",
    "            \n",
    "    def split(self, X, y, groups = None):\n",
    "        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n",
    "        return self.cv.split(X, kgroups, groups)\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups = None):\n",
    "        return self.cv.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4ecf2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.288961Z",
     "iopub.status.busy": "2021-07-22T05:55:12.288163Z",
     "iopub.status.idle": "2021-07-22T05:55:12.290834Z",
     "shell.execute_reply": "2021-07-22T05:55:12.290421Z"
    },
    "papermill": {
     "duration": 0.023254,
     "end_time": "2021-07-22T05:55:12.290949",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.267695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": regressor_group})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 1e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 2e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 7e-5\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea96d81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.326716Z",
     "iopub.status.busy": "2021-07-22T05:55:12.326013Z",
     "iopub.status.idle": "2021-07-22T05:55:12.328149Z",
     "shell.execute_reply": "2021-07-22T05:55:12.328569Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.141451Z"
    },
    "papermill": {
     "duration": 0.023784,
     "end_time": "2021-07-22T05:55:12.328683",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.304899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, target = None, is_test=False):\n",
    "        self.text = text.tolist()\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.max_len = MAX_LENGTH\n",
    "        self.tokenizer = tokenizer\n",
    "         \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.text[idx],\n",
    "            padding = 'max_length',            \n",
    "            max_length = self.max_len,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        ) \n",
    "        input_ids = torch.tensor(inputs['input_ids'])\n",
    "        attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "        if self.is_test:\n",
    "            return (input_ids, attention_mask)  \n",
    "        else:    \n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return (input_ids, attention_mask, targets)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3f5b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.360290Z",
     "iopub.status.busy": "2021-07-22T05:55:12.359822Z",
     "iopub.status.idle": "2021-07-22T05:55:12.373365Z",
     "shell.execute_reply": "2021-07-22T05:55:12.372944Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.152743Z"
    },
    "papermill": {
     "duration": 0.031073,
     "end_time": "2021-07-22T05:55:12.373483",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.342410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7154d60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.411926Z",
     "iopub.status.busy": "2021-07-22T05:55:12.411287Z",
     "iopub.status.idle": "2021-07-22T05:55:12.414519Z",
     "shell.execute_reply": "2021-07-22T05:55:12.414089Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.174602Z"
    },
    "papermill": {
     "duration": 0.027126,
     "end_time": "2021-07-22T05:55:12.414621",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.387495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"text\"] = test['excerpt'].apply(lambda x: x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d4bc13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.449898Z",
     "iopub.status.busy": "2021-07-22T05:55:12.449214Z",
     "iopub.status.idle": "2021-07-22T05:55:12.451894Z",
     "shell.execute_reply": "2021-07-22T05:55:12.451503Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.187837Z"
    },
    "papermill": {
     "duration": 0.023404,
     "end_time": "2021-07-22T05:55:12.451994",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.428590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicting(test, states):\n",
    "\n",
    "    all_preds = []\n",
    "    \n",
    "    for state in states:\n",
    "        model = RobertaForSequenceRegression()\n",
    "        model.load_state_dict(state)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_FP)\n",
    "        \n",
    "        test_set = TokenDataset(tokenizer,\n",
    "                        text = test['text'].values, \n",
    "                        is_test = True)\n",
    "        \n",
    "        test_dataloader = DataLoader(test_set, \n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             drop_last=False, \n",
    "                             shuffle=False, \n",
    "                             num_workers=2)\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (input_ids, attention_mask) in enumerate(test_dataloader):\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)   \n",
    "                output = model(input_ids, attention_mask)\n",
    "                preds.append(output.cpu().numpy())\n",
    "\n",
    "            preds = np.concatenate(preds)\n",
    "            \n",
    "            all_preds.append(preds)\n",
    "\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f09ac43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.484224Z",
     "iopub.status.busy": "2021-07-22T05:55:12.483486Z",
     "iopub.status.idle": "2021-07-22T05:55:12.485949Z",
     "shell.execute_reply": "2021-07-22T05:55:12.486358Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.198821Z"
    },
    "papermill": {
     "duration": 0.020466,
     "end_time": "2021-07-22T05:55:12.486470",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.466004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pathes = ['../input/models-batch/model_fold_1.bin', \n",
    "          '../input/models-batch/model_fold_2.bin',\n",
    "          '../input/models-batch/model_fold_3.bin',\n",
    "          '../input/models-batch/model_fold_4.bin',\n",
    "          '../input/models-batch/model_fold_5.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5df67fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:12.517664Z",
     "iopub.status.busy": "2021-07-22T05:55:12.517064Z",
     "iopub.status.idle": "2021-07-22T05:55:37.862808Z",
     "shell.execute_reply": "2021-07-22T05:55:37.861925Z",
     "shell.execute_reply.started": "2021-07-19T06:23:21.210785Z"
    },
    "papermill": {
     "duration": 25.362527,
     "end_time": "2021-07-22T05:55:37.862965",
     "exception": false,
     "start_time": "2021-07-22T05:55:12.500438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = [torch.load(s) for s in pathes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ab7273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:37.895587Z",
     "iopub.status.busy": "2021-07-22T05:55:37.894996Z",
     "iopub.status.idle": "2021-07-22T05:55:52.727483Z",
     "shell.execute_reply": "2021-07-22T05:55:52.727892Z",
     "shell.execute_reply.started": "2021-07-19T06:23:47.4856Z"
    },
    "papermill": {
     "duration": 14.850369,
     "end_time": "2021-07-22T05:55:52.728063",
     "exception": false,
     "start_time": "2021-07-22T05:55:37.877694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "all_preds = predicting(test, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19eadf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:52.773052Z",
     "iopub.status.busy": "2021-07-22T05:55:52.772466Z",
     "iopub.status.idle": "2021-07-22T05:55:52.776781Z",
     "shell.execute_reply": "2021-07-22T05:55:52.776294Z",
     "shell.execute_reply.started": "2021-07-19T06:24:01.959618Z"
    },
    "papermill": {
     "duration": 0.031722,
     "end_time": "2021-07-22T05:55:52.776925",
     "exception": false,
     "start_time": "2021-07-22T05:55:52.745203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(all_preds)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0609cc00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:52.828605Z",
     "iopub.status.busy": "2021-07-22T05:55:52.820857Z",
     "iopub.status.idle": "2021-07-22T05:55:52.831361Z",
     "shell.execute_reply": "2021-07-22T05:55:52.832042Z",
     "shell.execute_reply.started": "2021-07-19T06:24:01.97079Z"
    },
    "papermill": {
     "duration": 0.038928,
     "end_time": "2021-07-22T05:55:52.832225",
     "exception": false,
     "start_time": "2021-07-22T05:55:52.793297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = predictions.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88dbceaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:52.906025Z",
     "iopub.status.busy": "2021-07-22T05:55:52.905165Z",
     "iopub.status.idle": "2021-07-22T05:55:52.907889Z",
     "shell.execute_reply": "2021-07-22T05:55:52.908734Z",
     "shell.execute_reply.started": "2021-07-19T06:24:01.984569Z"
    },
    "papermill": {
     "duration": 0.044925,
     "end_time": "2021-07-22T05:55:52.908938",
     "exception": false,
     "start_time": "2021-07-22T05:55:52.864013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test['id'],'target':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19da04ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:52.978894Z",
     "iopub.status.busy": "2021-07-22T05:55:52.977987Z",
     "iopub.status.idle": "2021-07-22T05:55:52.982094Z",
     "shell.execute_reply": "2021-07-22T05:55:52.982884Z",
     "shell.execute_reply.started": "2021-07-19T06:24:01.99466Z"
    },
    "papermill": {
     "duration": 0.042501,
     "end_time": "2021-07-22T05:55:52.983127",
     "exception": false,
     "start_time": "2021-07-22T05:55:52.940626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba16525c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:53.055064Z",
     "iopub.status.busy": "2021-07-22T05:55:53.054158Z",
     "iopub.status.idle": "2021-07-22T05:55:53.066966Z",
     "shell.execute_reply": "2021-07-22T05:55:53.068146Z",
     "shell.execute_reply.started": "2021-07-19T06:24:02.006941Z"
    },
    "papermill": {
     "duration": 0.054389,
     "end_time": "2021-07-22T05:55:53.068332",
     "exception": false,
     "start_time": "2021-07-22T05:55:53.013943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.439601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.560899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.463929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.367995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.826550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-0.968265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.100761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.439601\n",
       "1  f0953f0a5 -0.560899\n",
       "2  0df072751 -0.463929\n",
       "3  04caf4e0c -2.367995\n",
       "4  0e63f8bea -1.826550\n",
       "5  12537fe78 -0.968265\n",
       "6  965e592c0  0.100761"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d12dd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T05:55:53.155547Z",
     "iopub.status.busy": "2021-07-22T05:55:53.154800Z",
     "iopub.status.idle": "2021-07-22T05:55:53.158735Z",
     "shell.execute_reply": "2021-07-22T05:55:53.159655Z",
     "shell.execute_reply.started": "2021-07-19T06:24:02.028737Z"
    },
    "papermill": {
     "duration": 0.060859,
     "end_time": "2021-07-22T05:55:53.159828",
     "exception": false,
     "start_time": "2021-07-22T05:55:53.098969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c817af",
   "metadata": {
    "papermill": {
     "duration": 0.029655,
     "end_time": "2021-07-22T05:55:53.217299",
     "exception": false,
     "start_time": "2021-07-22T05:55:53.187644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.671694,
   "end_time": "2021-07-22T05:55:55.178636",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-22T05:54:58.506942",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
