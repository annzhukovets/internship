{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport copy\nimport time\n%matplotlib inline\nimport os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel, AdamW\nfrom torch.optim import SGD\nimport random\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch_lr_finder import LRFinder, TrainDataLoaderIter, ValDataLoaderIter\n\n\nSEED = 42\nBATCH_SIZE = 16\nMAX_LENGTH = 321\nROBERTA_FP = '../input/roberta-base'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nos.environ['PYTHONASSEED'] = str(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"_uuid":"9a537004-fdaf-4d59-b417-e2f6a9de74d5","_cell_guid":"34f3b73b-4e2d-4976-8553-3785bc80ceaf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.590203Z","iopub.execute_input":"2021-07-04T14:45:22.590467Z","iopub.status.idle":"2021-07-04T14:45:22.657238Z","shell.execute_reply.started":"2021-07-04T14:45:22.590438Z","shell.execute_reply":"2021-07-04T14:45:22.656354Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install torch-lr-finder","metadata":{"_uuid":"bf40b604-ad48-42a1-a25f-95a75ad07058","_cell_guid":"c42408c1-cd3e-45f9-9236-ad1e7d9514fe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:15.088460Z","iopub.execute_input":"2021-07-04T14:45:15.088790Z","iopub.status.idle":"2021-07-04T14:45:22.587105Z","shell.execute_reply.started":"2021-07-04T14:45:15.088760Z","shell.execute_reply":"2021-07-04T14:45:22.586146Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torch-lr-finder\n  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (1.19.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (3.4.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (20.9)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (4.59.0)\nRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (1.7.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->torch-lr-finder) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->torch-lr-finder) (0.6)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (7.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (2.8.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.15.0)\nInstalling collected packages: torch-lr-finder\nSuccessfully installed torch-lr-finder-0.2.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"_uuid":"30c5a220-cb57-4717-9acf-3650a981ce1d","_cell_guid":"179096b0-64d9-4f7b-b0c9-5ecaac4af727","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.659167Z","iopub.execute_input":"2021-07-04T14:45:22.659752Z","iopub.status.idle":"2021-07-04T14:45:22.665289Z","shell.execute_reply.started":"2021-07-04T14:45:22.659714Z","shell.execute_reply":"2021-07-04T14:45:22.664372Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def children(m):\n    return m if isinstance(m, (list, tuple)) else list(m.children())\n\n\ndef set_trainable_attr(m, b):\n    m.trainable = b\n    for p in m.parameters():\n        p.requires_grad = b\n\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    if len(c) > 0:\n        for l in c:\n            apply_leaf(l, f)\n\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m, b))","metadata":{"_uuid":"7d158a9a-0862-4ba0-84b2-406c926093ac","_cell_guid":"c68fff04-419d-4691-89e4-61f4f7f72dc9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.667070Z","iopub.execute_input":"2021-07-04T14:45:22.667718Z","iopub.status.idle":"2021-07-04T14:45:22.676126Z","shell.execute_reply.started":"2021-07-04T14:45:22.667661Z","shell.execute_reply":"2021-07-04T14:45:22.675260Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class RobertaForSequenceRegression(nn.Module):\n    def __init__(self):\n        super(RobertaForSequenceRegression, self).__init__()\n        self.roberta = RobertaModel.from_pretrained(ROBERTA_FP)\n        self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n        self.linear1 = nn.Linear(self.roberta.config.hidden_size, 256)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(256, 1)\n\n    def forward(self, ids,  attention_mask):\n        _, pooled_output = self.roberta(ids, attention_mask, return_dict=False)\n        pooled_output = self.dropout(pooled_output)\n        pooled_output = self.linear1(pooled_output)\n        pooled_output = self.relu(pooled_output)\n        outputs = self.linear2(pooled_output)\n        return outputs.view(-1)","metadata":{"_uuid":"6f678c5b-030d-49bb-b611-0c744376f571","_cell_guid":"e1c853e2-5ae8-47dd-ba16-39c01402b109","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.678309Z","iopub.execute_input":"2021-07-04T14:45:22.679761Z","iopub.status.idle":"2021-07-04T14:45:22.696121Z","shell.execute_reply.started":"2021-07-04T14:45:22.679731Z","shell.execute_reply":"2021-07-04T14:45:22.694039Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def RMSELoss(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs, targets))","metadata":{"_uuid":"605ec29c-031c-4a91-a9dc-4c6964265c99","_cell_guid":"036568c5-6886-4da2-a9a8-bde13e052873","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.700258Z","iopub.execute_input":"2021-07-04T14:45:22.702472Z","iopub.status.idle":"2021-07-04T14:45:22.710649Z","shell.execute_reply.started":"2021-07-04T14:45:22.702432Z","shell.execute_reply":"2021-07-04T14:45:22.709759Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nclass regressor_stratified_cv:\n    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n                 random_state = 0, strategy = 'quantile'):\n        self.group_count = group_count\n        self.strategy = strategy\n        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n                             random_state = random_state)\n        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n                                            strategy = self.strategy)  \n            \n    def split(self, X, y, groups = None):\n        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n        return self.cv.split(X, kgroups, groups)\n    \n    def get_n_splits(self, X, y, groups = None):\n        return self.cv.get_n_splits(X, y, groups)","metadata":{"_uuid":"c0fbda5c-40f2-4dd9-8886-fb202bf84479","_cell_guid":"b43ea6f3-4a91-4482-a028-94a15c31a174","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:22.712078Z","iopub.execute_input":"2021-07-04T14:45:22.713139Z","iopub.status.idle":"2021-07-04T14:45:23.506135Z","shell.execute_reply.started":"2021-07-04T14:45:22.713099Z","shell.execute_reply":"2021-07-04T14:45:23.505287Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def text_preprocessing(excerpt):\n    \n    # lower casing\n    excerpt = excerpt.lower()\n\n    # removal of punctuation\n    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n\n                \n    return excerpt","metadata":{"_uuid":"f06f6d99-321e-462a-a7c5-e9798eb4d022","_cell_guid":"9d335daf-1ecf-4e78-81c1-4d38383b2cc8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:23.508107Z","iopub.execute_input":"2021-07-04T14:45:23.508368Z","iopub.status.idle":"2021-07-04T14:45:23.516419Z","shell.execute_reply.started":"2021-07-04T14:45:23.508342Z","shell.execute_reply":"2021-07-04T14:45:23.515617Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CustomTrainIter(TrainDataLoaderIter):\n    def inputs_labels_from_batch(self, batch_data):\n        inputs = batch_data[\"ids\"], batch_data[\"mask\"]\n        labels = batch_data[\"targets\"] \n        return  inputs, labels","metadata":{"_uuid":"d3154ab2-1423-4ae4-ae4b-11e7fcb8b340","_cell_guid":"f0930ec1-e8a1-4f28-8293-388f10c4d54f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:23.519864Z","iopub.execute_input":"2021-07-04T14:45:23.520113Z","iopub.status.idle":"2021-07-04T14:45:23.526867Z","shell.execute_reply.started":"2021-07-04T14:45:23.520090Z","shell.execute_reply":"2021-07-04T14:45:23.525989Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ModelWrapper(nn.Module):\n    def __init__(self, model):\n        super(ModelWrapper, self).__init__()\n        self.model = model\n\n    def forward(self, inputs):\n        ids, attention_mask = inputs\n        return self.model(ids=ids, attention_mask=attention_mask)","metadata":{"_uuid":"befdf74b-0f69-42bb-98a3-7adc2b3b0935","_cell_guid":"654587b3-261a-4fbe-85c9-7de4a182fb64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:23.528656Z","iopub.execute_input":"2021-07-04T14:45:23.528977Z","iopub.status.idle":"2021-07-04T14:45:23.537296Z","shell.execute_reply.started":"2021-07-04T14:45:23.528946Z","shell.execute_reply":"2021-07-04T14:45:23.536351Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndf","metadata":{"_uuid":"ac55590c-3f6f-4ba5-b053-5242aaa41b5e","_cell_guid":"07039672-d6a3-4e44-8a7b-e5799972f7cd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:23.595410Z","iopub.execute_input":"2021-07-04T14:45:23.595715Z","iopub.status.idle":"2021-07-04T14:45:23.693409Z","shell.execute_reply.started":"2021-07-04T14:45:23.595687Z","shell.execute_reply":"2021-07-04T14:45:23.692622Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             id                                          url_legal  \\\n0     c12129c31                                                NaN   \n1     85aa80a4c                                                NaN   \n2     b69ac6792                                                NaN   \n3     dd1000b26                                                NaN   \n4     37c1b32fb                                                NaN   \n...         ...                                                ...   \n2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n\n           license                                            excerpt  \\\n0              NaN  When the young people returned to the ballroom...   \n1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n2              NaN  As Roger had predicted, the snow departed as q...   \n3              NaN  And outside before the palace a great garden w...   \n4              NaN  Once upon a time there were Three Bears who li...   \n...            ...                                                ...   \n2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n\n        target  standard_error  \n0    -0.340259        0.464009  \n1    -0.315372        0.480805  \n2    -0.580118        0.476676  \n3    -1.054013        0.450007  \n4     0.247197        0.510845  \n...        ...             ...  \n2829  1.711390        0.646900  \n2830  0.189476        0.535648  \n2831  0.255209        0.483866  \n2832 -0.215279        0.514128  \n2833  0.300779        0.512379  \n\n[2834 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url_legal</th>\n      <th>license</th>\n      <th>excerpt</th>\n      <th>target</th>\n      <th>standard_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c12129c31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>When the young people returned to the ballroom...</td>\n      <td>-0.340259</td>\n      <td>0.464009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85aa80a4c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n      <td>-0.315372</td>\n      <td>0.480805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b69ac6792</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>As Roger had predicted, the snow departed as q...</td>\n      <td>-0.580118</td>\n      <td>0.476676</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dd1000b26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>And outside before the palace a great garden w...</td>\n      <td>-1.054013</td>\n      <td>0.450007</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37c1b32fb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Once upon a time there were Three Bears who li...</td>\n      <td>0.247197</td>\n      <td>0.510845</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2829</th>\n      <td>25ca8f498</td>\n      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>When you think of dinosaurs and where they liv...</td>\n      <td>1.711390</td>\n      <td>0.646900</td>\n    </tr>\n    <tr>\n      <th>2830</th>\n      <td>2c26db523</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>So what is a solid? Solids are usually hard be...</td>\n      <td>0.189476</td>\n      <td>0.535648</td>\n    </tr>\n    <tr>\n      <th>2831</th>\n      <td>cd19e2350</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>The second state of matter we will discuss is ...</td>\n      <td>0.255209</td>\n      <td>0.483866</td>\n    </tr>\n    <tr>\n      <th>2832</th>\n      <td>15e2e9e7a</td>\n      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Solids are shapes that you can actually touch....</td>\n      <td>-0.215279</td>\n      <td>0.514128</td>\n    </tr>\n    <tr>\n      <th>2833</th>\n      <td>5b990ba77</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Animals are made of many cells. They eat thing...</td>\n      <td>0.300779</td>\n      <td>0.512379</td>\n    </tr>\n  </tbody>\n</table>\n<p>2834 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))","metadata":{"_uuid":"2b7a539e-2add-4537-98c8-ee9a0286d392","_cell_guid":"c2b28ea0-c1e9-45cf-8d69-1ce466dac14e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:24.279190Z","iopub.execute_input":"2021-07-04T14:45:24.279508Z","iopub.status.idle":"2021-07-04T14:45:24.367223Z","shell.execute_reply.started":"2021-07-04T14:45:24.279478Z","shell.execute_reply":"2021-07-04T14:45:24.366368Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"excerpts = df.text.values\ntargets = df.target.values","metadata":{"_uuid":"0d090d08-8c7f-4fad-a2f8-0b5a8adb42ee","_cell_guid":"e9788680-3d78-4e10-8940-acc9a1e0a48b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:24.891874Z","iopub.execute_input":"2021-07-04T14:45:24.892208Z","iopub.status.idle":"2021-07-04T14:45:24.899025Z","shell.execute_reply.started":"2021-07-04T14:45:24.892177Z","shell.execute_reply":"2021-07-04T14:45:24.898164Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Load the ROBERTA tokenizer.\ntokenizer = RobertaTokenizer.from_pretrained(ROBERTA_FP)","metadata":{"_uuid":"dfe3837d-29c3-4720-972d-558ae5df1411","_cell_guid":"88b7ae3f-6da4-4e21-9820-b2ea2ef0af2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:25.257015Z","iopub.execute_input":"2021-07-04T14:45:25.257336Z","iopub.status.idle":"2021-07-04T14:45:25.363448Z","shell.execute_reply.started":"2021-07-04T14:45:25.257307Z","shell.execute_reply":"2021-07-04T14:45:25.362617Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class TokenDataset(Dataset):\n    def __init__(self, tokenizer, text, target = None, is_test=False):\n        self.text = text\n        self.target = target\n        self.is_test = is_test\n        self.max_len = MAX_LENGTH\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n        text = ' '.join(text.split())\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length = self.max_len,\n            padding='max_length',\n#             add_special_tokens=True,\n            return_attention_mask=True\n        )\n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n        \n        if self.is_test:\n            return {\n                'ids': ids,\n                'mask': mask,\n            }\n        else:    \n            targets = torch.tensor(self.target[idx], dtype=torch.float)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'targets': targets\n            }","metadata":{"_uuid":"f16bc25d-9dde-46e2-94ed-ed9af62f3f81","_cell_guid":"f1941f49-e270-463c-b5a1-cd56578c8840","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:25.728176Z","iopub.execute_input":"2021-07-04T14:45:25.728547Z","iopub.status.idle":"2021-07-04T14:45:25.740381Z","shell.execute_reply.started":"2021-07-04T14:45:25.728485Z","shell.execute_reply":"2021-07-04T14:45:25.739249Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"writer = SummaryWriter()","metadata":{"_uuid":"066449bb-db83-431b-90ce-638bc4756c47","_cell_guid":"c78ca05e-3ed9-408e-bfd8-5354c338f7c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:27.218839Z","iopub.execute_input":"2021-07-04T14:45:27.219176Z","iopub.status.idle":"2021-07-04T14:45:27.226944Z","shell.execute_reply.started":"2021-07-04T14:45:27.219146Z","shell.execute_reply":"2021-07-04T14:45:27.226149Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"CUDA_LAUNCH_BLOCKING=1\nn_splits = 5\nn_repeats = 1\ngroup_count = 10\n\ncv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n                           group_count = group_count, random_state = 0, strategy = 'quantile')\ni = 1\nfor train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n    train_data = df.loc[train_idx]\n    test_data = df.loc[test_idx]\n    \ntrain_set = TokenDataset(tokenizer,\n                        text = train_data['text'].values,\n                        target = train_data['target'].values\n                        )\n\ntrain_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n    \ncustom_train_iter = CustomTrainIter(train_dataloader)\ncriterion = nn.MSELoss()\nmodel = RobertaForSequenceRegression().to(device)\nmodel_wrapper = ModelWrapper(model)\noptimizer = SGD(model.parameters(), lr=2e-5, momentum=0.9)\nlr_finder = LRFinder(model_wrapper, optimizer, criterion, device)\nlr_finder.range_test(custom_train_iter, end_lr=1)\nlr_finder.plot()","metadata":{"_uuid":"e2e2dfd1-4d86-4930-b1d3-7899725be63b","_cell_guid":"f467df56-f13f-4acd-a153-7c9cb5cc9a66","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:45:28.305951Z","iopub.execute_input":"2021-07-04T14:45:28.306293Z","iopub.status.idle":"2021-07-04T14:46:29.257820Z","shell.execute_reply.started":"2021-07-04T14:45:28.306263Z","shell.execute_reply":"2021-07-04T14:46:29.256953Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"032aa4032fd44ad1adb96356187c423a"}},"metadata":{}},{"name":"stdout","text":"Stopping early, the loss has diverged\nLearning rate search finished. See the graph with {finder_name}.plot()\nLR suggestion: steepest gradient\nSuggested LR: 3.82E-04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEMCAYAAADJQLEhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4HklEQVR4nO3deXhU5dn48e892clOFsjCkrCTAAECCAhIVUBUQCtatFrcUFtbW/ta6vvTqm3tpu3bqq1bVQStomBdACsWZZFFCBDZtwTICgkhK9mT5/dHhsgyWZnJJDP357rmInPOM+fccxLmnmc5zyPGGJRSSrkvi7MDUEop5VyaCJRSys1pIlBKKTeniUAppdycJgKllHJzmgiUUsrNOSwRiMjrIpInInuaKXOFiKSKyF4RWeeoWJRSSjVNHHUfgYhMBsqAxcaYRBv7Q4BNwAxjTIaIRBpj8hwSjFJKqSZ5OurAxpj1ItK3mSK3Ah8YYzKs5VuVBMLDw03fvs0dViml1IW2b99+yhgTYWufwxJBKwwEvERkLRAI/M0Ys7ilF/Xt25eUlBRHx6aUUi5FRI43tc+ZicATGA1cCfgBm0VkizHm0IUFRWQBsACgd+/eHRqkUkq5OmeOGsoCPjPGnDHGnALWAyNsFTTGvGKMSTbGJEdE2KzZKKWUaidnJoKPgMtFxFNEugHjgP1OjEcppdySw5qGROQd4AogXESygCcALwBjzEvGmP0i8h9gF1AP/NMY0+RQU6VU+9XU1JCVlUVlZaWzQ1EO5uvrS2xsLF5eXq1+jSNHDc1rRZlngGccFYNSqkFWVhaBgYH07dsXEXF2OMpBjDEUFBSQlZVFXFxcq1+ndxYr5QYqKysJCwvTJODiRISwsLA21/w0ETjJgRMlVNbUOTsM5UY0CbiH9vyeNRE4wfbjp7nmbxt4dX26s0NRyjZjYMsW+Pe/G/510AwEf/3rXykvL3fIsVurqKiIf/zjHx12vr59+3Lq1CkAJkyY0O7jLFq0iJycHLvEpImgg1XX1vPL5bsxBr48qDNqqE5o1Sro3Ruuvhrmz2/4t3fvhu125iqJoLa2tl2v27RpU7vPqYmgC3tpXRqH88pI7hNKamYRxRU1zg5JqW+tWgU33QRZWVBWBiUlDf9mZTVsb2cyOHPmDNdeey0jRowgMTGRpUuX8txzz5GTk8PUqVOZOnUqAKtXr2b8+PGMGjWKuXPnUlZWBsD27duZMmUKo0ePZvr06eTm5gJwxRVX8NBDD5GUlERiYiJbt25tPN9dd93F2LFjGTlyJB999BEAe/fuZezYsSQlJTF8+HAOHz7ML3/5S9LS0khKSuKRRx65KPbf/OY3DBo0iMsvv5x58+bx7LPPNp77pz/9KcnJyfztb3/jk08+Ydy4cYwcOZKrrrqKkydPAlBQUMC0adNISEjgnnvu4dz53QICAhp/fuaZZxgzZgzDhw/niSeeAODYsWMMGTKEe++9l4SEBKZNm0ZFRQXLli0jJSWF2267jaSkJCoqKtr1e2lkjOlSj9GjR5uu6kheqRnwv6vMj97ebrYeLTB9Fq4wn+7OcXZYyg3s27ev5UL19cbExBjT0BBk+xEb21CujZYtW2buueeexudFRUXGGGP69Olj8vPzjTHG5Ofnm0mTJpmysjJjjDF/+MMfzFNPPWWqq6vN+PHjTV5enjHGmHfffdfceeedxhhjpkyZ0njcdevWmYSEBGOMMY8++qhZsmSJMcaYwsJCM2DAAFNWVmYefPBB89ZbbxljjKmqqjLl5eXm6NGjja+70NatW82IESNMRUWFKSkpMf379zfPPPNM47kfeOCBxrKnT5829dZr8+qrr5qHH37YGGPMj3/8Y/PUU08ZY4xZsWKFARrfs7+/vzHGmM8++8zce++9pr6+3tTV1Zlrr73WrFu3zhw9etR4eHiYnTt3GmOMmTt3buP7mjJlitm2bZvNuG39voEU08TnqjOnmHAr9fWGRz/Yja+XhSeuTyCkmxcBPp6sP3yKGYlRrTpGXb0hPb+MXVnF7MoqYld2MWeqannvvvGEdPN28DtQLu/rr6G4uPkyRUWwdSuMG9emQw8bNoyf//znLFy4kOuuu45JkyZdVGbLli3s27ePiRMnAlBdXc348eM5ePAge/bs4eqrrwagrq6OqKhv/8/Mm9cwUn3y5MmUlJRQVFTE6tWr+fjjjxu/vVdWVpKRkcH48eN5+umnycrK4sYbb2TAgAHNxr1x40Zmz56Nr68vvr6+XH/99eftv+WWWxp/zsrK4pZbbiE3N5fq6urG4Zvr16/ngw8+AODaa68lNDT0ovOsXr2a1atXM3LkSADKyso4fPgwvXv3Ji4ujqSkJABGjx7NsWPHmo25PTQRdJD3UjLZevQ0f/zuMCICfQCY0C+M9YfyMca02NNvjOGuRdtYdygfgG7eHgyNCuLQyTLe/jqDH03t7/D3oFxcbi5YWmgttligHe3SAwcOZMeOHaxatYrHHnuMK6+8kl/96lfnlTHGcPXVV/POO++ct3337t0kJCSwefNmm8e+8P+OiGCMYfny5QwaNOi8fUOGDGHcuHGsXLmSmTNn8vLLLxMfH9/m93OWv79/488//vGPefjhh5k1axZr167lySefbPVxjDE8+uij3HfffedtP3bsGD4+Po3PPTw8Lr0ZyAbtI+gAeaWV/G7Vfi6L787Nyb0at08aGEFWYQXHClruLNuRUcS6Q/ncNTGOz382md1PTmfZAxOYNCCcRZuOUVWrQ1HVJYqKgvr65svU10N0dJsPnZOTQ7du3fj+97/PI488wo4dOwAIDAyktLQUgMsuu4yNGzdy5MgRoKGd/9ChQwwaNIj8/PzGRFBTU8PevXsbj7106VIAvvrqK4KDgwkODmb69Ok8//zzje3xO3fuBCA9PZ34+Hh+8pOfMHv2bHbt2nVeDBeaOHEin3zyCZWVlZSVlbFixYom32NxcTExMTEAvPnmm43bJ0+ezL/+9S8APv30UwoLCy967fTp03n99dcb+0Sys7PJy2t+MElzcbeVJoIOsGx7FiWVtTx9w7Dzvr1MHhAOwIbD+S0e4/WNRwn09eTn0wYyoEcgHpaG49w7KZ780io++Sa33fEVlFVRWqmd1m5v3DgIDm6+TEgIjB3b5kPv3r27sZP2qaee4rHHHgNgwYIFzJgxg6lTpxIREcGiRYuYN28ew4cPZ/z48Rw4cABvb2+WLVvGwoULGTFiBElJSeeNtvH19WXkyJHcf//9vPbaawA8/vjj1NTUMHz4cBISEnj88ccBeO+990hMTCQpKYk9e/Zwxx13EBYWxsSJE0lMTLyos3jMmDHMmjWL4cOHc8011zBs2DCCm7hGTz75JHPnzmX06NGEh4c3bn/iiSdYv349CQkJfPDBBzZnUJ42bRq33nor48ePZ9iwYdx0000tfsjPnz+f+++/XzuLu4pH3k81yb/93Oa+SX/8wty9yHaHz1lZheUm/tGV5umVF3cA1dfXm2l/WWem/9+6xo6q1qisqTUrd+WYO9/YauIfXWlufXVzq1+rup5WdRYbY8zKlcb4+dnuKPbza9jfiTTXYWovpaWlxhhjzpw5Y0aPHm22b9/u0PPZQ1s7i7VG0AGOF5TTp3s3m/smDQhnc9opauqarpIv3nwMYwx3jO9z0T4R4e5JcRw4UcrGIwUtxlJZU8dTn+xl7NNr+OHbO9iXU8KwmGC2pJ/WoawKZs6EZcsgNhYCAiAoqOHf2NiG7TNnOjvCDrdgwQKSkpIYNWoU3/3udxk1apSzQ7I77SzuAJmny7ksPszmvkkDInj76wx2HC9knI0y5dW1vPN1BjMSexIbajuZzE6K5k//OcirG9K5fEC4zTLQMOroJ+/s5PP9J7lueDRzR8cysX84OzMKuemlzXx1+BTXDm/dCCblwmbOhIyMhtFBOTkNfQJjx0InnKJi7dq1Dj/H2fZ9V6aJwMGqauvILamkd5jtD/EJ/cPwsAgbDp+ymQiW78impLKWuyY2PZOgj6cHPxjfhz9/fohDJ0sZ2CPwojLGGJ78eC+r953kyeuHMv+c4yX1CiHI15N1h/I0EagGIm0eIqq6Lm0acrCswgqMgd5NNA0F+XoxsleIzQ7j+nrDGxuPMjw2mNF9Lh57fK7bLuuDr5eF1zYctbn/H2vTWLLlOPdNiT8vCQB4eliYNCCCddahrMo16e/WPbTn96yJwMEyTjcMDW0qEUBD89Cu7GIKz1Sft33d4XzS889w18S4Fu8z6O7vzXdHxfLvndnklZ4/Be3y7Vk889lB5iRFs3D6YJuvnzIogpMlVezPtc9wNNW5+Pr6UlBQoMnAxRnTsB6Br69vm16nTUMOlmG9R6CppiGASQPD+b//HmJj2imuG/7tGO3XvzpKZKAPM4e1rrnm7svj+NfWDC773RoiAn3oGexHZKAPXx7IY2L/MP500wgsFtsJ5YqBDWtBrz2Ux9DooNa+PdVFxMbGkpWVRX5+y0OVVdd2doWyttBE4GAZp8vx8/IgIsCnyTLDY4IJ8vXk/ZQssgsrOJxXxuG8Mr7JLOJ/pg3E27N1Fbf4iADeunscXx89zYniCnKLKzl26gwT+4fz/K0jmz1OZJAvQ6OCWHswnx9eoXcpuxovL682rVil3IsmAgc7XlBO7+7dmm3a8fSwMHlgBCt25bLuUD6RgT4M6BHAfVPiubOZTmJbJvYPZ2L/pkcONWfKoAheXZ9OSWUNQb6tX+9UKdW1aSJwsMzT5fRqpn/grKfnDOOuy+PoFx5AcDfnfAhfMTCCF9emselI6yfCU0p1fdpZ7EDGGDJOl9Onmf6Bs4K7eTGqd6jTkgDAqD6hBPp4svagtiMr5U60RuBA+WVVVNTUNTtiqDPx8rBwef8w8j9fh5EjSHR0w1jyTngjkVLKfjQROFBrRgx1KqtW8ef/uYf6wkLq/+WFhzENk4y9/LJbTi2glLvQpiEHas09BJ2GdYnCbnm5BNRU4lFaapclCpVSnZ8mAgfKOF2OCMSG+jk7lOYZAwsWQFNT2VZUwH33NZRTSrkcTQQOlFFQTlSQLz6eHs4OpXltWaJQKeVyNBE4UEYrh446nQOXKFRKdX6aCBzoeCuHjjqdA5coVEp1fpoIHKSiuo780qqu0VHswCUKlVKdnyYCB2kcMRTm7+RIWkEEXnkF/Jro1PbzaxhCqvcTKOWSNBE4SJcaOgoXLVFY2S2AM96+GDdeolApd6E3lDnI8YIzQBdKBHDeEoU7NuziT7tKefaZe+lvY8UzpZTr0ETgIJmnywn08STUiXMHtYt1icLgXoNJPfUV+0+UaiJQysVp05AdnL5gZTFoGDHUq4Xppzuz/pEBeFqEAydKnB2KUsrBNBFcor9/eYTRv/2cz/edPG97a2cd7ax8PD3oFxGgS1cq5QY0EVyCD3dm88xnB/EQ4Tcr9lFVWwc0LDqfdbqia/UP2DA4KpADuVojUMrVaSJop01pp3hk2TdcFt+dV+4YTcbpcl776igAJ0oqqa6r7zqzjjZhSFQQOcWVFJVf3PSllHIdmgja4fDJUu5bsp2+Yf68/P1kvjO4B1cP7cELXxzhZEll1xs62oTBPRs6iQ+c0OYhpVyZJoI2yiupZP4b2/D18uCNO8c0rij22LVDqK0z/Ok/BxvXIejTvQvcTNaMoVFBAOzX5iGlXJrDEoGIvC4ieSKyp4n9V4hIsYikWh+/clQs9lJVW8eCJdspLK/m9R+MITb022/8fcL8uXtSHMt3ZPHJrhw8LEJUiK8To710EYE+dPf35oB2GCvl0hxZI1gEzGihzAZjTJL18WsHxmIXT6/cT2pmEX+5eQTDYi+em+dHU/sTEejDhsOniA7xxcuja1e4RIQhUYHs1yGkSrk0h31SGWPWA6cddfyO9uHObBZvPs6CyfHMSIyyWSbAx5OFMwYDXb9Z6KzBPYM4eKKUunpdlEYpV+Xsr6zjReQbEflURBKaKiQiC0QkRURS8vPzOzI+AA6eKOXRD3YzNq47v5g+qNmyN46M4ZrEnlw9tEcHRedYQ6KCqKqt5+ipM84ORSnlIM6cYmIH0McYUyYiM4EPgQG2ChpjXgFeAUhOTu7Qr6allTU88NZ2Anw9eWHeSDxbaO6xWIQXvz+6g6JzvLMjh/bnltA/MsDJ0SilHMFpNQJjTIkxpsz68yrAS0TCnRWPLcYYFi7fxfHT5bwwbySRQV2787c9BvQIwEOnmlDKpTktEYhIT7FOxCMiY62xFDgrHlsyTpezavcJHpzan3HxYc4Oxykapprw16kmlHJhDmsaEpF3gCuAcBHJAp4AvACMMS8BNwEPiEgtUAF8zxjTqXokj+SVATB5YISTI3GuIVFBbDvqMv3+SqkLOCwRGGPmtbD/BeAFR53fHs4mgv4R7t02PrhnEB+l5lBUXk1IN29nh6OUsjNnjxrq1NLyywgP8Gm8e9hdDYnSqSaUcmWaCJqRln+GfhGucT/ApRhinWpiX452GCvlijQRNMEYw5G8MvrpkEkiA33oG9aNv605zKa0U84ORyllZ5oImlBwppriihq37x+AhqkmFt81jshAH+54bSvvbs1wdkhKKTvSRNCENGtHsdYIGvQO68byH05gQv9wfvnBbp5euU+nnVDKRWgiaEJafsOUCtpH8K0gXy9e/0Ey8yf05dUNR/nh29s1GSjlAjQRNOFIXhl+Xh5EB/s5O5ROxdPDwpOzEnjs2iF8tvckL61Lc3ZISqlLpImgCWn5ZcRH+GOxiLND6ZTuvjyO60dE85fPD7Ezo9DZ4SilLoEmgiak5ZfRTzuKmyQi/HZOIj2DfHno3VRKK2ucHZJSqp00EdhQUV1HdlGFzrbZgmA/L/72vSSyCst54qO9zg5HKdVOmghsSD9VhjFojaAVkvt25ydXDuCDndl8uDPb2eEopdpBE4ENjSOGInXEUGs8OLU/yX1CeezDPWQUlDs7HKVUG2kisOFIXhkWgb5hmghaw9PDwl+/l4QAP38/VYeUKtXFaCKwIS2/jF7du+Hr5eHsULqM2NBuPDU7gW3HCnl1Q3qrX3fwRCl5pZUOjEwp1RJNBDak5emIofa4YWQMMxJ68pfVh9if2/IEdaWVNdz04iZ+/cm+DohOKdUUTQQXqKs3pJ/SWUfbQ0R4+oZEgvy8+NnSVKpq65otv3RbJqVVtWw/rvchKOVMmggukF1YQXVtvQ4dbaewAB/+cOMwDpwo5a//Pdxkubp6w6JNx/CwCLnFleQWV3RglEqpc2kiuEBavnWyOW0aarerhvbgluRevLwujZRjtpe4XL33BFmFFSyYHA/AzoyiDoxQKXUuTQQXOLs8pSaCS/P49UOJDvHjp0tTKS6/+K7j1746Sq/ufjx05QB8PC3s0OYhpZxGE8EF0vLLCPP3JtRf1+a9FAE+njw3byQniiv5+fvfYMy3Q0q/ySwi5Xgh8yfE4evlwbCYYHbofEVKOY0mggvoHEP2M6p3KI/OHMJ/9588b0jpa18dJcDHk5uTYxvK9QllT05Ji53LSinH0ERwgbT8M3pHsR3dNbEvMxJ68sf/HCTl2GlyiytYtTuXW8b0ItDXC4CRvUKorq3XNZGVchJNBOc4faaa02eqtUZgRyLCn+YOJzbUjwf/tZO//fcw9cYwf0LfxjKj+oQC2mGslLNoIjhH44ghHTpqV0G+Xvz91lGcLq/m3W2ZTE/oSa/u3Rr39wjyJTrYV/sJlHISTQTnODtiSBest7/EmGB+PSsBXy9L45DRc43sE6o1AqWcxNPZAXQWR/JK+dt/DxMR6ENMiC5P6QjfG9ubOSNjbM7hNKp3KCt35XKypJIeQb5OiE4p96U1AmB3VjFzX9pMbb1h8V1jdXlKB2pqIr+RvUMAdNlLpZzA7RPB1+kFzHt1C928PVl2/3iGRAU5OyS3lBAdhLeHhR3aPKRUh3PrpqEvD+Rx/1vbiQ314617xhEVrE1CzuLj6UFCTJDWCJRyAresERhjeGPjUe5ZnMKAHgG8d994TQKdwKjeoezKKqa6tt7ZoSjlVtwuEVTV1rFw+S6e+mQf3xkcybsLxhMW4OPssBQNiaCqtp4DJ/TGMqU6kls1DeWVVvLAWzvYfryQn3ynPz+9aqB2DHciZzuMdxwvZHhsiFNjUcqduE2NYE92MbNf2Mi+nBL+fusoHp42SJNAJxMd4kfPIF/tMFaqg7lNjaCqth5fLw+WPZBMQnSws8NRTRjZO4SdmdphrFRHcpsaweg+oXz+s8maBDq5MX27k3m6ovEub6WU47lNIgDw9HCrt9slXTciCg+L8P72TGeHopTb0E9G1alEBvoydVAkH+zIprZOh5Eq1RE0EahO5+bkWPJLq1h3KN/ZoSjlFjQRqE5n6uBIwgO8eS9Fm4eU6ggOSwQi8rqI5InInhbKjRGRWhG5yVGxqK7Fy8PCjaNiWbM/j1NlVc4ORymX58gawSJgRnMFRMQD+COw2oFxqC5o7uhYausNH+7MdnYoSrk8hyUCY8x64HQLxX4MLAfyHBWH6poG9AhkZO8Qlm7LxBjj7HCUcmlO6yMQkRjgBuDFVpRdICIpIpKSn68diO5i7uheHM4r45usYmeHopRLc2Zn8V+BhcaYFscIGmNeMcYkG2OSIyIiHB+Z6hSuGxGFr5eF97XTWCmHcmYiSAbeFZFjwE3AP0RkjhPjUZ1MkK8XMxOj+Dg1h4rqOmeHo5TLalUiEBF/EbFYfx4oIrNExOtSTmyMiTPG9DXG9AWWAT80xnx4KcdUrmduci9Kq2p5Z2uGs0NRymW1tkawHvC1tuuvBm6nYVRQk0TkHWAzMEhEskTkbhG5X0Tuv5SAlXsZF9edyQMj+O3Kfazee8LZ4SjlkqQ1IzJEZIcxZpSI/BjwM8b8SURSjTFJDo/wAsnJySYlJaWjT6uc6ExVLbf+82v255aw+K6xXBYf5uyQlOpyRGS7MSbZ1r7W1ghERMYDtwErrds87BGcUi3x9/Fk0fwx9O7ejXveTGFPto4iUsqeWpsIfgo8CvzbGLNXROKBLx0WlVIXCPX3ZvFdYwny9WT+G1s5euqMs0NSymW0KhEYY9YZY2YZY/5o7TQ+ZYz5iYNjU+o80SF+LL57HHX1hgfe2q43millJ60dNfQvEQkSEX9gD7BPRB5xbGhKXax/ZAD/M30QB06Usi9XF7lXyh5a2zQ01BhTAswBPgXiaBg5pFSHm5kYhadF+Dg1x9mhKOUSWpsIvKz3DcwBPjbG1ABaL1dOEervzeSBEXzyTQ719fpnqNSlam0ieBk4BvgD60WkD6D1cuU0s5OiySmuJOW4LnSv1KVqbWfxc8aYGGPMTNPgODDVwbEp1aSrhvTA18vCR6k6TbVSl6q1ncXBIvKXszOAisifaagdKOUU/j6eXD20J6t251KjaxsrdUla2zT0OlAK3Gx9lABvOCoopVpj1ohoCstr+OrwKWeHolSX1tpE0M8Y84QxJt36eAqId2RgSrVkysAIgv28+PgbHT2k1KVobSKoEJHLzz4RkYlAhWNCUqp1vD0tXJPYk8/2ntBpqpW6BK1NBPcDfxeRY9b1A14A7nNYVEq10qykaMqr61hz4GTjtpLKGl776ihfpxc4MTKlug7P1hQyxnwDjBCRIOvzEhH5KbDLgbEp1aJxcWFEBvrwUWoOE/uF88bGo7yx6RillbWM7hPK8gcmODtEpTq9ViWCs6x3F5/1MA3LTSrlNB4W4foR0by56RgT//gF5dV1zEjoCcCXB/Oorq3H29OZC/Ep1fldyv8QsVsUSl2Cm5N74eftwbShPVj9s8m8dPtorh8RTVVtPQdO6H2PSrWkTTWCC+i9/apTGNQzkN1PTj9vW1LvEABSM4sYHhvS8UEp1YU0WyMQkVIRKbHxKAWiOyhGpdosOtiXiEAfUjOKnB2KUp1eszUCY0xgRwWilD2JCCN7hbAzs8jZoSjV6WkvmnJZSb1DOHrqDEXl1c4ORalOTROBcllJvUKAhn4CpVTTNBEolzU8NgSLwE7tJ1CqWZoIlMsK8PFkYI9ArREo1QJNBMqlJfUKITWzSBe6V6oZmgiUSxvZO4TiihqOnjrj7FCU6rQ0ESiXltQrFNAOY6Wao4lAubT+kQH4e3toh7FSzdBEoFyah0UYYe0nUErZpolAubykXiHszy2hskYXr1HKFk0EyuUl9Qqhtt6wJ7vY2aEo1SlpIlAu79yZSJVSF9NEoFxeZKAvMSF+2mGsVBM0ESi3kNRbO4yVaoomAuUWRvUOJbuogszT5c4ORalORxOBcgvThvYAYMWuXCdHolTno4lAuYVe3bsxqncIH6VmOzsUpTodTQTKbcwaEc2BE6UcOlnq7FCU6lQ0ESi3ce3waCwCH6fmODsUpToVTQTKbUQE+jCxfzgff5Oj01LbWVVtHX/5/BCFZ3RZ0K7IYYlARF4XkTwR2dPE/tkisktEUkUkRUQud1QsSp01a0Q0GafLdSipna07mM9zaw6zaNMxZ4ei2sGRNYJFwIxm9q8BRhhjkoC7gH86MBalAJie2BNvTwsfuUnz0D83pLNw2S6Hn2dTWgEAy7ZnUV+vta2uxmGJwBizHjjdzP4y82393B/Qvx7lcEG+Xlw5OJIVu3Kprat3djgOVV9v+OeGoyxNyWRnRqFDz7Up7RTdvD3ILqpgS3qBQ8+l7M+pfQQicoOIHABW0lAraKrcAmvzUUp+fn7HBahc0qwR0Zwqq2JLepPfU1zCruxiTpRUAvDK+nSHnSe/tIpDJ8tYMDmeQF9P3t+e5bBzKcdwaiIwxvzbGDMYmAP8pplyrxhjko0xyRERER0Wn3JNUwdHEujj6fL3FKzeewIPi/D9y3rzn70nSM8vc8h5NqWdAuA7gyOZNSKaT/fkUlJZ45BzKcfoFKOGrM1I8SIS7uxYlOvz9fJgemJP/rPnhEuvUfDZ3hNcFt+dh64ciJeHhVc3HHXIeTanFRDk60lCdDBzk3tRWVPPSr2Du0txWiIQkf4iItafRwE+gDYuqg4xa0Q0pVW1fHkgz9mhOMSRvDLS8s8wPaEnEYE+3DQ6luU7ssgrrbT7uTalFXBZfFjDanCxwQyIDOD9lEy7n0c5jiOHj74DbAYGiUiWiNwtIveLyP3WIt8F9ohIKvB34Bajg7tVB5nQL4yYED+e++IIdS44ymX1vhMAXG2dY2nBpHhq6upZtPGYXc+TebqcjNPlTOgXBoCIcNPoWHZkFHEkzzFNUcr+HDlqaJ4xJsoY42WMiTXGvGaMeckY85J1/x+NMQnGmCRjzHhjzFeOikWpC3l6WPjfmUPYn1vC0m2d79trvXVFtfZ+N/ps70lGxAYTFewHQN9wf65J7MmSLccpq6q1W5ybrcNGJ/T/tlX3hlExeFiEZe3oNM4truC/+07aLT7VOp2ij0ApZ5g5rCdj47rz7OqDFFd0rs7N1ftOcN3zX7XrBq0TxZV8k1nEtISe522/b3I/SitreefrDDtF2dBRHB7gw4DIgMZtkYG+XDEwgg92ZLV5iO4vl+/mnsUprNmvyaAjaSJQbktE+NV1Qyksr+a5NYedHc55NhxuGInz9Mr9bD/etnsAPrc2C01P6HHe9hG9QhgfH8ZrXx2luvbS76EwxrAxrYAJ/cKwdvc1mpscS15pVeP7aI1jp86w7lA+nhZh4fJdnCqruuQYVetoIlBuLTEmmO+N6cWbm451qjbtzekFjOkbSnSIHz96e0ebPhQ/23uS+Ah/+kcGXrTvgSv6caKkkhe+uPTEl5ZfRn5pVWP/wLm+M7gH3f2929TstmTLcTwtwuvzx1BSUcujH+zWOaE6iCYC5fZ+Pm0Qfl4e/HblPmeHAkBeSSXp+We4akgPXvz+KArLq3no3Z2t6tQuLq9hS3oB04b2tLl/8sAI5o6O5fkvj7DpSOu/rdtydlqJif0vHvXt7WlhbnIsq/edIKuw5VXhKqrreD8lk+mJPZk8MIJfzBjE5/tO8p6OPuoQmgiU2wsP8OGhqwaw9mB+pxhOutk6RcP4fmEkRAfzmzmJbDxSwP99fqjF135x8CS19eaiZqFzPTU7gX4RATy0NJX80vY3v2w6UkBsqB+9unezuf+O8X0REZZsPt7isT5KzaakspY7LusDwF0T45jQL4ynPtnH8YIz7Y5RtY4mAqVo+NCKD/fngbe3M+Ov67nnzRSe/HgvSzYfa7E93R7t7efakl5AoE/DDVoANyf34ntjevHCl0daHFHz2Z6T9AjyYURsSJNlunl78sKtIympqOHh91LbNUlcXb1hc3qBzWahs2JC/JiR0JN3tmZQXt30SCVjDIs3H2dQj0DGxnUHwGIRnp07Ag+L8LOlqS4/L5SzaSJQioamjJdvH83Nyb2ICfEjq7Cc5duzePyjvby0Lq3J163YlcPwpz7jZIn9btTanFbA2LjueFi+7YB9clYCiTFB/GxpapN9GdlFFaw7lM/VQ3tgsYjNMmcN7hnEE9cnsOHwKV5a3/T7O3vcV9en8+7WDA6cKKGu3rA/t4TiihqbzULnuuvyvpRU1rJ8R9PTeezIKGRfbgl3TOhzXqdzdIgfv52TyI6MIu5bsp3i8s41ssuVeDo7AKU6iwE9Avn17MTzts1/YyuLNh3j3knx+Hl7nLevrt7wl88PUVlTz47jhVwzLOqSY8gtruBYQTnftzaRnOXr5cHLtycz6/mvWLAkhQ9/NJEgX6/G/QVlVdz+z6/x9BDmT+jbqnPNG9uLjWmn+PPqQ4T5e5MQHUyv0G4Ed/OiqraOz/edZOm2TL46copz+2y7eXsQHuADwPj4pmsEAKN6hzIiNpg3Nh7ltrG9bSaoxZuPE+jjyZykmIv2zU6Koai8ht+u3Me1z2/gH7eNYvgFtZ30/DL25JRw3bCoFhOgsk0TgVLNeGBKP255ZQvvb8/kjvF9z9v3nz0nSM9vaL/enV1sl0Rwdgrny2x8wMaE+PGP20Zx2z+/5mfvpvLqHclYLEJpZQ0/eGMrOcUVLLl7nM3RQraICL+/cRj7c0tYuHx34/ZAX08EKKmsJSbEj598ZwA3jY6lpq6e1MyixkdiTE8ig3xbPMedE+P46dJU1h3OZ+qgyPP255dWsWp3LreN64O/j+2Pox9M6Mvw2GB+9PYObnpxM49fP5Trh0exYlcuy3dksTOjCIBuXh5cNbTpvhHVNOlqw7OSk5NNSkqKs8NQbsIYw40vbiK/tIq1/3MFnh6Wxu0zn/uKqto6vD0sRAb5sviusZd8vl8s+4bP9p5k5+NXN/ntdvHmY/zqo708OLU/D36nP/Pf2ErKsUJevSOZqYMjbb6mOZU1dRzJKyPzdDlZhRVkFpZTVVPPtcOjmNg//Lwmqvaorq3n8j9+waCegSy5e9x5+1744jDPrj7Emp9PoV9EQBNHaFB4prohoRzKx8Mi1NUbBvYI4LujYnlpXRoT+4fzwq2jLilWVyYi240xybb2aY1AqWaICPdP6cd9S7azcncus63NF18cyGN/bgnPzh3B1qMFrNmfhzHmohur2mpzekP/QHNNHLdf1oe92SW88OUR1h7KY29OCX+9JaldSQAamp0SY4JJjAlub9jN8va0cMf4Pjy7+hCHT5YyoEcglTV1LN2WyasbjnJ5//AWkwBAqL83b8wfw+LNx8gprmTWiGgSooMQETILy1m2PYuyqloCmqhZqKZpZ7FSLbh6SA/6Rfjz0rp0jDEYY3j+iyPEhvoxOymaxJhgCs5Uk1t8aR3GWYXlZJ6uaLHdXUT49ZwERvYOYU92CU9en9CYoDqreWN74+1p4R9r0/j7l0e4/I9f8MTHexkQGcAT1w9t9XEsFmH+xDj+d+YQEmOCGxPvnKQYKmvq+WzPCUe9BZemqVOpFlgswn2T+/GL5btYf/gUnhYhNbOI385JxMvD0vhNek92MdEhfu0+z9kV08Y3MyTzLB9PDxbdOZYDuSWMayFxdAZhAT7ckBTDUusNYlMGRvCjqf0bh4teqtF9QokN9ePD1Gy+OzrWLsd0J5oIlGqF2SOj+cvnh3hpbRoGQ4+ghjn+AYb0DMIiDYngwone2mJzWgGh3bwY1KN1nb3Bfl5dIgmc9dBVAwjw9eSGkTF2b4YSEWYnRfPi2jTySiuJDGy+E1udT5uGlGoFH08P7r48js3pBWxJP829k+Lx9WoYTurn7cGAyED25JS0+/jGGLakFzAuLsxlh0BGh/jx+HVDHdYXMScphnoDK77R1dHaShOBUq00b1xvgnw96e7vza3jep+3LyEmiN3Zxe0+dlZhBdlFFa1qFlK2DegRyNCoID5sxVrUhWeqWb33BKW6tjKgTUNKtVqAjycv3DoKT4vQzfv8/zrDYoL5YEc2eSWVLY6tt+XsAi+aCC7NnJHR/G7VAdLzy4g/ZySSMYZDJ8tYc+AkX+zPY0dGIfWmoW9hyd1jL/p9uhutESjVBpMHRpy3GtdZZ5s72lsr2JR2ijB/7/MWeFFtN2tEDCLwYWpO47a8kkrufjOF6X9dz5/+c5DK2joenNqfJ64fys6MQh54a4fd54vqatw7DSplJ0OjghCBPdklXDmkbXe3VtbUsWZ/HtMSel7yfQjurmewL5fFhfFRajY/u2oAq3af4P99uJuK6joWzhjMDSNj6Bn8bY3Nz8uDX36wm4ffS+Vv3xt5yTfPdVWaCJSyA38fT+LD/dtVI1izP4/SqlpuHNW57wXoKuaMjGbh8t3c/tpWvjpyihGxwfz55iT626htfW9sb4oqavjDpwcI9vPit3MSz0vGdfXGLZKDJgKl7GRYTDBfHz3d5tf9e2c2PYJ8bM4vpNpuRmIUj3+0ly3pBfzsqoH8aGq/xqlBbLl/Sj8Ky6t5eV06afll1NdDXmkl+aVVVNfVc8+keB66ckDjKDFXpIlAKTtJjAnmw9QcTpVVNc7O2ZLTZ6pZezCPOyf2dYtvnh0h2M+LN+8cS0g3L4ZEBbXqNb+cMRiAz/edJDzAh8SYYCIDfckvq+LFtWl8vu8kf7ppOKN6hzoydKfRRKCUnZx7h/EVg1o378/K3bnU1hvmjNRmIXtq6+grEeHRa4bw6DVDLtp30+hYHl2+i5te3MTdl8dxz6R4Qrt54+3pOmNtNBEoZSdDoxu+fbYlEXy0M5uBPQIY2spvrqrjTRkYwWc/m8wfPj3AqxuO8uqGo0DDcOKQbl4MiAzg5duTu3Ri0ESglJ0E+XoRF+7PnuzW3WGcUVBOyvFCfjFjkI4W6uQCfb14+oZhzE3uxe7sYgrPVFNYXk3m6XL+uz+PDYfz2zxarDPRRKCUHSVEBzUulNKSj6x3wHb2mUPVt5J6hZDUK6TxeXVtPWOe/i8rd+V26UTQdesySnVCw2KCyS6qoPBMdbPljDH8OzWbcXHdibmEGUuVc3l7Wpie0IPV+05SWVPn7HDaTROBUnbU2GGc0/z9BLuzi0nPP8MN2knc5V03PJqyqlrWHcp3dijtpolAKTtKjG5IBOtb+FD4985svD0sdlnnWDnXhH5hhHbzYsWurjvrqSYCpewouJsXMxJ68uqGozz+4R6bc9jklVbyyTe5XDkkkmA/LydEqezJ08PCjMQo1uw/SUV112we0kSglJ29cOtIFkyOZ8mW49z2zy3kl1YBUFJZw7OfHWTKn9ZSVF7N7eP7ODlSZS/XD4+ivLqOLw/mOTuUdtFRQ0rZmaeHhf+dOYSE6CAWLt/F9c9/xc1jerF48zGKymu4fkQ0P796IH3D/Z0dqrKTcfFhhAf4sGJXDjO7YHOfJgKlHGR2Ugz9IwNYsHg7z605zOSBEfxi+iCHrdClnMfDIswc1pP3UjI5U1WLv0/X+mjtWtEq1cUkRAez6qFJZBSUMyxWE4Aru3ZYFIs3H2fNgTxmjYh2djhton0ESjlYsJ+XJgE3MKZvd3oE+bDim5yWC3cymgiUUsoOLBZh5rAo1h7K73JrIWvTkFJK2cl1w6N4Y+MxZr+wER8vD+rrDXXGMLp3KL+/cRiWVk41boyhsLyG7v7eDo64gdYIlFLKTkb2CuX2y/oQF+5PbKgfceH+RAX7sjQlk3e3Zbb6OO9vz+Ky360hp6jCgdF+y2E1AhF5HbgOyDPGJNrYfxuwEBCgFHjAGPONo+JRSilHs1iE38w5/+POGMO8V7fw+0/3c9XQSCIDfZt49beWbD5OdV09W9ILuHFUrKPCbeTIGsEiYEYz+48CU4wxw4DfAK84MBallHIKEeHpG4ZRVVPPrz/Z12L5PdnFjWtfbzvW9qVP28NhicAYsx5o8l0YYzYZYwqtT7cAjk97SinlBP0iAnjwO/1ZsSuXLw80f/fx0m2Z+HhaGN0nlK3tWAO7PTpLH8HdwKfODkIppRzl/in96B8ZwGMf7qG8utZmmYrqOj5MzWbmsCiuHBJJWv4ZCsqqHB6b0xOBiEylIREsbKbMAhFJEZGU/PyuO9WrUsp9eXta+P2Nw8guquD/Pj9ks8yne3IprazlljG9GNu3OwApxwttlrUnpyYCERkO/BOYbYwpaKqcMeYVY0yyMSY5IiKi4wJUSik7GtO3O/PG9ua1r47abP9/d2smceH+jIvrzrDYYLw9LWzrgOYhpyUCEekNfADcboyxnR6VUsrF/PKawfQJ8+eeN1M4klfauD0tv4ytx05zy5heiAg+nh4kxYZ0SIexwxKBiLwDbAYGiUiWiNwtIveLyP3WIr8CwoB/iEiqiKQ4KhallOosgv28WHzXWLw8LPzg9W2cLKkE4L1tmXhahO+eM1x0TFwoe3JKOFNlu0/BXhw5amieMSbKGONljIk1xrxmjHnJGPOSdf89xphQY0yS9ZHsqFiUUqoz6dW9G4vuHENReTU/eH0rp89Us3xHFlcN6UFEoE9juTF9u1NXb9iZUeTQeJzeWayUUu4oMSaYl24fzZG8Mq57bgOnyqq5ZWyv88qM7hOKRWCrg5uHNBEopZSTTBoQwbNzR5BTXEl0sC+TB5w/GCbQ14shUUGkODgR6KRzSinlRHNGxuDr5UGwnxceNialG9O3O0u3ZVJTV4+Xh2O+u2uNQCmlnGxGYk/G9wuzuW9sXHcqaurYY512whE0ESilVCc2xnpjmSOHkWoiUEqpTiwi0Ie4cH+2HnXcHcaaCJRSqpMb0zeUlOOnqa83Djm+JgKllOrkxvTtTlF5DUfyyxxyfE0ESinVyZ3tJ3DUtNSaCJRSqpPrE9aN+Ah/yhw01YTeR6CUUp2ciLDm4SmIXHyfgT1ojUAppboARyUB0ESglFJuTxOBUkq5OU0ESinl5jQRKKWUm9NEoJRSbk4TgVJKuTlNBEop5ebEGMdMYuQoIpIPHG+mSDDQ3MTdTe23tb0128KBU82cz95aen/2PkZryuo1t+8x9Jpf+jVv6+sv9Zq3dZ8zrnkfY0yEzT3GGJd6AK+0Z7+t7a3ZBqR0pvdn72O0pqxec73mne2at/X1l3rN27qvs11zV2wa+qSd+21tb+22jmSP87flGK0pq9fcvsfQa37p52/r6y/1mrd1X6e65l2uaaizEZEUY0yys+NwJ3rNO55e847XkdfcFWsEHe0VZwfghvSadzy95h2vw6651giUUsrNaY1AKaXcnCYCpZRyc5oIlFLKzWkicDAR8ReRFBG5ztmxuAMRGSIiL4nIMhF5wNnxuAMRmSMir4rIUhGZ5ux43IGIxIvIayKyzB7H00TQBBF5XUTyRGTPBdtniMhBETkiIr9sxaEWAu85JkrXYo9rbozZb4y5H7gZmOjIeF2Bna75h8aYe4H7gVscGa8rsNM1TzfG3G23mHTUkG0iMhkoAxYbYxKt2zyAQ8DVQBawDZgHeAC/v+AQdwEjgDDAFzhljFnRMdF3Tfa45saYPBGZBTwALDHG/Kuj4u+K7HXNra/7M/C2MWZHB4XfJdn5mi8zxtx0qTHp4vVNMMasF5G+F2weCxwxxqQDiMi7wGxjzO+Bi5p+ROQKwB8YClSIyCpjTL0j4+7K7HHNrcf5GPhYRFYCmgiaYae/cwH+AHyqSaBl9vo7tydNBG0TA2Se8zwLGNdUYWPM/wMQkfk01Ag0CbRdm665NfneCPgAqxwZmAtr0zUHfgxcBQSLSH9jzEuODM5FtfXvPAx4GhgpIo9aE0a7aSLoAMaYRc6OwV0YY9YCa50chlsxxjwHPOfsONyJMaaAhj4Zu9DO4rbJBnqd8zzWuk05jl7zjqfXvOM59ZprImibbcAAEYkTEW/ge8DHTo7J1ek173h6zTueU6+5JoImiMg7wGZgkIhkicjdxpha4EHgM2A/8J4xZq8z43Qles07nl7zjtcZr7kOH1VKKTenNQKllHJzmgiUUsrNaSJQSik3p4lAKaXcnCYCpZRyc5oIlFLKzWkiUC5DRMo6+HybOvh8ISLyw448p3IPmgiUaoKINDsXlzFmQgefMwTQRKDsThOBcmki0k9E/iMi20Vkg4gMtm6/XkS+FpGdIvJfEelh3f6kiCwRkY3AEuvz10VkrYiki8hPzjl2mfXfK6z7l4nIARF52zo1MyIy07ptu4g8JyIXrUkhIvNF5GMR+QJYIyIBIrJGRHaIyG4RmW0t+gegn4ikisgz1tc+IiLbRGSXiDzlyGupXJgxRh/6cIkHUGZj2xpggPXnccAX1p9D+fbO+nuAP1t/fhLYDvid83wTDdNahwMFgNe55wOuAIppmCjMQsP0AZfTsCBRJhBnLfcOsMJGjPNpmHa4u/W5JxBk/TkcOAII0BfYc87rpgGvWPdZgBXAZGf/HvTR9R46DbVyWSISAEwA3rd+QYeGD3Ro+NBeKiJRgDdw9JyXfmyMqTjn+UpjTBVQJSJ5QA8aPrjPtdUYk2U9byoNH9plQLox5uyx3wEWNBHu58aY02dDB35nXcmqnoa56nvYeM0062On9XkAMABY38Q5lLJJE4FyZRagyBiTZGPf88BfjDEfWxezefKcfWcuKFt1zs912P5/05oyzTn3nLcBEcBoY0yNiByjoXZxIQF+b4x5uY3nUuo82kegXJYxpgQ4KiJzoWFJRREZYd0dzLfzvf/AQSEcBOLPWZawtQu7BwN51iQwFehj3V4KBJ5T7jPgLmvNBxGJEZHISw9buRutEShX0k1Ezm2y+QsN365fFJHHAC/gXeAbGmoA74tIIfAFEGfvYIwxFdbhnv8RkTM0zDnfGm8Dn4jIbiAFOGA9XoGIbBSRPTSsD/yIiAwBNlubvsqA7wN59n4vyrXpNNRKOZCIBBhjyqyjiP4OHDbG/J+z41LqXNo0pJRj3WvtPN5LQ5OPtuerTkdrBEop5ea0RqCUUm5OE4FSSrk5TQRKKeXmNBEopZSb00SglFJuThOBUkq5uf8PvtUEgMTfb3gAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(<AxesSubplot:xlabel='Learning rate', ylabel='Loss'>, 0.00038244348724062984)"},"metadata":{}}]},{"cell_type":"code","source":"n_splits = 5\nn_repeats = 1\ngroup_count = 10\n\ncv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n                           group_count = group_count, random_state = 0, strategy = 'quantile')\n\ndf = df[['text', 'target']]\n\nepochs = 30\nn_epochs_stop = 10\nepochs_no_improve = 0\ntraining_stats = []\ni = 1\neval_losses = []\nfor train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n    print('======== Fold {:}  ========'.format(i))\n    train_data = df.loc[train_idx]\n    test_data = df.loc[test_idx]\n    \n    train_set = TokenDataset(tokenizer,\n                            text = train_data['text'].values,\n                            target = train_data['target'].values\n                           )\n    \n    test_set = TokenDataset(tokenizer,\n                           text = test_data['text'].values,\n                           target = test_data['target'].values\n                          )\n\n    train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n\n    test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = False, num_workers=8)\n    \n    model = RobertaForSequenceRegression().to(device)\n#     optimizer = AdamW(model.parameters(),\n#                       lr = 2e-5,\n#                       weight_decay = 0.01\n#                      )\n    optimizer = SGD(model.parameters(), lr=3.82e-4, momentum=0.9)\n#     total_steps = (len(train_dataloader) * epochs) \n#     scheduler = CosineAnnealingWarmRestarts(optimizer, T_0 = 10, T_mult = 1)\n#     scheduler = OneCycleLR(optimizer, max_lr=2e-5, steps_per_epoch=len(train_dataloader), epochs=epochs)\n    iters = len(train_dataloader)\n#     scheduler = get_linear_schedule_with_warmup(optimizer, \n#                                             num_warmup_steps = 0,\n#                                             num_training_steps = total_steps)\n#     scheduler = get_cosine_schedule_with_warmup(optimizer,\n#                                                 num_warmup_steps=0, \n#                                                 num_training_steps= total_steps)\n    iter_eval_loss = []\n    min_eval_loss = np.Inf\n    for epoch_i in range(0, epochs):\n        print(\"\")\n        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n        t0 = time.time()\n        # training\n        model.train()\n        tr_loss = []\n        for step, batch in enumerate(train_dataloader):\n            ids = batch['ids'].to(device, dtype=torch.long)\n            input_mask = batch['mask'].to(device, dtype=torch.long)\n            target = batch['targets'].to(device, dtype=torch.float)\n            optimizer.zero_grad()\n            with autocast():\n                output = model(ids, input_mask)\n                loss = RMSELoss(output, target)\n                tr_loss.append(loss.cpu().detach().numpy().tolist())\n\n            loss.backward()\n            optimizer.step()\n#             scheduler.step(epoch_i + step/ iters)\n        \n        torch.cuda.empty_cache()\n        train_losses = np.mean(tr_loss)  \n        training_time = format_time(time.time() - t0)\n        writer.add_scalar(f\"Loss/train_fold_{i}\", train_losses, epoch_i)\n        print(\"Train loss: \", train_losses)\n        print(\"Training epcoh took: {:}\".format(training_time))\n        \n        # evaluation\n        t0 = time.time()\n        all_targets, all_preds = [], []\n        model.eval()   \n        eval_loss = []\n        \n        # disable gradients \n        with torch.no_grad(): \n            for batch in test_dataloader:\n                ids = batch['ids'].to(device, dtype=torch.long)\n                input_mask = batch['mask'].to(device, dtype=torch.long)\n                target = batch['targets'].to(device, dtype=torch.float)\n                output = model(ids, input_mask)\n                loss = RMSELoss(output, target)\n                eval_loss.append(loss.cpu().detach().numpy().tolist())\n            \n        epoch_eval_loss = np.mean(eval_loss)\n        eval_time = format_time(time.time() - t0)\n        writer.add_scalar(f\"Loss/eval_fold_{i}\", epoch_eval_loss, epoch_i)\n        print(\"Eval loss: \", epoch_eval_loss)\n        print(\"Evaluation took: {:}\".format(eval_time))\n        \n        # recording all statistics from this epoch\n        training_stats.append({\n            'fold' : i,\n            'epoch': epoch_i + 1,\n            'Training Loss': train_losses,\n            'Eval Loss': epoch_eval_loss,\n            'Training Time': training_time,\n            'Eval Time': eval_time\n        })\n        \n        # early stopping and saving best model\n        if epoch_eval_loss < min_eval_loss:\n            epochs_no_improve = 0\n            min_eval_loss = epoch_eval_loss\n            best_model = copy.deepcopy(model)\n            PATH = f'model_fold_{i}_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.pt'\n        else:\n            epochs_no_improve += 1\n#         if epochs_no_improve >= n_epochs_stop:\n#             print('Early stopping! Epoch {:}'.format(epoch_i + 1) )\n#             break\n#         else:\n#             continue\n    \n    torch.save(best_model.state_dict(), PATH)    \n    i += 1    \n    torch.cuda.empty_cache()\nwriter.flush()\nwriter.close()","metadata":{"_uuid":"163bad85-f736-456f-b0ed-8c75cce84146","_cell_guid":"3569fa32-c022-49f6-b6fe-f9ddc75c3dfe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-04T14:47:10.543180Z","iopub.execute_input":"2021-07-04T14:47:10.543558Z","iopub.status.idle":"2021-07-04T15:31:09.387021Z","shell.execute_reply.started":"2021-07-04T14:47:10.543514Z","shell.execute_reply":"2021-07-04T15:31:09.385651Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"======== Fold 1  ========\n\n======== Epoch 1 / 30 ========\nTrain loss:  1.056304543370932\nTraining epcoh took: 0:01:20\nEval loss:  0.8699180798398124\nEvaluation took: 0:00:07\n\n======== Epoch 2 / 30 ========\nTrain loss:  0.7214763126742672\nTraining epcoh took: 0:01:20\nEval loss:  0.6790545160571734\nEvaluation took: 0:00:07\n\n======== Epoch 3 / 30 ========\nTrain loss:  0.6694185060094779\nTraining epcoh took: 0:01:20\nEval loss:  0.5779657289385796\nEvaluation took: 0:00:07\n\n======== Epoch 4 / 30 ========\nTrain loss:  0.6151235342865259\nTraining epcoh took: 0:01:20\nEval loss:  0.5816126192609469\nEvaluation took: 0:00:07\n\n======== Epoch 5 / 30 ========\nTrain loss:  0.5620421374767599\nTraining epcoh took: 0:01:20\nEval loss:  0.6769032817747858\nEvaluation took: 0:00:07\n\n======== Epoch 6 / 30 ========\nTrain loss:  0.5384575628059011\nTraining epcoh took: 0:01:20\nEval loss:  0.6744037634796567\nEvaluation took: 0:00:07\n\n======== Epoch 7 / 30 ========\nTrain loss:  0.5166100406310927\nTraining epcoh took: 0:01:20\nEval loss:  0.596802779369884\nEvaluation took: 0:00:07\n\n======== Epoch 8 / 30 ========\nTrain loss:  0.49042787161511436\nTraining epcoh took: 0:01:20\nEval loss:  0.6967563488417201\nEvaluation took: 0:00:07\n\n======== Epoch 9 / 30 ========\nTrain loss:  0.48287429146363703\nTraining epcoh took: 0:01:20\nEval loss:  0.7125738345914416\nEvaluation took: 0:00:07\n\n======== Epoch 10 / 30 ========\nTrain loss:  0.44470422620504674\nTraining epcoh took: 0:01:20\nEval loss:  0.6763277500867844\nEvaluation took: 0:00:07\n\n======== Epoch 11 / 30 ========\nTrain loss:  0.4303189606313974\nTraining epcoh took: 0:01:20\nEval loss:  0.5887925095028348\nEvaluation took: 0:00:07\n\n======== Epoch 12 / 30 ========\nTrain loss:  0.4161481584461642\nTraining epcoh took: 0:01:20\nEval loss:  0.6144399601552222\nEvaluation took: 0:00:07\n\n======== Epoch 13 / 30 ========\nTrain loss:  0.4061630224468003\nTraining epcoh took: 0:01:20\nEval loss:  0.5486519088347753\nEvaluation took: 0:00:07\n\n======== Epoch 14 / 30 ========\nTrain loss:  0.3847464690325965\nTraining epcoh took: 0:01:20\nEval loss:  0.62793753710058\nEvaluation took: 0:00:07\n\n======== Epoch 15 / 30 ========\nTrain loss:  0.3512870020849604\nTraining epcoh took: 0:01:20\nEval loss:  0.6885620322492387\nEvaluation took: 0:00:07\n\n======== Epoch 16 / 30 ========\nTrain loss:  0.34083143023537915\nTraining epcoh took: 0:01:20\nEval loss:  0.6638166705767313\nEvaluation took: 0:00:07\n\n======== Epoch 17 / 30 ========\nTrain loss:  0.3074139668278291\nTraining epcoh took: 0:01:20\nEval loss:  0.6293103107147746\nEvaluation took: 0:00:07\n\n======== Epoch 18 / 30 ========\nTrain loss:  0.31258792692506815\nTraining epcoh took: 0:01:20\nEval loss:  0.6922698724601004\nEvaluation took: 0:00:07\n\n======== Epoch 19 / 30 ========\nTrain loss:  0.2958476731265095\nTraining epcoh took: 0:01:20\nEval loss:  0.6356978962818781\nEvaluation took: 0:00:07\n\n======== Epoch 20 / 30 ========\nTrain loss:  0.2899365475479986\nTraining epcoh took: 0:01:20\nEval loss:  0.6761815489994155\nEvaluation took: 0:00:07\n\n======== Epoch 21 / 30 ========\nTrain loss:  0.28332345439514645\nTraining epcoh took: 0:01:20\nEval loss:  0.7409509387281206\nEvaluation took: 0:00:07\n\n======== Epoch 22 / 30 ========\nTrain loss:  0.281853162171975\nTraining epcoh took: 0:01:20\nEval loss:  0.7018230118685298\nEvaluation took: 0:00:07\n\n======== Epoch 23 / 30 ========\nTrain loss:  0.2602769508957863\nTraining epcoh took: 0:01:20\nEval loss:  0.6768529208170043\nEvaluation took: 0:00:07\n\n======== Epoch 24 / 30 ========\nTrain loss:  0.24623973929966\nTraining epcoh took: 0:01:20\nEval loss:  0.5935472415553199\nEvaluation took: 0:00:07\n\n======== Epoch 25 / 30 ========\nTrain loss:  0.23529637751864715\nTraining epcoh took: 0:01:20\nEval loss:  0.639545319808854\nEvaluation took: 0:00:07\n\n======== Epoch 26 / 30 ========\nTrain loss:  0.23344389674529223\nTraining epcoh took: 0:01:20\nEval loss:  0.6372308275765843\nEvaluation took: 0:00:07\n\n======== Epoch 27 / 30 ========\nTrain loss:  0.2373607566868755\nTraining epcoh took: 0:01:20\nEval loss:  0.6568031965030564\nEvaluation took: 0:00:07\n\n======== Epoch 28 / 30 ========\nTrain loss:  0.21355141321538199\nTraining epcoh took: 0:01:20\nEval loss:  0.6406518701050017\nEvaluation took: 0:00:07\n\n======== Epoch 29 / 30 ========\nTrain loss:  0.19806496757017056\nTraining epcoh took: 0:01:20\nEval loss:  0.6060608120428191\nEvaluation took: 0:00:07\n\n======== Epoch 30 / 30 ========\nTrain loss:  0.20770666239337182\nTraining epcoh took: 0:01:20\nEval loss:  0.601772709025277\nEvaluation took: 0:00:07\n======== Fold 2  ========\n\n======== Epoch 1 / 30 ========\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-5d85f37cb980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#             scheduler.step(epoch_i + step/ iters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Create a DataFrame from our training statistics.\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'fold' as the row index.\n# df_stats = df_stats.set_index('fold')\ndf_stats","metadata":{"_uuid":"242393f2-f3f2-42b0-a7bc-6a547876da9a","_cell_guid":"d851b70c-8a9e-4b62-9720-9af838753bc9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 15))\nfor fold in df_stats.fold.unique():\n    ax = fig.add_subplot(5,1,fold)\n    max_epoch = df_stats[df_stats['fold']==fold]['epoch'].max()\n    x = np.arange(max_epoch)\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Training Loss']])\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Eval Loss']])\n    plt.xticks(range(0, max_epoch, 5))","metadata":{"_uuid":"902da3b7-7d86-4716-b68d-07ca03ce50d4","_cell_guid":"9ad36d53-cc01-451e-bdf1-c6ad6f45b4ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_splits = 5\n# n_repeats = 2\n# group_count = 10\n# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n\n# for train_index, test_index in cv.split(input_ids, targets):\n#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n#     train_targets, test_targets = targets[train_index], targets[test_index]\n#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]","metadata":{"_uuid":"5f8bd137-286f-4f52-9877-0151412dc1d2","_cell_guid":"c003fc35-13d4-4158-a277-63a3cb776fde","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n# test_inputs = torch.tensor(test_inputs, dtype=torch.long)\n# train_targets = torch.tensor(train_targets, dtype=torch.float)\n# test_targets = torch.tensor(test_targets, dtype=torch.float)\n# train_masks = torch.tensor(train_masks, dtype=torch.long)\n# test_masks = torch.tensor(test_masks, dtype=torch.long)\n# train_type_ids = torch.tensor(train_type_ids, dtype=torch.long)\n# test_type_ids = torch.tensor(test_type_ids, dtype=torch.long)","metadata":{"_uuid":"c254bfbe-430f-4d0f-9606-239cc9d6e9e1","_cell_guid":"3f524936-43f8-4b10-aa49-e3e721261840","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data = TensorDataset(train_inputs, train_masks, train_type_ids, train_targets)\n# train_sampler = RandomSampler(train_data)\n# train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = BATCH_SIZE)\n\n# test_data = TensorDataset(test_inputs, test_masks, test_type_ids, test_targets)\n# test_sampler = RandomSampler(test_data)\n# test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = BATCH_SIZE)","metadata":{"_uuid":"e30d268e-2046-4a55-98cd-9dce31bb6366","_cell_guid":"55255cf8-436d-461a-83fe-1ace1194257d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set_trainable(model, True)\n# set_trainable(model.bert.embeddings, True)    \n# set_trainable(model.bert.encoder, True)","metadata":{"_uuid":"59d149e4-6cb9-49a0-a50e-4801b51cf9bf","_cell_guid":"723d1ff0-e469-4e20-92b7-2eca47b3a49e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epochs = 5\n# optimizer = AdamW(model.parameters(),\n#                   lr = 5e-6,\n#                   eps = 1e-6 \n#                 )\n# total_steps = len(train_dataloader) * epochs\n# scheduler = get_linear_schedule_with_warmup(optimizer, \n#                                             num_warmup_steps = 0,\n#                                             num_training_steps = total_steps)\n# eval_losses = []\n# for epoch_i in range(0, epochs):\n#     print(\"\")\n#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n#     # training\n#     model.train()\n#     tr_loss = []\n    \n#     for step, batch in enumerate(train_dataloader):\n#         batch = tuple(t.to(device) for t in batch)\n#         ids, input_mask, type_ids, target = batch\n#         output = model(ids, input_mask, type_ids, target)\n#         loss = RMSELoss(output, target)\n#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n#         loss.backward()  \n#         optimizer.step()\n#         optimizer.zero_grad()  \n#         scheduler.step()\n            \n#     train_losses = np.mean(tr_loss)  \n#     print(\"Train loss: \", train_losses)\n#     all_targets, all_preds = [], []\n#     model.eval()   \n#     eval_loss = []\n#     # evaluation\n#     # disable gradients \n#     with torch.no_grad(): \n#         for batch in test_dataloader:\n#             batch = tuple(t.to(device) for t in batch)\n#             ids, input_mask, type_ids, target = batch\n#             output = model(ids, input_mask, type_ids, target)\n#             loss = RMSELoss(output, target)\n#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n            \n#     epoch_eval_loss = np.mean(eval_loss)\n#     print(\"Eval loss: \", epoch_eval_loss)\n\n#     eval_losses.append(epoch_eval_loss)   \n# torch.cuda.empty_cache()\n# mean_eval_loss = np.mean(eval_losses)\n# print(mean_eval_loss)","metadata":{"_uuid":"e00d869d-c1b5-491c-9fd9-da562f67ac4e","_cell_guid":"676a670c-02dd-4914-a4df-26fef294717b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"_uuid":"ba1b3151-aff7-4da9-8163-729658471e12","_cell_guid":"7fe96e02-5bff-4399-bc9d-8e33d2b1788f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))","metadata":{"_uuid":"ac750cde-13ca-40b8-ae0b-1134093a71b1","_cell_guid":"9c69b185-47d9-4fd3-98fd-d744ca80bd3e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# excerpts = test.text.values","metadata":{"_uuid":"59fd4308-2cc9-4400-b685-72aa5efe276a","_cell_guid":"0ba4c7b2-3563-4014-ab9d-f04600c8e975","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # convert sentences into tokens\n# input_ids = [tokenizer.encode(excerpt, add_special_tokens = True, max_length = MAX_LENGTH,\n#                               padding='max_length') for excerpt in excerpts]\n\n# input_ids = np.array(input_ids)\n# attention_masks = []\n# # create a mask of 1 for all input tokens and 0 for all padding tokens\n# attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n# attention_masks = np.array(attention_masks)\n# # create token type ids\n# token_type_ids = [[0 for i in seq] for seq in input_ids]\n# token_type_ids = np.array(token_type_ids)","metadata":{"_uuid":"5bb54ba8-2995-4390-8069-ad5333a526ea","_cell_guid":"31a89ebf-81b4-48e6-922f-fbd851d787c3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_ids = torch.tensor(input_ids, dtype=torch.long)\n# attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n# token_type_ids = torch.tensor(token_type_ids, dtype=torch.long)","metadata":{"_uuid":"571d84c0-3bf6-4317-9bed-5e8a6aca2e15","_cell_guid":"1d50e596-a80c-460d-91ac-b4e76852c5a6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction_data = TensorDataset(input_ids, attention_masks, token_type_ids)\n# prediction_sampler = SequentialSampler(prediction_data)\n# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=BATCH_SIZE)","metadata":{"_uuid":"d44b5f79-bb95-4ecc-aef0-3d539a019cb3","_cell_guid":"d9d98d5f-0899-4180-9e30-e230cc029130","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.eval()   \n# predictions , true_labels = [], []\n# # evaluation\n# for batch in prediction_dataloader:\n#     # disable gradients \n#     batch = tuple(t.to(device) for t in batch)\n#     ids, input_mask, type_ids = batch\n#     with torch.no_grad():    \n#         output = model(ids, input_mask, type_ids) \n#     output = output.cpu().detach().numpy().tolist()\n#     predictions += output","metadata":{"_uuid":"5353fa59-9bd4-43ef-84a3-c564fd042a77","_cell_guid":"69c06869-3b98-4509-8f21-3f7e4fa97fb8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id':test['id'],'target':predictions})","metadata":{"_uuid":"8f0cb4ae-84f3-40e6-bd92-2f13edccfaba","_cell_guid":"b543c4d5-6bfd-4a3b-866a-545b8ec22f83","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv('submission.csv',index=False)","metadata":{"_uuid":"a7b24ae2-9c22-4d15-8b58-f52e7bdad0b5","_cell_guid":"58bdb1ec-27d0-4e77-8600-90ee61f14225","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"_uuid":"070e6a6c-2304-43d7-b97e-a18d4b3b0c2b","_cell_guid":"5452bdab-8b67-4675-8298-31689a85566c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"bfef8cfd-afe4-427b-999e-8eaa167a3972","_cell_guid":"977ed5ac-a426-4e13-8dfe-e2915a93f3c3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}