{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-class",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:21.717436Z",
     "iopub.status.busy": "2021-06-29T14:30:21.715891Z",
     "iopub.status.idle": "2021-06-29T14:30:34.700568Z",
     "shell.execute_reply": "2021-06-29T14:30:34.701315Z",
     "shell.execute_reply.started": "2021-06-29T11:19:32.852938Z"
    },
    "papermill": {
     "duration": 13.017745,
     "end_time": "2021-06-29T14:30:34.701665",
     "exception": false,
     "start_time": "2021-06-29T14:30:21.683920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "import os\n",
    "# os.listdir(\"../input/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.system('pip install pytorch_pretrained_bert --no-index --find-links=\"../input/pytorch-pretrained-bert/pytorch_pretrained_bert\" ')\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "import random\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 356\n",
    "BERT_FP = '../input/bert-base-uncased'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "independent-criminal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:34.775093Z",
     "iopub.status.busy": "2021-06-29T14:30:34.774137Z",
     "iopub.status.idle": "2021-06-29T14:30:34.776523Z",
     "shell.execute_reply": "2021-06-29T14:30:34.775850Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.558514Z"
    },
    "papermill": {
     "duration": 0.042047,
     "end_time": "2021-06-29T14:30:34.776695",
     "exception": false,
     "start_time": "2021-06-29T14:30:34.734648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "horizontal-statistics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:34.831236Z",
     "iopub.status.busy": "2021-06-29T14:30:34.829994Z",
     "iopub.status.idle": "2021-06-29T14:30:34.832738Z",
     "shell.execute_reply": "2021-06-29T14:30:34.832314Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.566924Z"
    },
    "papermill": {
     "duration": 0.029277,
     "end_time": "2021-06-29T14:30:34.832839",
     "exception": false,
     "start_time": "2021-06-29T14:30:34.803562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "\n",
    "\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-moment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:34.881451Z",
     "iopub.status.busy": "2021-06-29T14:30:34.879856Z",
     "iopub.status.idle": "2021-06-29T14:30:34.882402Z",
     "shell.execute_reply": "2021-06-29T14:30:34.882826Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.577548Z"
    },
    "papermill": {
     "duration": 0.029798,
     "end_time": "2021-06-29T14:30:34.882969",
     "exception": false,
     "start_time": "2021-06-29T14:30:34.853171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForSequenceRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForSequenceRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_FP)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, ids,  token_type_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear1(pooled_output)\n",
    "        pooled_output = self.relu(pooled_output)\n",
    "        outputs = self.linear2(pooled_output)\n",
    "        return outputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "martial-combine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:34.927227Z",
     "iopub.status.busy": "2021-06-29T14:30:34.926685Z",
     "iopub.status.idle": "2021-06-29T14:30:34.930555Z",
     "shell.execute_reply": "2021-06-29T14:30:34.930159Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.588976Z"
    },
    "papermill": {
     "duration": 0.027458,
     "end_time": "2021-06-29T14:30:34.930658",
     "exception": false,
     "start_time": "2021-06-29T14:30:34.903200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSELoss(outputs, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "significant-arizona",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:34.977452Z",
     "iopub.status.busy": "2021-06-29T14:30:34.976946Z",
     "iopub.status.idle": "2021-06-29T14:30:35.715611Z",
     "shell.execute_reply": "2021-06-29T14:30:35.715145Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.598337Z"
    },
    "papermill": {
     "duration": 0.765447,
     "end_time": "2021-06-29T14:30:35.715737",
     "exception": false,
     "start_time": "2021-06-29T14:30:34.950290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "class regressor_stratified_cv:\n",
    "    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n",
    "                 random_state = 0, strategy = 'quantile'):\n",
    "        self.group_count = group_count\n",
    "        self.strategy = strategy\n",
    "        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n",
    "                             random_state = random_state)\n",
    "        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n",
    "        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n",
    "                                            strategy = self.strategy)  \n",
    "            \n",
    "    def split(self, X, y, groups = None):\n",
    "        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n",
    "        return self.cv.split(X, kgroups, groups)\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups = None):\n",
    "        return self.cv.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-spirit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:35.759645Z",
     "iopub.status.busy": "2021-06-29T14:30:35.759128Z",
     "iopub.status.idle": "2021-06-29T14:30:35.762914Z",
     "shell.execute_reply": "2021-06-29T14:30:35.762445Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.611382Z"
    },
    "papermill": {
     "duration": 0.027394,
     "end_time": "2021-06-29T14:30:35.763023",
     "exception": false,
     "start_time": "2021-06-29T14:30:35.735629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(excerpt):\n",
    "    \n",
    "    # lower casing\n",
    "    excerpt = excerpt.lower()\n",
    "\n",
    "    # removal of punctuation\n",
    "    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        \n",
    "    # removal of stopwords\n",
    "#     from nltk.corpus import stopwords\n",
    "#     \", \".join(stopwords.words('english'))\n",
    "#     STOPWORDS = set(stopwords.words('english'))\n",
    "#     excerpt = \" \".join([word for word in str(excerpt).split() if word not in STOPWORDS])\n",
    "        \n",
    "    # lemmatization \n",
    "#     from nltk.stem import WordNetLemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     excerpt = \" \".join([lemmatizer.lemmatize(word) for word in excerpt.split()])\n",
    "        \n",
    "                \n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-european",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:35.808127Z",
     "iopub.status.busy": "2021-06-29T14:30:35.807587Z",
     "iopub.status.idle": "2021-06-29T14:30:35.919375Z",
     "shell.execute_reply": "2021-06-29T14:30:35.918890Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.621207Z"
    },
    "papermill": {
     "duration": 0.136879,
     "end_time": "2021-06-29T14:30:35.919493",
     "exception": false,
     "start_time": "2021-06-29T14:30:35.782614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2829  1.711390        0.646900  \n",
       "2830  0.189476        0.535648  \n",
       "2831  0.255209        0.483866  \n",
       "2832 -0.215279        0.514128  \n",
       "2833  0.300779        0.512379  \n",
       "\n",
       "[2834 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "green-spirit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:35.991774Z",
     "iopub.status.busy": "2021-06-29T14:30:35.976272Z",
     "iopub.status.idle": "2021-06-29T14:30:36.045348Z",
     "shell.execute_reply": "2021-06-29T14:30:36.044945Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.675289Z"
    },
    "papermill": {
     "duration": 0.104736,
     "end_time": "2021-06-29T14:30:36.045455",
     "exception": false,
     "start_time": "2021-06-29T14:30:35.940719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opposed-advertiser",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.090484Z",
     "iopub.status.busy": "2021-06-29T14:30:36.089972Z",
     "iopub.status.idle": "2021-06-29T14:30:36.093417Z",
     "shell.execute_reply": "2021-06-29T14:30:36.093782Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.758059Z"
    },
    "papermill": {
     "duration": 0.027713,
     "end_time": "2021-06-29T14:30:36.093919",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.066206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "excerpts = df.text.values\n",
    "targets = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wanted-composition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.137763Z",
     "iopub.status.busy": "2021-06-29T14:30:36.137290Z",
     "iopub.status.idle": "2021-06-29T14:30:36.189717Z",
     "shell.execute_reply": "2021-06-29T14:30:36.189284Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.764340Z"
    },
    "papermill": {
     "duration": 0.075325,
     "end_time": "2021-06-29T14:30:36.189822",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.114497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_FP, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "curious-referral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.238698Z",
     "iopub.status.busy": "2021-06-29T14:30:36.238177Z",
     "iopub.status.idle": "2021-06-29T14:30:36.241129Z",
     "shell.execute_reply": "2021-06-29T14:30:36.240711Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.808321Z"
    },
    "papermill": {
     "duration": 0.031125,
     "end_time": "2021-06-29T14:30:36.241234",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.210109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, target = None, is_test=False):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.max_len = MAX_LENGTH\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.text[idx])\n",
    "        text = ' '.join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "            }\n",
    "        else:    \n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'targets': targets\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sapphire-terrain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.288515Z",
     "iopub.status.busy": "2021-06-29T14:30:36.287390Z",
     "iopub.status.idle": "2021-06-29T14:30:36.290762Z",
     "shell.execute_reply": "2021-06-29T14:30:36.291153Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.820009Z"
    },
    "papermill": {
     "duration": 0.029863,
     "end_time": "2021-06-29T14:30:36.291273",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.261410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "least-carbon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.339381Z",
     "iopub.status.busy": "2021-06-29T14:30:36.338864Z",
     "iopub.status.idle": "2021-06-29T14:30:36.352847Z",
     "shell.execute_reply": "2021-06-29T14:30:36.353395Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.832327Z"
    },
    "papermill": {
     "duration": 0.04216,
     "end_time": "2021-06-29T14:30:36.353518",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.311358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "group_count = 10\n",
    "\n",
    "cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "                           group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "df = df[['text', 'target']]\n",
    "\n",
    "epochs = 10\n",
    "n_epochs_stop = 5\n",
    "epochs_no_improve = 0\n",
    "training_stats = []\n",
    "i = 1\n",
    "eval_losses = []\n",
    "scaler = GradScaler()\n",
    "# input_ids, attention_masks, token_type_ids = encode(excerpts, tokenizer)\n",
    "for train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n",
    "    train_data = df.loc[train_idx]\n",
    "    test_data = df.loc[test_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unauthorized-citizen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.414594Z",
     "iopub.status.busy": "2021-06-29T14:30:36.414063Z",
     "iopub.status.idle": "2021-06-29T14:46:58.371888Z",
     "shell.execute_reply": "2021-06-29T14:46:58.371417Z",
     "shell.execute_reply.started": "2021-06-29T11:20:35.386874Z"
    },
    "papermill": {
     "duration": 981.998312,
     "end_time": "2021-06-29T14:46:58.372034",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.373722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Train loss:  0.6217751968914355\n",
      "Training epcoh took: 0:01:28\n",
      "Eval loss:  0.6429912249247233\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Train loss:  0.5853088409967826\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6688158346547021\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Train loss:  0.5563317386197372\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6497073587444093\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Train loss:  0.5406856457112541\n",
      "Training epcoh took: 0:01:28\n",
      "Eval loss:  0.6295302030113008\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Train loss:  0.5199518711634086\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6283517214987013\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Train loss:  0.5064372164262853\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6311002059115304\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Train loss:  0.4981851770844258\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6574519707096947\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Train loss:  0.4856776091414438\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6317128241062164\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Train loss:  0.48688099501838145\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6502416067653232\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Train loss:  0.47998277905961156\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6502194801966349\n",
      "Evaluation took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "train_set = TokenDataset(tokenizer,\n",
    "                        text = train_data['text'].values,\n",
    "                        target = train_data['target'].values\n",
    "                        )\n",
    "    \n",
    "test_set = TokenDataset(tokenizer,\n",
    "                        text = test_data['text'].values,\n",
    "                        target = test_data['target'].values\n",
    "                        )\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "    \n",
    "model = BertForSequenceRegression().to(device)\n",
    "model.load_state_dict(torch.load('../input/model-2-16-0659/model_fold_2_epoch_16_loss_0.659.pt'))\n",
    "set_trainable(model, True)\n",
    "set_trainable(model.bert.embeddings, True)\n",
    "set_trainable(model.bert.encoder, True)\n",
    "# Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.0}\n",
    "]  \n",
    "optimizer = AdamW(optimizer_parameters,\n",
    "                      lr = 2e-6\n",
    "                     )\n",
    "total_steps = (len(train_dataloader) * epochs)               \n",
    "#     num_steps = int(total_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "iter_eval_loss = []\n",
    "min_eval_loss = np.Inf\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    # training\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        target = batch['targets'].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "\n",
    "        scheduler.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "    train_losses = np.mean(tr_loss)  \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/train_fold_{i}_epoch_{epoch_i+1}\", train_losses, epoch_i)\n",
    "    print(\"Train loss: \", train_losses)\n",
    "    print(\"Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # evaluation\n",
    "    t0 = time.time()\n",
    "    all_targets, all_preds = [], []\n",
    "    model.eval()   \n",
    "    eval_loss = []\n",
    "        \n",
    "    # disable gradients \n",
    "    with torch.no_grad(): \n",
    "        for batch in test_dataloader:\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            target = batch['targets'].to(device, dtype=torch.float)\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "    epoch_eval_loss = np.mean(eval_loss)\n",
    "    eval_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/eval_fold_{i}_epoch_{epoch_i+1}\", epoch_eval_loss, epoch_i)\n",
    "    print(\"Eval loss: \", epoch_eval_loss)\n",
    "    print(\"Evaluation took: {:}\".format(eval_time))\n",
    "        \n",
    "    # recording all statistics from this epoch\n",
    "    training_stats.append({\n",
    "            'fold' : i,\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': train_losses,\n",
    "            'Eval Loss': epoch_eval_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Eval Time': eval_time\n",
    "    })\n",
    "        \n",
    "    # early stopping and saving best model\n",
    "    if epoch_eval_loss < min_eval_loss:\n",
    "        min_eval_loss = epoch_eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        PATH = f'model_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.pt'\n",
    "    \n",
    "torch.save(best_model.state_dict(), PATH)   \n",
    "torch.cuda.empty_cache()\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proved-modem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.427716Z",
     "iopub.status.busy": "2021-06-29T14:46:58.427213Z",
     "iopub.status.idle": "2021-06-29T14:46:58.430987Z",
     "shell.execute_reply": "2021-06-29T14:46:58.430550Z"
    },
    "papermill": {
     "duration": 0.032709,
     "end_time": "2021-06-29T14:46:58.431087",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.398378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# n_repeats = 2\n",
    "# group_count = 10\n",
    "# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "# for train_index, test_index in cv.split(input_ids, targets):\n",
    "#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n",
    "#     train_targets, test_targets = targets[train_index], targets[test_index]\n",
    "#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n",
    "#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "solved-studio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.485811Z",
     "iopub.status.busy": "2021-06-29T14:46:58.485192Z",
     "iopub.status.idle": "2021-06-29T14:46:58.488139Z",
     "shell.execute_reply": "2021-06-29T14:46:58.487666Z"
    },
    "papermill": {
     "duration": 0.031475,
     "end_time": "2021-06-29T14:46:58.488241",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.456766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_trainable(model, True)\n",
    "# set_trainable(model.bert.embeddings, True)    \n",
    "# set_trainable(model.bert.encoder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handmade-letters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.543312Z",
     "iopub.status.busy": "2021-06-29T14:46:58.542630Z",
     "iopub.status.idle": "2021-06-29T14:46:58.545461Z",
     "shell.execute_reply": "2021-06-29T14:46:58.545021Z"
    },
    "papermill": {
     "duration": 0.031828,
     "end_time": "2021-06-29T14:46:58.545556",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.513728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs = 5\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = 5e-6,\n",
    "#                   eps = 1e-6 \n",
    "#                 )\n",
    "# total_steps = len(train_dataloader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps = 0,\n",
    "#                                             num_training_steps = total_steps)\n",
    "# eval_losses = []\n",
    "# for epoch_i in range(0, epochs):\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "#     # training\n",
    "#     model.train()\n",
    "#     tr_loss = []\n",
    "    \n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "#         ids, input_mask, type_ids, target = batch\n",
    "#         output = model(ids, input_mask, type_ids, target)\n",
    "#         loss = RMSELoss(output, target)\n",
    "#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "#         loss.backward()  \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()  \n",
    "#         scheduler.step()\n",
    "            \n",
    "#     train_losses = np.mean(tr_loss)  \n",
    "#     print(\"Train loss: \", train_losses)\n",
    "#     all_targets, all_preds = [], []\n",
    "#     model.eval()   \n",
    "#     eval_loss = []\n",
    "#     # evaluation\n",
    "#     # disable gradients \n",
    "#     with torch.no_grad(): \n",
    "#         for batch in test_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             ids, input_mask, type_ids, target = batch\n",
    "#             output = model(ids, input_mask, type_ids, target)\n",
    "#             loss = RMSELoss(output, target)\n",
    "#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "#     epoch_eval_loss = np.mean(eval_loss)\n",
    "#     print(\"Eval loss: \", epoch_eval_loss)\n",
    "\n",
    "#     eval_losses.append(epoch_eval_loss)   \n",
    "# torch.cuda.empty_cache()\n",
    "# mean_eval_loss = np.mean(eval_losses)\n",
    "# print(mean_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parental-postcard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.600707Z",
     "iopub.status.busy": "2021-06-29T14:46:58.599925Z",
     "iopub.status.idle": "2021-06-29T14:46:58.602667Z",
     "shell.execute_reply": "2021-06-29T14:46:58.602258Z"
    },
    "papermill": {
     "duration": 0.031153,
     "end_time": "2021-06-29T14:46:58.602762",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.571609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "protecting-soundtrack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.657633Z",
     "iopub.status.busy": "2021-06-29T14:46:58.656867Z",
     "iopub.status.idle": "2021-06-29T14:46:58.659499Z",
     "shell.execute_reply": "2021-06-29T14:46:58.659089Z"
    },
    "papermill": {
     "duration": 0.03128,
     "end_time": "2021-06-29T14:46:58.659601",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.628321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "increased-caution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.714668Z",
     "iopub.status.busy": "2021-06-29T14:46:58.713977Z",
     "iopub.status.idle": "2021-06-29T14:46:58.716602Z",
     "shell.execute_reply": "2021-06-29T14:46:58.716199Z"
    },
    "papermill": {
     "duration": 0.03095,
     "end_time": "2021-06-29T14:46:58.716696",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.685746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excerpts = test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impressed-incentive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.771452Z",
     "iopub.status.busy": "2021-06-29T14:46:58.770718Z",
     "iopub.status.idle": "2021-06-29T14:46:58.773274Z",
     "shell.execute_reply": "2021-06-29T14:46:58.772773Z"
    },
    "papermill": {
     "duration": 0.030864,
     "end_time": "2021-06-29T14:46:58.773369",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.742505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "similar-thread",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.828797Z",
     "iopub.status.busy": "2021-06-29T14:46:58.828151Z",
     "iopub.status.idle": "2021-06-29T14:46:58.830840Z",
     "shell.execute_reply": "2021-06-29T14:46:58.830374Z"
    },
    "papermill": {
     "duration": 0.031159,
     "end_time": "2021-06-29T14:46:58.830974",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.799815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_set = TokenDataset(tokenizer,\n",
    "#                         text = test_data['text'].values, is_test = True\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "precious-anniversary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.885979Z",
     "iopub.status.busy": "2021-06-29T14:46:58.885304Z",
     "iopub.status.idle": "2021-06-29T14:46:58.887837Z",
     "shell.execute_reply": "2021-06-29T14:46:58.887431Z"
    },
    "papermill": {
     "duration": 0.030983,
     "end_time": "2021-06-29T14:46:58.887952",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.856969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "convertible-steam",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:58.943009Z",
     "iopub.status.busy": "2021-06-29T14:46:58.942327Z",
     "iopub.status.idle": "2021-06-29T14:46:58.945164Z",
     "shell.execute_reply": "2021-06-29T14:46:58.944692Z"
    },
    "papermill": {
     "duration": 0.031602,
     "end_time": "2021-06-29T14:46:58.945268",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.913666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BertForSequenceRegression().to(device)\n",
    "# model.load_state_dict(torch.load('../input/model-1-13-0662/model_fold_1_epoch_13_loss_0.662.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cubic-cooperation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:59.000848Z",
     "iopub.status.busy": "2021-06-29T14:46:59.000132Z",
     "iopub.status.idle": "2021-06-29T14:46:59.002677Z",
     "shell.execute_reply": "2021-06-29T14:46:59.002297Z"
    },
    "papermill": {
     "duration": 0.031259,
     "end_time": "2021-06-29T14:46:59.002775",
     "exception": false,
     "start_time": "2021-06-29T14:46:58.971516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# # disable gradients \n",
    "# with torch.no_grad(): \n",
    "#     for batch in test_dataloader:\n",
    "#         ids = batch['ids'].to(device, dtype=torch.long)\n",
    "#         input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "#         type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "#         output = model(ids, input_mask, type_ids)\n",
    "#         output = output.cpu().detach().numpy().tolist()\n",
    "#         predictions += output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mysterious-superior",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:59.057932Z",
     "iopub.status.busy": "2021-06-29T14:46:59.057263Z",
     "iopub.status.idle": "2021-06-29T14:46:59.060090Z",
     "shell.execute_reply": "2021-06-29T14:46:59.059523Z"
    },
    "papermill": {
     "duration": 0.031481,
     "end_time": "2021-06-29T14:46:59.060217",
     "exception": false,
     "start_time": "2021-06-29T14:46:59.028736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id':test['id'],'target':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "detailed-unemployment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:59.116310Z",
     "iopub.status.busy": "2021-06-29T14:46:59.115640Z",
     "iopub.status.idle": "2021-06-29T14:46:59.118061Z",
     "shell.execute_reply": "2021-06-29T14:46:59.118434Z"
    },
    "papermill": {
     "duration": 0.032105,
     "end_time": "2021-06-29T14:46:59.118548",
     "exception": false,
     "start_time": "2021-06-29T14:46:59.086443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appreciated-uzbekistan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:46:59.174069Z",
     "iopub.status.busy": "2021-06-29T14:46:59.173410Z",
     "iopub.status.idle": "2021-06-29T14:46:59.176228Z",
     "shell.execute_reply": "2021-06-29T14:46:59.175691Z"
    },
    "papermill": {
     "duration": 0.031901,
     "end_time": "2021-06-29T14:46:59.176331",
     "exception": false,
     "start_time": "2021-06-29T14:46:59.144430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-angel",
   "metadata": {
    "papermill": {
     "duration": 0.025913,
     "end_time": "2021-06-29T14:46:59.229288",
     "exception": false,
     "start_time": "2021-06-29T14:46:59.203375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1006.999218,
   "end_time": "2021-06-29T14:47:01.790580",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-29T14:30:14.791362",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
