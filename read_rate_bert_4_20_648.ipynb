{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "miniature-ocean",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:07.277425Z",
     "iopub.status.busy": "2021-06-29T16:00:07.275751Z",
     "iopub.status.idle": "2021-06-29T16:00:20.380791Z",
     "shell.execute_reply": "2021-06-29T16:00:20.380187Z",
     "shell.execute_reply.started": "2021-06-29T11:19:32.852938Z"
    },
    "papermill": {
     "duration": 13.13009,
     "end_time": "2021-06-29T16:00:20.380954",
     "exception": false,
     "start_time": "2021-06-29T16:00:07.250864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "import os\n",
    "# os.listdir(\"../input/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.system('pip install pytorch_pretrained_bert --no-index --find-links=\"../input/pytorch-pretrained-bert/pytorch_pretrained_bert\" ')\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "import random\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 356\n",
    "BERT_FP = '../input/bert-base-uncased'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nearby-wellington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:20.427352Z",
     "iopub.status.busy": "2021-06-29T16:00:20.426573Z",
     "iopub.status.idle": "2021-06-29T16:00:20.429374Z",
     "shell.execute_reply": "2021-06-29T16:00:20.428905Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.558514Z"
    },
    "papermill": {
     "duration": 0.027875,
     "end_time": "2021-06-29T16:00:20.429482",
     "exception": false,
     "start_time": "2021-06-29T16:00:20.401607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smoking-basketball",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:20.475338Z",
     "iopub.status.busy": "2021-06-29T16:00:20.474614Z",
     "iopub.status.idle": "2021-06-29T16:00:20.477557Z",
     "shell.execute_reply": "2021-06-29T16:00:20.477080Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.566924Z"
    },
    "papermill": {
     "duration": 0.028409,
     "end_time": "2021-06-29T16:00:20.477661",
     "exception": false,
     "start_time": "2021-06-29T16:00:20.449252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "\n",
    "\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "designing-printer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:20.523753Z",
     "iopub.status.busy": "2021-06-29T16:00:20.523056Z",
     "iopub.status.idle": "2021-06-29T16:00:20.525903Z",
     "shell.execute_reply": "2021-06-29T16:00:20.525419Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.577548Z"
    },
    "papermill": {
     "duration": 0.028258,
     "end_time": "2021-06-29T16:00:20.526008",
     "exception": false,
     "start_time": "2021-06-29T16:00:20.497750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForSequenceRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForSequenceRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_FP)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, ids,  token_type_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear1(pooled_output)\n",
    "        pooled_output = self.relu(pooled_output)\n",
    "        outputs = self.linear2(pooled_output)\n",
    "        return outputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aware-latex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:20.569155Z",
     "iopub.status.busy": "2021-06-29T16:00:20.568408Z",
     "iopub.status.idle": "2021-06-29T16:00:20.570578Z",
     "shell.execute_reply": "2021-06-29T16:00:20.571020Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.588976Z"
    },
    "papermill": {
     "duration": 0.025395,
     "end_time": "2021-06-29T16:00:20.571143",
     "exception": false,
     "start_time": "2021-06-29T16:00:20.545748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSELoss(outputs, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "impaired-football",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:20.617372Z",
     "iopub.status.busy": "2021-06-29T16:00:20.616861Z",
     "iopub.status.idle": "2021-06-29T16:00:21.311080Z",
     "shell.execute_reply": "2021-06-29T16:00:21.310569Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.598337Z"
    },
    "papermill": {
     "duration": 0.720201,
     "end_time": "2021-06-29T16:00:21.311225",
     "exception": false,
     "start_time": "2021-06-29T16:00:20.591024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "class regressor_stratified_cv:\n",
    "    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n",
    "                 random_state = 0, strategy = 'quantile'):\n",
    "        self.group_count = group_count\n",
    "        self.strategy = strategy\n",
    "        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n",
    "                             random_state = random_state)\n",
    "        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n",
    "        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n",
    "                                            strategy = self.strategy)  \n",
    "            \n",
    "    def split(self, X, y, groups = None):\n",
    "        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n",
    "        return self.cv.split(X, kgroups, groups)\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups = None):\n",
    "        return self.cv.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infectious-apartment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.355462Z",
     "iopub.status.busy": "2021-06-29T16:00:21.354691Z",
     "iopub.status.idle": "2021-06-29T16:00:21.356921Z",
     "shell.execute_reply": "2021-06-29T16:00:21.357283Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.611382Z"
    },
    "papermill": {
     "duration": 0.026362,
     "end_time": "2021-06-29T16:00:21.357403",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.331041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(excerpt):\n",
    "    \n",
    "    # lower casing\n",
    "    excerpt = excerpt.lower()\n",
    "\n",
    "    # removal of punctuation\n",
    "    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        \n",
    "    # removal of stopwords\n",
    "#     from nltk.corpus import stopwords\n",
    "#     \", \".join(stopwords.words('english'))\n",
    "#     STOPWORDS = set(stopwords.words('english'))\n",
    "#     excerpt = \" \".join([word for word in str(excerpt).split() if word not in STOPWORDS])\n",
    "        \n",
    "    # lemmatization \n",
    "#     from nltk.stem import WordNetLemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     excerpt = \" \".join([lemmatizer.lemmatize(word) for word in excerpt.split()])\n",
    "        \n",
    "                \n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premium-blake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.401675Z",
     "iopub.status.busy": "2021-06-29T16:00:21.401162Z",
     "iopub.status.idle": "2021-06-29T16:00:21.496648Z",
     "shell.execute_reply": "2021-06-29T16:00:21.496152Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.621207Z"
    },
    "papermill": {
     "duration": 0.119929,
     "end_time": "2021-06-29T16:00:21.496818",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.376889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2829  1.711390        0.646900  \n",
       "2830  0.189476        0.535648  \n",
       "2831  0.255209        0.483866  \n",
       "2832 -0.215279        0.514128  \n",
       "2833  0.300779        0.512379  \n",
       "\n",
       "[2834 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "visible-africa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.572967Z",
     "iopub.status.busy": "2021-06-29T16:00:21.567807Z",
     "iopub.status.idle": "2021-06-29T16:00:21.634889Z",
     "shell.execute_reply": "2021-06-29T16:00:21.635288Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.675289Z"
    },
    "papermill": {
     "duration": 0.115497,
     "end_time": "2021-06-29T16:00:21.635428",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.519931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nearby-cookie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.681456Z",
     "iopub.status.busy": "2021-06-29T16:00:21.680968Z",
     "iopub.status.idle": "2021-06-29T16:00:21.684644Z",
     "shell.execute_reply": "2021-06-29T16:00:21.684242Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.758059Z"
    },
    "papermill": {
     "duration": 0.027808,
     "end_time": "2021-06-29T16:00:21.684767",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.656959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "excerpts = df.text.values\n",
    "targets = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unique-trinidad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.728529Z",
     "iopub.status.busy": "2021-06-29T16:00:21.728044Z",
     "iopub.status.idle": "2021-06-29T16:00:21.779148Z",
     "shell.execute_reply": "2021-06-29T16:00:21.778747Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.76434Z"
    },
    "papermill": {
     "duration": 0.074205,
     "end_time": "2021-06-29T16:00:21.779260",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.705055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_FP, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worthy-logistics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.828561Z",
     "iopub.status.busy": "2021-06-29T16:00:21.828006Z",
     "iopub.status.idle": "2021-06-29T16:00:21.830483Z",
     "shell.execute_reply": "2021-06-29T16:00:21.830906Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.808321Z"
    },
    "papermill": {
     "duration": 0.031408,
     "end_time": "2021-06-29T16:00:21.831025",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.799617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, target = None, is_test=False):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.max_len = MAX_LENGTH\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.text[idx])\n",
    "        text = ' '.join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "            }\n",
    "        else:    \n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'targets': targets\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brazilian-stuart",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.875155Z",
     "iopub.status.busy": "2021-06-29T16:00:21.874626Z",
     "iopub.status.idle": "2021-06-29T16:00:21.881244Z",
     "shell.execute_reply": "2021-06-29T16:00:21.881612Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.820009Z"
    },
    "papermill": {
     "duration": 0.030154,
     "end_time": "2021-06-29T16:00:21.881748",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.851594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "precise-significance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:21.929208Z",
     "iopub.status.busy": "2021-06-29T16:00:21.928326Z",
     "iopub.status.idle": "2021-06-29T16:00:21.945531Z",
     "shell.execute_reply": "2021-06-29T16:00:21.945063Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.832327Z"
    },
    "papermill": {
     "duration": 0.043545,
     "end_time": "2021-06-29T16:00:21.945644",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.902099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "group_count = 10\n",
    "\n",
    "cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "                           group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "df = df[['text', 'target']]\n",
    "\n",
    "epochs = 10\n",
    "n_epochs_stop = 5\n",
    "epochs_no_improve = 0\n",
    "training_stats = []\n",
    "i = 1\n",
    "eval_losses = []\n",
    "scaler = GradScaler()\n",
    "# input_ids, attention_masks, token_type_ids = encode(excerpts, tokenizer)\n",
    "for train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n",
    "    train_data = df.loc[train_idx]\n",
    "    test_data = df.loc[test_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "directed-insider",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:00:22.010333Z",
     "iopub.status.busy": "2021-06-29T16:00:22.004970Z",
     "iopub.status.idle": "2021-06-29T16:16:36.297778Z",
     "shell.execute_reply": "2021-06-29T16:16:36.298842Z",
     "shell.execute_reply.started": "2021-06-29T11:20:35.386874Z"
    },
    "papermill": {
     "duration": 974.32981,
     "end_time": "2021-06-29T16:16:36.299094",
     "exception": false,
     "start_time": "2021-06-29T16:00:21.969284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Train loss:  0.6145947113843031\n",
      "Training epcoh took: 0:01:28\n",
      "Eval loss:  0.6512783500883315\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Train loss:  0.581712223694358\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6650660269790225\n",
      "Evaluation took: 0:00:09\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Train loss:  0.5491588002359363\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6579830629958047\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Train loss:  0.535218789124153\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6403369224733777\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Train loss:  0.5161133123115754\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6299225903219647\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Train loss:  0.5023194517887813\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6257989754279455\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Train loss:  0.4949530048269621\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6634146670500437\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Train loss:  0.4817390240414042\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6334445244736142\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Train loss:  0.4842379252675553\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6556078692277273\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Train loss:  0.4754784199553476\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6523706217606863\n",
      "Evaluation took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "train_set = TokenDataset(tokenizer,\n",
    "                        text = train_data['text'].values,\n",
    "                        target = train_data['target'].values\n",
    "                        )\n",
    "    \n",
    "test_set = TokenDataset(tokenizer,\n",
    "                        text = test_data['text'].values,\n",
    "                        target = test_data['target'].values\n",
    "                        )\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "    \n",
    "model = BertForSequenceRegression().to(device)\n",
    "model.load_state_dict(torch.load('../input/model-4-20-0649/model_fold_4_epoch_20_loss_0.649.pt'))\n",
    "set_trainable(model, True)\n",
    "set_trainable(model.bert.embeddings, True)\n",
    "set_trainable(model.bert.encoder, True)\n",
    "# Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.0}\n",
    "]  \n",
    "optimizer = AdamW(optimizer_parameters,\n",
    "                      lr = 2e-6\n",
    "                     )\n",
    "total_steps = (len(train_dataloader) * epochs)               \n",
    "#     num_steps = int(total_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "iter_eval_loss = []\n",
    "min_eval_loss = np.Inf\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    # training\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        target = batch['targets'].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "\n",
    "        scheduler.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "    train_losses = np.mean(tr_loss)  \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/train_fold_{i}_epoch_{epoch_i+1}\", train_losses, epoch_i)\n",
    "    print(\"Train loss: \", train_losses)\n",
    "    print(\"Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # evaluation\n",
    "    t0 = time.time()\n",
    "    all_targets, all_preds = [], []\n",
    "    model.eval()   \n",
    "    eval_loss = []\n",
    "        \n",
    "    # disable gradients \n",
    "    with torch.no_grad(): \n",
    "        for batch in test_dataloader:\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            target = batch['targets'].to(device, dtype=torch.float)\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "    epoch_eval_loss = np.mean(eval_loss)\n",
    "    eval_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/eval_fold_{i}_epoch_{epoch_i+1}\", epoch_eval_loss, epoch_i)\n",
    "    print(\"Eval loss: \", epoch_eval_loss)\n",
    "    print(\"Evaluation took: {:}\".format(eval_time))\n",
    "        \n",
    "    # recording all statistics from this epoch\n",
    "    training_stats.append({\n",
    "            'fold' : i,\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': train_losses,\n",
    "            'Eval Loss': epoch_eval_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Eval Time': eval_time\n",
    "    })\n",
    "        \n",
    "    # early stopping and saving best model\n",
    "    if epoch_eval_loss < min_eval_loss:\n",
    "        min_eval_loss = epoch_eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        PATH = f'model_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.pt'\n",
    "    \n",
    "torch.save(best_model.state_dict(), PATH)   \n",
    "torch.cuda.empty_cache()\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "virtual-budapest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.355945Z",
     "iopub.status.busy": "2021-06-29T16:16:36.354407Z",
     "iopub.status.idle": "2021-06-29T16:16:36.356747Z",
     "shell.execute_reply": "2021-06-29T16:16:36.357170Z"
    },
    "papermill": {
     "duration": 0.032133,
     "end_time": "2021-06-29T16:16:36.357305",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.325172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# n_repeats = 2\n",
    "# group_count = 10\n",
    "# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "# for train_index, test_index in cv.split(input_ids, targets):\n",
    "#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n",
    "#     train_targets, test_targets = targets[train_index], targets[test_index]\n",
    "#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n",
    "#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "northern-cruise",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.412470Z",
     "iopub.status.busy": "2021-06-29T16:16:36.411296Z",
     "iopub.status.idle": "2021-06-29T16:16:36.414001Z",
     "shell.execute_reply": "2021-06-29T16:16:36.413555Z"
    },
    "papermill": {
     "duration": 0.031281,
     "end_time": "2021-06-29T16:16:36.414104",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.382823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_trainable(model, True)\n",
    "# set_trainable(model.bert.embeddings, True)    \n",
    "# set_trainable(model.bert.encoder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pressing-companion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.472602Z",
     "iopub.status.busy": "2021-06-29T16:16:36.471407Z",
     "iopub.status.idle": "2021-06-29T16:16:36.474200Z",
     "shell.execute_reply": "2021-06-29T16:16:36.473755Z"
    },
    "papermill": {
     "duration": 0.034894,
     "end_time": "2021-06-29T16:16:36.474325",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.439431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs = 5\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = 5e-6,\n",
    "#                   eps = 1e-6 \n",
    "#                 )\n",
    "# total_steps = len(train_dataloader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps = 0,\n",
    "#                                             num_training_steps = total_steps)\n",
    "# eval_losses = []\n",
    "# for epoch_i in range(0, epochs):\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "#     # training\n",
    "#     model.train()\n",
    "#     tr_loss = []\n",
    "    \n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "#         ids, input_mask, type_ids, target = batch\n",
    "#         output = model(ids, input_mask, type_ids, target)\n",
    "#         loss = RMSELoss(output, target)\n",
    "#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "#         loss.backward()  \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()  \n",
    "#         scheduler.step()\n",
    "            \n",
    "#     train_losses = np.mean(tr_loss)  \n",
    "#     print(\"Train loss: \", train_losses)\n",
    "#     all_targets, all_preds = [], []\n",
    "#     model.eval()   \n",
    "#     eval_loss = []\n",
    "#     # evaluation\n",
    "#     # disable gradients \n",
    "#     with torch.no_grad(): \n",
    "#         for batch in test_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             ids, input_mask, type_ids, target = batch\n",
    "#             output = model(ids, input_mask, type_ids, target)\n",
    "#             loss = RMSELoss(output, target)\n",
    "#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "#     epoch_eval_loss = np.mean(eval_loss)\n",
    "#     print(\"Eval loss: \", epoch_eval_loss)\n",
    "\n",
    "#     eval_losses.append(epoch_eval_loss)   \n",
    "# torch.cuda.empty_cache()\n",
    "# mean_eval_loss = np.mean(eval_losses)\n",
    "# print(mean_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "anticipated-indian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.530434Z",
     "iopub.status.busy": "2021-06-29T16:16:36.529249Z",
     "iopub.status.idle": "2021-06-29T16:16:36.532119Z",
     "shell.execute_reply": "2021-06-29T16:16:36.531578Z"
    },
    "papermill": {
     "duration": 0.032071,
     "end_time": "2021-06-29T16:16:36.532222",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.500151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "historical-revolution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.588286Z",
     "iopub.status.busy": "2021-06-29T16:16:36.587099Z",
     "iopub.status.idle": "2021-06-29T16:16:36.589985Z",
     "shell.execute_reply": "2021-06-29T16:16:36.589465Z"
    },
    "papermill": {
     "duration": 0.03172,
     "end_time": "2021-06-29T16:16:36.590106",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.558386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "double-american",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.644504Z",
     "iopub.status.busy": "2021-06-29T16:16:36.644015Z",
     "iopub.status.idle": "2021-06-29T16:16:36.647915Z",
     "shell.execute_reply": "2021-06-29T16:16:36.647425Z"
    },
    "papermill": {
     "duration": 0.032457,
     "end_time": "2021-06-29T16:16:36.648018",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.615561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excerpts = test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceramic-advancement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.703039Z",
     "iopub.status.busy": "2021-06-29T16:16:36.702509Z",
     "iopub.status.idle": "2021-06-29T16:16:36.706345Z",
     "shell.execute_reply": "2021-06-29T16:16:36.705935Z"
    },
    "papermill": {
     "duration": 0.032267,
     "end_time": "2021-06-29T16:16:36.706448",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.674181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "intended-search",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.761428Z",
     "iopub.status.busy": "2021-06-29T16:16:36.760675Z",
     "iopub.status.idle": "2021-06-29T16:16:36.762980Z",
     "shell.execute_reply": "2021-06-29T16:16:36.763348Z"
    },
    "papermill": {
     "duration": 0.031282,
     "end_time": "2021-06-29T16:16:36.763473",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.732191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_set = TokenDataset(tokenizer,\n",
    "#                         text = test_data['text'].values, is_test = True\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "compatible-dakota",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.820637Z",
     "iopub.status.busy": "2021-06-29T16:16:36.819867Z",
     "iopub.status.idle": "2021-06-29T16:16:36.822495Z",
     "shell.execute_reply": "2021-06-29T16:16:36.822105Z"
    },
    "papermill": {
     "duration": 0.032225,
     "end_time": "2021-06-29T16:16:36.822601",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.790376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "decreased-building",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.878035Z",
     "iopub.status.busy": "2021-06-29T16:16:36.877334Z",
     "iopub.status.idle": "2021-06-29T16:16:36.880223Z",
     "shell.execute_reply": "2021-06-29T16:16:36.879766Z"
    },
    "papermill": {
     "duration": 0.031695,
     "end_time": "2021-06-29T16:16:36.880328",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.848633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BertForSequenceRegression().to(device)\n",
    "# model.load_state_dict(torch.load('../input/model-1-13-0662/model_fold_1_epoch_13_loss_0.662.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "quarterly-minute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.936397Z",
     "iopub.status.busy": "2021-06-29T16:16:36.935633Z",
     "iopub.status.idle": "2021-06-29T16:16:36.938320Z",
     "shell.execute_reply": "2021-06-29T16:16:36.937909Z"
    },
    "papermill": {
     "duration": 0.031661,
     "end_time": "2021-06-29T16:16:36.938426",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.906765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# # disable gradients \n",
    "# with torch.no_grad(): \n",
    "#     for batch in test_dataloader:\n",
    "#         ids = batch['ids'].to(device, dtype=torch.long)\n",
    "#         input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "#         type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "#         output = model(ids, input_mask, type_ids)\n",
    "#         output = output.cpu().detach().numpy().tolist()\n",
    "#         predictions += output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "crude-superintendent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:36.997424Z",
     "iopub.status.busy": "2021-06-29T16:16:36.996655Z",
     "iopub.status.idle": "2021-06-29T16:16:36.999024Z",
     "shell.execute_reply": "2021-06-29T16:16:36.999435Z"
    },
    "papermill": {
     "duration": 0.03381,
     "end_time": "2021-06-29T16:16:36.999563",
     "exception": false,
     "start_time": "2021-06-29T16:16:36.965753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id':test['id'],'target':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "potential-intelligence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:37.057644Z",
     "iopub.status.busy": "2021-06-29T16:16:37.056912Z",
     "iopub.status.idle": "2021-06-29T16:16:37.059702Z",
     "shell.execute_reply": "2021-06-29T16:16:37.059256Z"
    },
    "papermill": {
     "duration": 0.033952,
     "end_time": "2021-06-29T16:16:37.059843",
     "exception": false,
     "start_time": "2021-06-29T16:16:37.025891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "massive-imaging",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T16:16:37.116875Z",
     "iopub.status.busy": "2021-06-29T16:16:37.116129Z",
     "iopub.status.idle": "2021-06-29T16:16:37.118955Z",
     "shell.execute_reply": "2021-06-29T16:16:37.118524Z"
    },
    "papermill": {
     "duration": 0.032909,
     "end_time": "2021-06-29T16:16:37.119067",
     "exception": false,
     "start_time": "2021-06-29T16:16:37.086158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-empire",
   "metadata": {
    "papermill": {
     "duration": 0.026431,
     "end_time": "2021-06-29T16:16:37.172222",
     "exception": false,
     "start_time": "2021-06-29T16:16:37.145791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 999.998128,
   "end_time": "2021-06-29T16:16:39.818974",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-29T15:59:59.820846",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
