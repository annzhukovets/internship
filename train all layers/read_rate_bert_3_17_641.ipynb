{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-angel",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:36.918357Z",
     "iopub.status.busy": "2021-06-29T14:30:36.917515Z",
     "iopub.status.idle": "2021-06-29T14:30:50.040848Z",
     "shell.execute_reply": "2021-06-29T14:30:50.039784Z",
     "shell.execute_reply.started": "2021-06-29T11:19:32.852938Z"
    },
    "papermill": {
     "duration": 13.181394,
     "end_time": "2021-06-29T14:30:50.041035",
     "exception": false,
     "start_time": "2021-06-29T14:30:36.859641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "import os\n",
    "# os.listdir(\"../input/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.system('pip install pytorch_pretrained_bert --no-index --find-links=\"../input/pytorch-pretrained-bert/pytorch_pretrained_bert\" ')\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "import random\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 356\n",
    "BERT_FP = '../input/bert-base-uncased'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "democratic-taylor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:50.088556Z",
     "iopub.status.busy": "2021-06-29T14:30:50.087711Z",
     "iopub.status.idle": "2021-06-29T14:30:50.090534Z",
     "shell.execute_reply": "2021-06-29T14:30:50.089995Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.558514Z"
    },
    "papermill": {
     "duration": 0.027777,
     "end_time": "2021-06-29T14:30:50.090639",
     "exception": false,
     "start_time": "2021-06-29T14:30:50.062862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "basic-pontiac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:50.136784Z",
     "iopub.status.busy": "2021-06-29T14:30:50.136198Z",
     "iopub.status.idle": "2021-06-29T14:30:50.139419Z",
     "shell.execute_reply": "2021-06-29T14:30:50.138893Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.566924Z"
    },
    "papermill": {
     "duration": 0.028806,
     "end_time": "2021-06-29T14:30:50.139522",
     "exception": false,
     "start_time": "2021-06-29T14:30:50.110716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "\n",
    "\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pointed-worth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:50.186025Z",
     "iopub.status.busy": "2021-06-29T14:30:50.184823Z",
     "iopub.status.idle": "2021-06-29T14:30:50.187121Z",
     "shell.execute_reply": "2021-06-29T14:30:50.187501Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.577548Z"
    },
    "papermill": {
     "duration": 0.028474,
     "end_time": "2021-06-29T14:30:50.187619",
     "exception": false,
     "start_time": "2021-06-29T14:30:50.159145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForSequenceRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForSequenceRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_FP)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, ids,  token_type_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(ids, token_type_ids, attention_mask, return_dict=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = self.linear1(pooled_output)\n",
    "        pooled_output = self.relu(pooled_output)\n",
    "        outputs = self.linear2(pooled_output)\n",
    "        return outputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sustainable-league",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:50.230345Z",
     "iopub.status.busy": "2021-06-29T14:30:50.229818Z",
     "iopub.status.idle": "2021-06-29T14:30:50.233655Z",
     "shell.execute_reply": "2021-06-29T14:30:50.233205Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.588976Z"
    },
    "papermill": {
     "duration": 0.026435,
     "end_time": "2021-06-29T14:30:50.233760",
     "exception": false,
     "start_time": "2021-06-29T14:30:50.207325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RMSELoss(outputs, targets):\n",
    "    return torch.sqrt(nn.MSELoss()(outputs, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "national-murray",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:50.281201Z",
     "iopub.status.busy": "2021-06-29T14:30:50.280542Z",
     "iopub.status.idle": "2021-06-29T14:30:51.012858Z",
     "shell.execute_reply": "2021-06-29T14:30:51.012217Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.598337Z"
    },
    "papermill": {
     "duration": 0.759501,
     "end_time": "2021-06-29T14:30:51.012989",
     "exception": false,
     "start_time": "2021-06-29T14:30:50.253488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "class regressor_stratified_cv:\n",
    "    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n",
    "                 random_state = 0, strategy = 'quantile'):\n",
    "        self.group_count = group_count\n",
    "        self.strategy = strategy\n",
    "        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n",
    "                             random_state = random_state)\n",
    "        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n",
    "        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n",
    "                                            strategy = self.strategy)  \n",
    "            \n",
    "    def split(self, X, y, groups = None):\n",
    "        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n",
    "        return self.cv.split(X, kgroups, groups)\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups = None):\n",
    "        return self.cv.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excessive-appointment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.058936Z",
     "iopub.status.busy": "2021-06-29T14:30:51.057697Z",
     "iopub.status.idle": "2021-06-29T14:30:51.060469Z",
     "shell.execute_reply": "2021-06-29T14:30:51.060049Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.611382Z"
    },
    "papermill": {
     "duration": 0.02728,
     "end_time": "2021-06-29T14:30:51.060576",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.033296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(excerpt):\n",
    "    \n",
    "    # lower casing\n",
    "    excerpt = excerpt.lower()\n",
    "\n",
    "    # removal of punctuation\n",
    "    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        \n",
    "    # removal of stopwords\n",
    "#     from nltk.corpus import stopwords\n",
    "#     \", \".join(stopwords.words('english'))\n",
    "#     STOPWORDS = set(stopwords.words('english'))\n",
    "#     excerpt = \" \".join([word for word in str(excerpt).split() if word not in STOPWORDS])\n",
    "        \n",
    "    # lemmatization \n",
    "#     from nltk.stem import WordNetLemmatizer\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     excerpt = \" \".join([lemmatizer.lemmatize(word) for word in excerpt.split()])\n",
    "        \n",
    "                \n",
    "    return excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "growing-consent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.106050Z",
     "iopub.status.busy": "2021-06-29T14:30:51.105567Z",
     "iopub.status.idle": "2021-06-29T14:30:51.192165Z",
     "shell.execute_reply": "2021-06-29T14:30:51.192551Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.621207Z"
    },
    "papermill": {
     "duration": 0.112248,
     "end_time": "2021-06-29T14:30:51.192694",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.080446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  \n",
       "0    -0.340259        0.464009  \n",
       "1    -0.315372        0.480805  \n",
       "2    -0.580118        0.476676  \n",
       "3    -1.054013        0.450007  \n",
       "4     0.247197        0.510845  \n",
       "...        ...             ...  \n",
       "2829  1.711390        0.646900  \n",
       "2830  0.189476        0.535648  \n",
       "2831  0.255209        0.483866  \n",
       "2832 -0.215279        0.514128  \n",
       "2833  0.300779        0.512379  \n",
       "\n",
       "[2834 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polyphonic-wright",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.261225Z",
     "iopub.status.busy": "2021-06-29T14:30:51.250905Z",
     "iopub.status.idle": "2021-06-29T14:30:51.320524Z",
     "shell.execute_reply": "2021-06-29T14:30:51.320921Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.675289Z"
    },
    "papermill": {
     "duration": 0.106078,
     "end_time": "2021-06-29T14:30:51.321061",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.214983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "integral-impression",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.366933Z",
     "iopub.status.busy": "2021-06-29T14:30:51.366453Z",
     "iopub.status.idle": "2021-06-29T14:30:51.369826Z",
     "shell.execute_reply": "2021-06-29T14:30:51.370223Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.758059Z"
    },
    "papermill": {
     "duration": 0.028106,
     "end_time": "2021-06-29T14:30:51.370343",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.342237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "excerpts = df.text.values\n",
    "targets = df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "characteristic-outline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.414003Z",
     "iopub.status.busy": "2021-06-29T14:30:51.413508Z",
     "iopub.status.idle": "2021-06-29T14:30:51.458320Z",
     "shell.execute_reply": "2021-06-29T14:30:51.457898Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.76434Z"
    },
    "papermill": {
     "duration": 0.067833,
     "end_time": "2021-06-29T14:30:51.458425",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.390592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_FP, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "friendly-literature",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.507633Z",
     "iopub.status.busy": "2021-06-29T14:30:51.506963Z",
     "iopub.status.idle": "2021-06-29T14:30:51.510338Z",
     "shell.execute_reply": "2021-06-29T14:30:51.509899Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.808321Z"
    },
    "papermill": {
     "duration": 0.031603,
     "end_time": "2021-06-29T14:30:51.510439",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.478836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, target = None, is_test=False):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.is_test = is_test\n",
    "        self.max_len = MAX_LENGTH\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.text[idx])\n",
    "        text = ' '.join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "            }\n",
    "        else:    \n",
    "            targets = torch.tensor(self.target[idx], dtype=torch.float)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'targets': targets\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "moving-triumph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.554697Z",
     "iopub.status.busy": "2021-06-29T14:30:51.554204Z",
     "iopub.status.idle": "2021-06-29T14:30:51.561361Z",
     "shell.execute_reply": "2021-06-29T14:30:51.561770Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.820009Z"
    },
    "papermill": {
     "duration": 0.031145,
     "end_time": "2021-06-29T14:30:51.561884",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.530739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "guided-documentary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.610371Z",
     "iopub.status.busy": "2021-06-29T14:30:51.609858Z",
     "iopub.status.idle": "2021-06-29T14:30:51.624031Z",
     "shell.execute_reply": "2021-06-29T14:30:51.623647Z",
     "shell.execute_reply.started": "2021-06-29T11:19:37.832327Z"
    },
    "papermill": {
     "duration": 0.041644,
     "end_time": "2021-06-29T14:30:51.624148",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.582504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "group_count = 10\n",
    "\n",
    "cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "                           group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "df = df[['text', 'target']]\n",
    "\n",
    "epochs = 10\n",
    "n_epochs_stop = 5\n",
    "epochs_no_improve = 0\n",
    "training_stats = []\n",
    "i = 1\n",
    "eval_losses = []\n",
    "scaler = GradScaler()\n",
    "# input_ids, attention_masks, token_type_ids = encode(excerpts, tokenizer)\n",
    "for train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n",
    "    train_data = df.loc[train_idx]\n",
    "    test_data = df.loc[test_idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "flush-testing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:30:51.685733Z",
     "iopub.status.busy": "2021-06-29T14:30:51.685073Z",
     "iopub.status.idle": "2021-06-29T14:47:05.491697Z",
     "shell.execute_reply": "2021-06-29T14:47:05.490770Z",
     "shell.execute_reply.started": "2021-06-29T11:20:35.386874Z"
    },
    "papermill": {
     "duration": 973.847479,
     "end_time": "2021-06-29T14:47:05.491860",
     "exception": false,
     "start_time": "2021-06-29T14:30:51.644381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Train loss:  0.6210688864681083\n",
      "Training epcoh took: 0:01:29\n",
      "Eval loss:  0.6473967730998993\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Train loss:  0.5814598593073832\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6573622392283546\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Train loss:  0.5533418252434529\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6436605271365907\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Train loss:  0.5348704218024939\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6244939747783873\n",
      "Evaluation took: 0:00:09\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Train loss:  0.5149993963644538\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6262731717692481\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Train loss:  0.5011052229035069\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6265911956628164\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Train loss:  0.49555060435348836\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6488037241829766\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Train loss:  0.4814061677791703\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6315911610921224\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Train loss:  0.48193569040634265\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.6483930846055349\n",
      "Evaluation took: 0:00:08\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Train loss:  0.47456585437479154\n",
      "Training epcoh took: 0:01:27\n",
      "Eval loss:  0.648006667693456\n",
      "Evaluation took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "train_set = TokenDataset(tokenizer,\n",
    "                        text = train_data['text'].values,\n",
    "                        target = train_data['target'].values\n",
    "                        )\n",
    "    \n",
    "test_set = TokenDataset(tokenizer,\n",
    "                        text = test_data['text'].values,\n",
    "                        target = test_data['target'].values\n",
    "                        )\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "    \n",
    "model = BertForSequenceRegression().to(device)\n",
    "model.load_state_dict(torch.load('../input/model-3-17-0641/model_fold_3_epoch_17_loss_0.641.pt'))\n",
    "set_trainable(model, True)\n",
    "set_trainable(model.bert.embeddings, True)\n",
    "set_trainable(model.bert.encoder, True)\n",
    "# Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "    'weight_decay': 0.0}\n",
    "]  \n",
    "optimizer = AdamW(optimizer_parameters,\n",
    "                      lr = 2e-6\n",
    "                     )\n",
    "total_steps = (len(train_dataloader) * epochs)               \n",
    "#     num_steps = int(total_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "iter_eval_loss = []\n",
    "min_eval_loss = np.Inf\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    # training\n",
    "    model.train()\n",
    "    tr_loss = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        ids = batch['ids'].to(device, dtype=torch.long)\n",
    "        input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "        type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "        target = batch['targets'].to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "\n",
    "        scheduler.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "            \n",
    "    train_losses = np.mean(tr_loss)  \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/train_fold_{i}_epoch_{epoch_i+1}\", train_losses, epoch_i)\n",
    "    print(\"Train loss: \", train_losses)\n",
    "    print(\"Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # evaluation\n",
    "    t0 = time.time()\n",
    "    all_targets, all_preds = [], []\n",
    "    model.eval()   \n",
    "    eval_loss = []\n",
    "        \n",
    "    # disable gradients \n",
    "    with torch.no_grad(): \n",
    "        for batch in test_dataloader:\n",
    "            ids = batch['ids'].to(device, dtype=torch.long)\n",
    "            input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "            type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "            target = batch['targets'].to(device, dtype=torch.float)\n",
    "            output = model(ids, input_mask, type_ids)\n",
    "            loss = RMSELoss(output, target)\n",
    "            eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "    epoch_eval_loss = np.mean(eval_loss)\n",
    "    eval_time = format_time(time.time() - t0)\n",
    "    writer.add_scalar(f\"Loss/eval_fold_{i}_epoch_{epoch_i+1}\", epoch_eval_loss, epoch_i)\n",
    "    print(\"Eval loss: \", epoch_eval_loss)\n",
    "    print(\"Evaluation took: {:}\".format(eval_time))\n",
    "        \n",
    "    # recording all statistics from this epoch\n",
    "    training_stats.append({\n",
    "            'fold' : i,\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': train_losses,\n",
    "            'Eval Loss': epoch_eval_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Eval Time': eval_time\n",
    "    })\n",
    "        \n",
    "    # early stopping and saving best model\n",
    "    if epoch_eval_loss < min_eval_loss:\n",
    "        min_eval_loss = epoch_eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        PATH = f'model_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.pt'\n",
    "    \n",
    "torch.save(best_model.state_dict(), PATH)   \n",
    "torch.cuda.empty_cache()\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increasing-hospital",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.548440Z",
     "iopub.status.busy": "2021-06-29T14:47:05.547189Z",
     "iopub.status.idle": "2021-06-29T14:47:05.549496Z",
     "shell.execute_reply": "2021-06-29T14:47:05.549891Z"
    },
    "papermill": {
     "duration": 0.032011,
     "end_time": "2021-06-29T14:47:05.550008",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.517997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# n_repeats = 2\n",
    "# group_count = 10\n",
    "# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n",
    "#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n",
    "\n",
    "# for train_index, test_index in cv.split(input_ids, targets):\n",
    "#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n",
    "#     train_targets, test_targets = targets[train_index], targets[test_index]\n",
    "#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n",
    "#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "resident-ocean",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.605019Z",
     "iopub.status.busy": "2021-06-29T14:47:05.604496Z",
     "iopub.status.idle": "2021-06-29T14:47:05.608309Z",
     "shell.execute_reply": "2021-06-29T14:47:05.607776Z"
    },
    "papermill": {
     "duration": 0.032192,
     "end_time": "2021-06-29T14:47:05.608415",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.576223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_trainable(model, True)\n",
    "# set_trainable(model.bert.embeddings, True)    \n",
    "# set_trainable(model.bert.encoder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amateur-standing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.664391Z",
     "iopub.status.busy": "2021-06-29T14:47:05.663853Z",
     "iopub.status.idle": "2021-06-29T14:47:05.667592Z",
     "shell.execute_reply": "2021-06-29T14:47:05.667205Z"
    },
    "papermill": {
     "duration": 0.032814,
     "end_time": "2021-06-29T14:47:05.667690",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.634876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epochs = 5\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = 5e-6,\n",
    "#                   eps = 1e-6 \n",
    "#                 )\n",
    "# total_steps = len(train_dataloader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps = 0,\n",
    "#                                             num_training_steps = total_steps)\n",
    "# eval_losses = []\n",
    "# for epoch_i in range(0, epochs):\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "#     # training\n",
    "#     model.train()\n",
    "#     tr_loss = []\n",
    "    \n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "#         ids, input_mask, type_ids, target = batch\n",
    "#         output = model(ids, input_mask, type_ids, target)\n",
    "#         loss = RMSELoss(output, target)\n",
    "#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "#         loss.backward()  \n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()  \n",
    "#         scheduler.step()\n",
    "            \n",
    "#     train_losses = np.mean(tr_loss)  \n",
    "#     print(\"Train loss: \", train_losses)\n",
    "#     all_targets, all_preds = [], []\n",
    "#     model.eval()   \n",
    "#     eval_loss = []\n",
    "#     # evaluation\n",
    "#     # disable gradients \n",
    "#     with torch.no_grad(): \n",
    "#         for batch in test_dataloader:\n",
    "#             batch = tuple(t.to(device) for t in batch)\n",
    "#             ids, input_mask, type_ids, target = batch\n",
    "#             output = model(ids, input_mask, type_ids, target)\n",
    "#             loss = RMSELoss(output, target)\n",
    "#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n",
    "            \n",
    "#     epoch_eval_loss = np.mean(eval_loss)\n",
    "#     print(\"Eval loss: \", epoch_eval_loss)\n",
    "\n",
    "#     eval_losses.append(epoch_eval_loss)   \n",
    "# torch.cuda.empty_cache()\n",
    "# mean_eval_loss = np.mean(eval_losses)\n",
    "# print(mean_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automated-attitude",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.724172Z",
     "iopub.status.busy": "2021-06-29T14:47:05.722977Z",
     "iopub.status.idle": "2021-06-29T14:47:05.725668Z",
     "shell.execute_reply": "2021-06-29T14:47:05.725256Z"
    },
    "papermill": {
     "duration": 0.031849,
     "end_time": "2021-06-29T14:47:05.725761",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.693912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "least-clearing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.780859Z",
     "iopub.status.busy": "2021-06-29T14:47:05.780368Z",
     "iopub.status.idle": "2021-06-29T14:47:05.784140Z",
     "shell.execute_reply": "2021-06-29T14:47:05.783650Z"
    },
    "papermill": {
     "duration": 0.032373,
     "end_time": "2021-06-29T14:47:05.784235",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.751862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stretch-block",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.839694Z",
     "iopub.status.busy": "2021-06-29T14:47:05.838543Z",
     "iopub.status.idle": "2021-06-29T14:47:05.841362Z",
     "shell.execute_reply": "2021-06-29T14:47:05.840791Z"
    },
    "papermill": {
     "duration": 0.031424,
     "end_time": "2021-06-29T14:47:05.841463",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.810039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excerpts = test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "headed-farming",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.895953Z",
     "iopub.status.busy": "2021-06-29T14:47:05.895459Z",
     "iopub.status.idle": "2021-06-29T14:47:05.898669Z",
     "shell.execute_reply": "2021-06-29T14:47:05.899043Z"
    },
    "papermill": {
     "duration": 0.032043,
     "end_time": "2021-06-29T14:47:05.899219",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.867176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "christian-hughes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:05.953995Z",
     "iopub.status.busy": "2021-06-29T14:47:05.953356Z",
     "iopub.status.idle": "2021-06-29T14:47:05.956246Z",
     "shell.execute_reply": "2021-06-29T14:47:05.955756Z"
    },
    "papermill": {
     "duration": 0.031314,
     "end_time": "2021-06-29T14:47:05.956348",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.925034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_set = TokenDataset(tokenizer,\n",
    "#                         text = test_data['text'].values, is_test = True\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "integrated-hamburg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.011501Z",
     "iopub.status.busy": "2021-06-29T14:47:06.010841Z",
     "iopub.status.idle": "2021-06-29T14:47:06.013152Z",
     "shell.execute_reply": "2021-06-29T14:47:06.013595Z"
    },
    "papermill": {
     "duration": 0.03104,
     "end_time": "2021-06-29T14:47:06.013703",
     "exception": false,
     "start_time": "2021-06-29T14:47:05.982663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "joint-probe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.068523Z",
     "iopub.status.busy": "2021-06-29T14:47:06.067835Z",
     "iopub.status.idle": "2021-06-29T14:47:06.070572Z",
     "shell.execute_reply": "2021-06-29T14:47:06.070041Z"
    },
    "papermill": {
     "duration": 0.031143,
     "end_time": "2021-06-29T14:47:06.070668",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.039525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BertForSequenceRegression().to(device)\n",
    "# model.load_state_dict(torch.load('../input/model-1-13-0662/model_fold_1_epoch_13_loss_0.662.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "focal-departure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.127487Z",
     "iopub.status.busy": "2021-06-29T14:47:06.126770Z",
     "iopub.status.idle": "2021-06-29T14:47:06.129527Z",
     "shell.execute_reply": "2021-06-29T14:47:06.129016Z"
    },
    "papermill": {
     "duration": 0.03195,
     "end_time": "2021-06-29T14:47:06.129623",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.097673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# # disable gradients \n",
    "# with torch.no_grad(): \n",
    "#     for batch in test_dataloader:\n",
    "#         ids = batch['ids'].to(device, dtype=torch.long)\n",
    "#         input_mask = batch['mask'].to(device, dtype=torch.long)\n",
    "#         type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "#         output = model(ids, input_mask, type_ids)\n",
    "#         output = output.cpu().detach().numpy().tolist()\n",
    "#         predictions += output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "otherwise-liberia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.185460Z",
     "iopub.status.busy": "2021-06-29T14:47:06.184729Z",
     "iopub.status.idle": "2021-06-29T14:47:06.187345Z",
     "shell.execute_reply": "2021-06-29T14:47:06.186852Z"
    },
    "papermill": {
     "duration": 0.031932,
     "end_time": "2021-06-29T14:47:06.187442",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.155510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'id':test['id'],'target':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "impaired-cuisine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.242376Z",
     "iopub.status.busy": "2021-06-29T14:47:06.241739Z",
     "iopub.status.idle": "2021-06-29T14:47:06.244458Z",
     "shell.execute_reply": "2021-06-29T14:47:06.243931Z"
    },
    "papermill": {
     "duration": 0.031214,
     "end_time": "2021-06-29T14:47:06.244559",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.213345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cultural-embassy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T14:47:06.300407Z",
     "iopub.status.busy": "2021-06-29T14:47:06.299633Z",
     "iopub.status.idle": "2021-06-29T14:47:06.302401Z",
     "shell.execute_reply": "2021-06-29T14:47:06.301974Z"
    },
    "papermill": {
     "duration": 0.032042,
     "end_time": "2021-06-29T14:47:06.302502",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.270460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-halloween",
   "metadata": {
    "papermill": {
     "duration": 0.026159,
     "end_time": "2021-06-29T14:47:06.354808",
     "exception": false,
     "start_time": "2021-06-29T14:47:06.328649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 998.933583,
   "end_time": "2021-06-29T14:47:08.977451",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-29T14:30:30.043868",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
