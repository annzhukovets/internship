{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import string\nimport copy\nimport time\n%matplotlib inline\nimport os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import RobertaTokenizer\n\nfrom transformers import RobertaModel, AdamW\nfrom torch.optim import SGD\nimport random\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\n\n\nSEED = 42\nBATCH_SIZE = 16\nMAX_LENGTH = 321\nROBERTA_FP = '../input/roberta-base'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nos.environ['PYTHONASSEED'] = str(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"_uuid":"9a537004-fdaf-4d59-b417-e2f6a9de74d5","_cell_guid":"34f3b73b-4e2d-4976-8553-3785bc80ceaf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:44.183635Z","iopub.execute_input":"2021-07-05T07:18:44.184085Z","iopub.status.idle":"2021-07-05T07:18:50.703229Z","shell.execute_reply.started":"2021-07-05T07:18:44.183973Z","shell.execute_reply":"2021-07-05T07:18:50.702388Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"_uuid":"30c5a220-cb57-4717-9acf-3650a981ce1d","_cell_guid":"179096b0-64d9-4f7b-b0c9-5ecaac4af727","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:50.706548Z","iopub.execute_input":"2021-07-05T07:18:50.706820Z","iopub.status.idle":"2021-07-05T07:18:50.713292Z","shell.execute_reply.started":"2021-07-05T07:18:50.706795Z","shell.execute_reply":"2021-07-05T07:18:50.712483Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def children(m):\n    return m if isinstance(m, (list, tuple)) else list(m.children())\n\n\ndef set_trainable_attr(m, b):\n    m.trainable = b\n    for p in m.parameters():\n        p.requires_grad = b\n\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    if len(c) > 0:\n        for l in c:\n            apply_leaf(l, f)\n\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m, b))","metadata":{"_uuid":"7d158a9a-0862-4ba0-84b2-406c926093ac","_cell_guid":"c68fff04-419d-4691-89e4-61f4f7f72dc9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:50.715323Z","iopub.execute_input":"2021-07-05T07:18:50.715816Z","iopub.status.idle":"2021-07-05T07:18:50.722440Z","shell.execute_reply.started":"2021-07-05T07:18:50.715779Z","shell.execute_reply":"2021-07-05T07:18:50.721410Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class RobertaForSequenceRegression(nn.Module):\n    def __init__(self):\n        super(RobertaForSequenceRegression, self).__init__()\n        self.roberta = RobertaModel.from_pretrained(ROBERTA_FP)\n        self.head = AttentionHead(self.roberta.config.hidden_size, self.roberta.config.hidden_size)\n        self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n        self.linear1 = nn.Linear(self.roberta.config.hidden_size, 256)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(256, 1)\n\n    def forward(self, ids,  attention_mask):\n        pooled_output = self.roberta(input_ids=ids, attention_mask=attention_mask)[0]\n        pooled_output = self.head(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        pooled_output = self.linear1(pooled_output)\n        pooled_output = self.relu(pooled_output)\n        outputs = self.linear2(pooled_output)\n        return outputs.view(-1)","metadata":{"_uuid":"6f678c5b-030d-49bb-b611-0c744376f571","_cell_guid":"e1c853e2-5ae8-47dd-ba16-39c01402b109","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:50.724064Z","iopub.execute_input":"2021-07-05T07:18:50.724398Z","iopub.status.idle":"2021-07-05T07:18:50.733759Z","shell.execute_reply.started":"2021-07-05T07:18:50.724364Z","shell.execute_reply":"2021-07-05T07:18:50.732567Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-07-05T07:18:50.735097Z","iopub.execute_input":"2021-07-05T07:18:50.735575Z","iopub.status.idle":"2021-07-05T07:18:50.747245Z","shell.execute_reply.started":"2021-07-05T07:18:50.735522Z","shell.execute_reply":"2021-07-05T07:18:50.746436Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def RMSELoss(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs, targets))","metadata":{"_uuid":"605ec29c-031c-4a91-a9dc-4c6964265c99","_cell_guid":"036568c5-6886-4da2-a9a8-bde13e052873","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:50.748419Z","iopub.execute_input":"2021-07-05T07:18:50.748771Z","iopub.status.idle":"2021-07-05T07:18:50.756291Z","shell.execute_reply.started":"2021-07-05T07:18:50.748737Z","shell.execute_reply":"2021-07-05T07:18:50.755445Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nclass regressor_stratified_cv:\n    def __init__(self, n_splits = 10, n_repeats = 2, group_count = 10,\n                 random_state = 0, strategy = 'quantile'):\n        self.group_count = group_count\n        self.strategy = strategy\n        self.cvkwargs = dict(n_splits = n_splits, n_repeats = n_repeats, \n                             random_state = random_state)\n        self.cv = RepeatedStratifiedKFold(**self.cvkwargs)\n        self.discretizer = KBinsDiscretizer(n_bins = self.group_count, encode = 'ordinal',\n                                            strategy = self.strategy)  \n            \n    def split(self, X, y, groups = None):\n        kgroups=self.discretizer.fit_transform(y[:, None])[:, 0]\n        return self.cv.split(X, kgroups, groups)\n    \n    def get_n_splits(self, X, y, groups = None):\n        return self.cv.get_n_splits(X, y, groups)","metadata":{"_uuid":"c0fbda5c-40f2-4dd9-8886-fb202bf84479","_cell_guid":"b43ea6f3-4a91-4482-a028-94a15c31a174","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:50.757445Z","iopub.execute_input":"2021-07-05T07:18:50.757701Z","iopub.status.idle":"2021-07-05T07:18:51.472001Z","shell.execute_reply.started":"2021-07-05T07:18:50.757678Z","shell.execute_reply":"2021-07-05T07:18:51.471123Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def text_preprocessing(excerpt):\n    \n    # lower casing\n    excerpt = excerpt.lower()\n\n    # removal of punctuation\n    excerpt = excerpt.translate(str.maketrans('', '', string.punctuation))\n\n                \n    return excerpt","metadata":{"_uuid":"f06f6d99-321e-462a-a7c5-e9798eb4d022","_cell_guid":"9d335daf-1ecf-4e78-81c1-4d38383b2cc8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.473158Z","iopub.execute_input":"2021-07-05T07:18:51.473494Z","iopub.status.idle":"2021-07-05T07:18:51.481098Z","shell.execute_reply.started":"2021-07-05T07:18:51.473460Z","shell.execute_reply":"2021-07-05T07:18:51.480197Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/train-with-trans/commonlit_train_with_augs_trans.csv')\ndf","metadata":{"_uuid":"ac55590c-3f6f-4ba5-b053-5242aaa41b5e","_cell_guid":"07039672-d6a3-4e44-8a7b-e5799972f7cd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.485526Z","iopub.execute_input":"2021-07-05T07:18:51.485773Z","iopub.status.idle":"2021-07-05T07:18:51.648465Z","shell.execute_reply.started":"2021-07-05T07:18:51.485749Z","shell.execute_reply":"2021-07-05T07:18:51.647692Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"             id                                          url_legal  \\\n0     c12129c31                                                NaN   \n1     85aa80a4c                                                NaN   \n2     b69ac6792                                                NaN   \n3     dd1000b26                                                NaN   \n4     37c1b32fb                                                NaN   \n...         ...                                                ...   \n2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n\n           license                                            excerpt  \\\n0              NaN  When the young people returned to the ballroom...   \n1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n2              NaN  As Roger had predicted, the snow departed as q...   \n3              NaN  And outside before the palace a great garden w...   \n4              NaN  Once upon a time there were Three Bears who li...   \n...            ...                                                ...   \n2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n\n        target  standard_error  \\\n0    -0.753342        0.464009   \n1    -0.353870        0.480805   \n2    -0.601594        0.476676   \n3    -1.461556        0.450007   \n4     0.007099        0.510845   \n...        ...             ...   \n2829  1.074728        0.646900   \n2830 -0.259013        0.535648   \n2831 -0.006627        0.483866   \n2832 -0.512207        0.514128   \n2833 -0.012121        0.512379   \n\n                                                   text  \n0     When the youngsters returned to the ballroom, ...  \n1     Throughout the dinner hour, Mrs. Fayre remaine...  \n2     As Roger had predicted, the snow was gone as f...  \n3     And outside, in front of the palace, a large g...  \n4     Once upon a time there were three bears who li...  \n...                                                 ...  \n2829  When you think about dinosaurs and where they ...  \n2830  So what is a solid? Solids are usually hard be...  \n2831  The second state of matter we will talk about ...  \n2832  Solids are shapes that you can actually touch....  \n2833  Animals are made up of many cells. They eat th...  \n\n[2834 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url_legal</th>\n      <th>license</th>\n      <th>excerpt</th>\n      <th>target</th>\n      <th>standard_error</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c12129c31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>When the young people returned to the ballroom...</td>\n      <td>-0.753342</td>\n      <td>0.464009</td>\n      <td>When the youngsters returned to the ballroom, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85aa80a4c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n      <td>-0.353870</td>\n      <td>0.480805</td>\n      <td>Throughout the dinner hour, Mrs. Fayre remaine...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b69ac6792</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>As Roger had predicted, the snow departed as q...</td>\n      <td>-0.601594</td>\n      <td>0.476676</td>\n      <td>As Roger had predicted, the snow was gone as f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dd1000b26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>And outside before the palace a great garden w...</td>\n      <td>-1.461556</td>\n      <td>0.450007</td>\n      <td>And outside, in front of the palace, a large g...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37c1b32fb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Once upon a time there were Three Bears who li...</td>\n      <td>0.007099</td>\n      <td>0.510845</td>\n      <td>Once upon a time there were three bears who li...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2829</th>\n      <td>25ca8f498</td>\n      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>When you think of dinosaurs and where they liv...</td>\n      <td>1.074728</td>\n      <td>0.646900</td>\n      <td>When you think about dinosaurs and where they ...</td>\n    </tr>\n    <tr>\n      <th>2830</th>\n      <td>2c26db523</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>So what is a solid? Solids are usually hard be...</td>\n      <td>-0.259013</td>\n      <td>0.535648</td>\n      <td>So what is a solid? Solids are usually hard be...</td>\n    </tr>\n    <tr>\n      <th>2831</th>\n      <td>cd19e2350</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>The second state of matter we will discuss is ...</td>\n      <td>-0.006627</td>\n      <td>0.483866</td>\n      <td>The second state of matter we will talk about ...</td>\n    </tr>\n    <tr>\n      <th>2832</th>\n      <td>15e2e9e7a</td>\n      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Solids are shapes that you can actually touch....</td>\n      <td>-0.512207</td>\n      <td>0.514128</td>\n      <td>Solids are shapes that you can actually touch....</td>\n    </tr>\n    <tr>\n      <th>2833</th>\n      <td>5b990ba77</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Animals are made of many cells. They eat thing...</td>\n      <td>-0.012121</td>\n      <td>0.512379</td>\n      <td>Animals are made up of many cells. They eat th...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2834 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df[\"text\"] = df[\"excerpt\"].apply(lambda x: text_preprocessing(x))","metadata":{"_uuid":"2b7a539e-2add-4537-98c8-ee9a0286d392","_cell_guid":"c2b28ea0-c1e9-45cf-8d69-1ce466dac14e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.650286Z","iopub.execute_input":"2021-07-05T07:18:51.650543Z","iopub.status.idle":"2021-07-05T07:18:51.657994Z","shell.execute_reply.started":"2021-07-05T07:18:51.650517Z","shell.execute_reply":"2021-07-05T07:18:51.657171Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"excerpts = df.text.values\ntargets = df.target.values","metadata":{"_uuid":"0d090d08-8c7f-4fad-a2f8-0b5a8adb42ee","_cell_guid":"e9788680-3d78-4e10-8940-acc9a1e0a48b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.659323Z","iopub.execute_input":"2021-07-05T07:18:51.659699Z","iopub.status.idle":"2021-07-05T07:18:51.665479Z","shell.execute_reply.started":"2021-07-05T07:18:51.659659Z","shell.execute_reply":"2021-07-05T07:18:51.664745Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Load the ROBERTA tokenizer.\ntokenizer = RobertaTokenizer.from_pretrained(ROBERTA_FP)","metadata":{"_uuid":"dfe3837d-29c3-4720-972d-558ae5df1411","_cell_guid":"88b7ae3f-6da4-4e21-9820-b2ea2ef0af2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.666309Z","iopub.execute_input":"2021-07-05T07:18:51.666549Z","iopub.status.idle":"2021-07-05T07:18:51.786222Z","shell.execute_reply.started":"2021-07-05T07:18:51.666526Z","shell.execute_reply":"2021-07-05T07:18:51.785386Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TokenDataset(Dataset):\n    def __init__(self, tokenizer, text, target = None, is_test=False):\n        self.text = text\n        self.target = target\n        self.is_test = is_test\n        self.max_len = MAX_LENGTH\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n        text = ' '.join(text.split())\n        inputs = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            add_special_tokens=True,\n            max_length = self.max_len,\n            padding='max_length',\n#             add_special_tokens=True,\n            return_attention_mask=True\n        )\n        ids = torch.tensor(inputs['input_ids'], dtype=torch.long)\n        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n        \n        if self.is_test:\n            return {\n                'ids': ids,\n                'mask': mask,\n            }\n        else:    \n            targets = torch.tensor(self.target[idx], dtype=torch.float)\n            return {\n                'ids': ids,\n                'mask': mask,\n                'targets': targets\n            }","metadata":{"_uuid":"f16bc25d-9dde-46e2-94ed-ed9af62f3f81","_cell_guid":"f1941f49-e270-463c-b5a1-cd56578c8840","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.788642Z","iopub.execute_input":"2021-07-05T07:18:51.789170Z","iopub.status.idle":"2021-07-05T07:18:51.797879Z","shell.execute_reply.started":"2021-07-05T07:18:51.789131Z","shell.execute_reply":"2021-07-05T07:18:51.797010Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"writer = SummaryWriter()","metadata":{"_uuid":"066449bb-db83-431b-90ce-638bc4756c47","_cell_guid":"c78ca05e-3ed9-408e-bfd8-5354c338f7c6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.799044Z","iopub.execute_input":"2021-07-05T07:18:51.799574Z","iopub.status.idle":"2021-07-05T07:18:51.814463Z","shell.execute_reply.started":"2021-07-05T07:18:51.799534Z","shell.execute_reply":"2021-07-05T07:18:51.813569Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\nn_repeats = 1\ngroup_count = 10\n\ncv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n                           group_count = group_count, random_state = 0, strategy = 'quantile')\n\ndf = df[['text', 'target']]\n\nepochs = 30\nn_epochs_stop = 10\nepochs_no_improve = 0\ntraining_stats = []\ni = 1\neval_losses = []\n# scaler = GradScaler()\n# input_ids, attention_masks, token_type_ids = encode(excerpts, tokenizer)\nfor train_idx, test_idx in cv.split(df[\"text\"], df[\"target\"].values):\n    print('======== Fold {:}  ========'.format(i))\n    train_data = df.loc[train_idx]\n    test_data = df.loc[test_idx]\n    \n    train_set = TokenDataset(tokenizer,\n                            text = train_data['text'].values,\n                            target = train_data['target'].values\n                           )\n    \n    test_set = TokenDataset(tokenizer,\n                           text = test_data['text'].values,\n                           target = test_data['target'].values\n                          )\n\n    train_dataloader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers=8)\n\n    test_dataloader = DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = False, num_workers=8)\n    \n    model = RobertaForSequenceRegression().to(device) \n    optimizer = AdamW(model.parameters(),\n                      lr = 2e-5,\n                      weight_decay = 0.01\n                     )\n    total_steps = (len(train_dataloader) * epochs)               \n    iters = len(train_dataloader)\n    scheduler = get_cosine_schedule_with_warmup(optimizer,\n                                                num_warmup_steps=0, \n                                                num_training_steps= total_steps)    \n    iter_eval_loss = []\n    min_eval_loss = np.Inf\n    for epoch_i in range(0, epochs):\n        print(\"\")\n        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n        t0 = time.time()\n        # training\n        model.train()\n        tr_loss = []\n        for step, batch in enumerate(train_dataloader):\n            ids = batch['ids'].to(device, dtype=torch.long)\n            input_mask = batch['mask'].to(device, dtype=torch.long)\n            target = batch['targets'].to(device, dtype=torch.float)\n            optimizer.zero_grad()\n            with autocast():\n                output = model(ids, input_mask)\n                loss = RMSELoss(output, target)\n                tr_loss.append(loss.cpu().detach().numpy().tolist())\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step(epoch_i + step/ iters)\n        \n        torch.cuda.empty_cache()\n        train_losses = np.mean(tr_loss)  \n        training_time = format_time(time.time() - t0)\n        writer.add_scalar(f\"Loss/train_fold_{i}\", train_losses, epoch_i)\n        print(\"Train loss: \", train_losses)\n        print(\"Training epcoh took: {:}\".format(training_time))\n        \n        # evaluation\n        t0 = time.time()\n        all_targets, all_preds = [], []\n        model.eval()   \n        eval_loss = []\n        \n        # disable gradients \n        with torch.no_grad(): \n            for batch in test_dataloader:\n                ids = batch['ids'].to(device, dtype=torch.long)\n                input_mask = batch['mask'].to(device, dtype=torch.long)\n                target = batch['targets'].to(device, dtype=torch.float)\n                output = model(ids, input_mask)\n                loss = RMSELoss(output, target)\n                eval_loss.append(loss.cpu().detach().numpy().tolist())\n            \n        epoch_eval_loss = np.mean(eval_loss)\n        eval_time = format_time(time.time() - t0)\n        writer.add_scalar(f\"Loss/eval_fold_{i}\", epoch_eval_loss, epoch_i)\n        print(\"Eval loss: \", epoch_eval_loss)\n        print(\"Evaluation took: {:}\".format(eval_time))\n        \n        # recording all statistics from this epoch\n        training_stats.append({\n            'fold' : i,\n            'epoch': epoch_i + 1,\n            'Training Loss': train_losses,\n            'Eval Loss': epoch_eval_loss,\n            'Training Time': training_time,\n            'Eval Time': eval_time\n        })\n        \n        # early stopping and saving best model\n        if epoch_eval_loss < min_eval_loss:\n            epochs_no_improve = 0\n            min_eval_loss = epoch_eval_loss\n            best_model = copy.deepcopy(model)\n            PATH = f'model_fold_{i}_epoch_{epoch_i+1}_loss_{round(epoch_eval_loss, 3)}.bin'\n        else:\n            epochs_no_improve += 1\n        if epochs_no_improve >= n_epochs_stop:\n            print('Early stopping! Epoch {:}'.format(epoch_i + 1) )\n            break\n        else:\n            continue\n    \n    torch.save(best_model.state_dict(), PATH)    \n    i += 1    \n    torch.cuda.empty_cache()\nwriter.flush()\nwriter.close()","metadata":{"_uuid":"163bad85-f736-456f-b0ed-8c75cce84146","_cell_guid":"3569fa32-c022-49f6-b6fe-f9ddc75c3dfe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-05T07:18:51.816035Z","iopub.execute_input":"2021-07-05T07:18:51.816413Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"======== Fold 1  ========\n\n======== Epoch 1 / 30 ========\nTrain loss:  0.7715758788333812\nTraining epcoh took: 0:01:24\nEval loss:  0.5845868728227086\nEvaluation took: 0:00:07\n\n======== Epoch 2 / 30 ========\nTrain loss:  0.5502157752782526\nTraining epcoh took: 0:01:22\nEval loss:  0.5514436256554391\nEvaluation took: 0:00:07\n\n======== Epoch 3 / 30 ========\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a DataFrame from our training statistics.\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'fold' as the row index.\n# df_stats = df_stats.set_index('fold')\ndf_stats","metadata":{"_uuid":"242393f2-f3f2-42b0-a7bc-6a547876da9a","_cell_guid":"d851b70c-8a9e-4b62-9720-9af838753bc9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 15))\nfor fold in df_stats.fold.unique():\n    ax = fig.add_subplot(5,1,fold)\n    max_epoch = df_stats[df_stats['fold']==fold]['epoch'].max()\n    x = np.arange(max_epoch)\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Training Loss']])\n    ax.plot(x,df_stats[df_stats['fold']==fold][['Eval Loss']])\n    plt.xticks(range(0, max_epoch, 5))","metadata":{"_uuid":"902da3b7-7d86-4716-b68d-07ca03ce50d4","_cell_guid":"9ad36d53-cc01-451e-bdf1-c6ad6f45b4ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_splits = 5\n# n_repeats = 2\n# group_count = 10\n# cv = regressor_stratified_cv(n_splits = n_splits, n_repeats = n_repeats,\n#                            group_count = group_count, random_state = 0, strategy = 'quantile')\n\n# for train_index, test_index in cv.split(input_ids, targets):\n#     train_inputs, test_inputs = input_ids[train_index], input_ids[test_index]\n#     train_targets, test_targets = targets[train_index], targets[test_index]\n#     train_masks, test_masks = attention_masks[train_index], attention_masks[test_index]\n#     train_type_ids, test_type_ids = token_type_ids[train_index], token_type_ids[test_index]","metadata":{"_uuid":"5f8bd137-286f-4f52-9877-0151412dc1d2","_cell_guid":"c003fc35-13d4-4158-a277-63a3cb776fde","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n# test_inputs = torch.tensor(test_inputs, dtype=torch.long)\n# train_targets = torch.tensor(train_targets, dtype=torch.float)\n# test_targets = torch.tensor(test_targets, dtype=torch.float)\n# train_masks = torch.tensor(train_masks, dtype=torch.long)\n# test_masks = torch.tensor(test_masks, dtype=torch.long)\n# train_type_ids = torch.tensor(train_type_ids, dtype=torch.long)\n# test_type_ids = torch.tensor(test_type_ids, dtype=torch.long)","metadata":{"_uuid":"c254bfbe-430f-4d0f-9606-239cc9d6e9e1","_cell_guid":"3f524936-43f8-4b10-aa49-e3e721261840","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data = TensorDataset(train_inputs, train_masks, train_type_ids, train_targets)\n# train_sampler = RandomSampler(train_data)\n# train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = BATCH_SIZE)\n\n# test_data = TensorDataset(test_inputs, test_masks, test_type_ids, test_targets)\n# test_sampler = RandomSampler(test_data)\n# test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = BATCH_SIZE)","metadata":{"_uuid":"e30d268e-2046-4a55-98cd-9dce31bb6366","_cell_guid":"55255cf8-436d-461a-83fe-1ace1194257d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set_trainable(model, True)\n# set_trainable(model.bert.embeddings, True)    \n# set_trainable(model.bert.encoder, True)","metadata":{"_uuid":"59d149e4-6cb9-49a0-a50e-4801b51cf9bf","_cell_guid":"723d1ff0-e469-4e20-92b7-2eca47b3a49e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epochs = 5\n# optimizer = AdamW(model.parameters(),\n#                   lr = 5e-6,\n#                   eps = 1e-6 \n#                 )\n# total_steps = len(train_dataloader) * epochs\n# scheduler = get_linear_schedule_with_warmup(optimizer, \n#                                             num_warmup_steps = 0,\n#                                             num_training_steps = total_steps)\n# eval_losses = []\n# for epoch_i in range(0, epochs):\n#     print(\"\")\n#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n#     # training\n#     model.train()\n#     tr_loss = []\n    \n#     for step, batch in enumerate(train_dataloader):\n#         batch = tuple(t.to(device) for t in batch)\n#         ids, input_mask, type_ids, target = batch\n#         output = model(ids, input_mask, type_ids, target)\n#         loss = RMSELoss(output, target)\n#         tr_loss.append(loss.cpu().detach().numpy().tolist())\n#         loss.backward()  \n#         optimizer.step()\n#         optimizer.zero_grad()  \n#         scheduler.step()\n            \n#     train_losses = np.mean(tr_loss)  \n#     print(\"Train loss: \", train_losses)\n#     all_targets, all_preds = [], []\n#     model.eval()   \n#     eval_loss = []\n#     # evaluation\n#     # disable gradients \n#     with torch.no_grad(): \n#         for batch in test_dataloader:\n#             batch = tuple(t.to(device) for t in batch)\n#             ids, input_mask, type_ids, target = batch\n#             output = model(ids, input_mask, type_ids, target)\n#             loss = RMSELoss(output, target)\n#         eval_loss.append(loss.cpu().detach().numpy().tolist())\n            \n#     epoch_eval_loss = np.mean(eval_loss)\n#     print(\"Eval loss: \", epoch_eval_loss)\n\n#     eval_losses.append(epoch_eval_loss)   \n# torch.cuda.empty_cache()\n# mean_eval_loss = np.mean(eval_losses)\n# print(mean_eval_loss)","metadata":{"_uuid":"e00d869d-c1b5-491c-9fd9-da562f67ac4e","_cell_guid":"676a670c-02dd-4914-a4df-26fef294717b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"_uuid":"ba1b3151-aff7-4da9-8163-729658471e12","_cell_guid":"7fe96e02-5bff-4399-bc9d-8e33d2b1788f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[\"text\"] = test[\"excerpt\"].apply(lambda x: text_preprocessing(x))","metadata":{"_uuid":"ac750cde-13ca-40b8-ae0b-1134093a71b1","_cell_guid":"9c69b185-47d9-4fd3-98fd-d744ca80bd3e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# excerpts = test.text.values","metadata":{"_uuid":"59fd4308-2cc9-4400-b685-72aa5efe276a","_cell_guid":"0ba4c7b2-3563-4014-ab9d-f04600c8e975","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # convert sentences into tokens\n# input_ids = [tokenizer.encode(excerpt, add_special_tokens = True, max_length = MAX_LENGTH,\n#                               padding='max_length') for excerpt in excerpts]\n\n# input_ids = np.array(input_ids)\n# attention_masks = []\n# # create a mask of 1 for all input tokens and 0 for all padding tokens\n# attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n# attention_masks = np.array(attention_masks)\n# # create token type ids\n# token_type_ids = [[0 for i in seq] for seq in input_ids]\n# token_type_ids = np.array(token_type_ids)","metadata":{"_uuid":"5bb54ba8-2995-4390-8069-ad5333a526ea","_cell_guid":"31a89ebf-81b4-48e6-922f-fbd851d787c3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_ids = torch.tensor(input_ids, dtype=torch.long)\n# attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n# token_type_ids = torch.tensor(token_type_ids, dtype=torch.long)","metadata":{"_uuid":"571d84c0-3bf6-4317-9bed-5e8a6aca2e15","_cell_guid":"1d50e596-a80c-460d-91ac-b4e76852c5a6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction_data = TensorDataset(input_ids, attention_masks, token_type_ids)\n# prediction_sampler = SequentialSampler(prediction_data)\n# prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=BATCH_SIZE)","metadata":{"_uuid":"d44b5f79-bb95-4ecc-aef0-3d539a019cb3","_cell_guid":"d9d98d5f-0899-4180-9e30-e230cc029130","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.eval()   \n# predictions , true_labels = [], []\n# # evaluation\n# for batch in prediction_dataloader:\n#     # disable gradients \n#     batch = tuple(t.to(device) for t in batch)\n#     ids, input_mask, type_ids = batch\n#     with torch.no_grad():    \n#         output = model(ids, input_mask, type_ids) \n#     output = output.cpu().detach().numpy().tolist()\n#     predictions += output","metadata":{"_uuid":"5353fa59-9bd4-43ef-84a3-c564fd042a77","_cell_guid":"69c06869-3b98-4509-8f21-3f7e4fa97fb8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id':test['id'],'target':predictions})","metadata":{"_uuid":"8f0cb4ae-84f3-40e6-bd92-2f13edccfaba","_cell_guid":"b543c4d5-6bfd-4a3b-866a-545b8ec22f83","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission.to_csv('submission.csv',index=False)","metadata":{"_uuid":"a7b24ae2-9c22-4d15-8b58-f52e7bdad0b5","_cell_guid":"58bdb1ec-27d0-4e77-8600-90ee61f14225","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"_uuid":"070e6a6c-2304-43d7-b97e-a18d4b3b0c2b","_cell_guid":"5452bdab-8b67-4675-8298-31689a85566c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"bfef8cfd-afe4-427b-999e-8eaa167a3972","_cell_guid":"977ed5ac-a426-4e13-8dfe-e2915a93f3c3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}